
@article{ackermanSharingKnowledgeExpertise2013,
  title = {Sharing {{Knowledge}} and {{Expertise}}: {{The CSCW View}} of {{Knowledge Management}}},
  shorttitle = {Sharing {{Knowledge}} and {{Expertise}}},
  author = {Ackerman, Mark S. and Dachtera, Juri and Pipek, Volkmar and Wulf, Volker},
  year = {2013},
  month = aug,
  volume = {22},
  pages = {531--573},
  issn = {0925-9724, 1573-7551},
  doi = {10.1007/s10606-013-9192-8},
  url = {http://link.springer.com/10.1007/s10606-013-9192-8},
  urldate = {2020-04-14},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/MSJFGB99/Ackerman et al. - 2013 - Sharing Knowledge and Expertise The CSCW View of .pdf},
  journal = {Computer Supported Cooperative Work (CSCW)},
  language = {en},
  number = {4-6}
}

@article{adler-milsteinCrossingHealthIT2017,
  title = {Crossing the Health {{IT}} Chasm: Considerations and Policy Recommendations to Overcome Current Challenges and Enable Value-Based Care},
  author = {{Adler-Milstein}, Julia and Embi, Peter J and Middleton, Blackford and Sarkar, Indra Neil and Smith, Jeff},
  year = {2017},
  month = sep,
  volume = {24},
  pages = {1036--1043},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocx017},
  url = {http://dx.doi.org/10.1093/jamia/ocx017},
  abstract = {While great progress has been made in digitizing the US health care
system, today's health information technology (IT) infrastructure remains
largely a collection of systems that are not designed to support a
transition to value-based care. In addition, the pursuit of value-based
care, in which we deliver better care with better outcomes at lower cost,
places new demands on the health care system that our IT infrastructure
needs to be able to support. Provider organizations pursuing new models of
health care delivery and payment are finding that their electronic systems
lack the capabilities needed to succeed. The result is a chasm between the
current health IT ecosystem and the health IT ecosystem that is
desperately needed.In this paper, we identify a set of focal goals and
associated near-term achievable actions that are critical to pursue in
order to enable the health IT ecosystem to meet the acute needs of modern
health care delivery. These ideas emerged from discussions that occurred
during the 2015 American Medical Informatics Association Policy
Invitational Meeting. To illustrate the chasm and motivate our
recommendations, we created a vignette from the multistakeholder
perspectives of a patient, his provider, and researchers/innovators. It
describes an idealized scenario in which each stakeholder's needs are
supported by an integrated health IT environment. We identify the gaps
preventing such a reality today and present associated policy
recommendations that serve as a blueprint for critical actions that would
enable us to cross the current health IT chasm by leveraging systems and
information to routinely deliver high-value care.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8DKVFKD6/Adler-Milstein et al_2017_Crossing the health IT chasm.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/essential (all collaborators should peruse),AMIA,health reform,policy},
  number = {5}
}

@article{ahaltClinicalDataSources2019,
  title = {Clinical {{Data}}: {{Sources}} and {{Types}}, {{Regulatory Constraints}}, {{Applications}}},
  shorttitle = {Clinical {{Data}}},
  author = {Ahalt, Stanley C. and Chute, Christopher G. and Fecho, Karamarie and Glusman, Gustavo and Hadlock, Jennifer and Taylor, Casey Overby and Pfaff, Emily R. and Robinson, Peter N. and Solbrig, Harold and Ta, Casey and Tatonetti, Nicholas and Weng, Chunhua},
  year = {2019},
  volume = {12},
  pages = {329--333},
  issn = {1752-8062},
  doi = {10.1111/cts.12638},
  url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1111/cts.12638},
  urldate = {2020-04-27},
  copyright = {\textcopyright{} 2019 The Authors. Clinical and Translational Science published by Wiley Periodicals, Inc. on behalf of the American Society for Clinical Pharmacology and Therapeutics.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4RAMNEHK/Ahalt et al_2019_Clinical Data.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/GUJLRJCQ/cts.html},
  journal = {Clinical and Translational Science},
  language = {en},
  number = {4}
}

@unpublished{alperDevelopingMetadataCategories2020,
  title = {Developing {{Metadata Categories}} as a {{Strategy}} to {{Mobilize Computable Biomedical Knowledge}}},
  author = {Alper, Brian S and Bray, Bruce E and Conte, Marisa L and Eldredge, Christina and Flynn, Allen and Gold, Sigfried and Greenes, Robert A and Haug, Peter and Koru, Gunes and McClay, James and Sainvil, Marc L and Sottara, Davide and Tuttle, Mark and Yurk, Robin Ann},
  year = {2020},
  url = {https://deepblue.lib.umich.edu/handle/2027.42/155655},
  abstract = {Computable biomedical knowledge artifacts (CBKs) are digital objects or entities representing biomedical knowledge as machine-independent data structures that can be parsed and processed by different information systems. The breadth of content represented in CBKs spans all biomedical knowledge related to human health and so it includes knowledge about molecules, cells, organs, individual people, human populations, and the environment. CBKs vary in their scope, purpose, and audience. Some CBKs support biomedical research. Other CBKs help improve health outcomes by enabling clinical decision support, health education, health promotion, and population health analytics. In some instances, CBKs have multiple uses that span research, education, clinical care, or population health. As the number of CBKs grows large, producers must describe them with structured, searchable metadata so that consumers can find, deploy, and use them properly. This report delineates categories of metadata for describing CBKs sufficiently to enable CBKs to be mobilized for various purposes.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/NDPPSBHN/Alper et al. - 2020 - Developing Metadata Categories as a Strategy to Mo.pdf},
  keywords = {computable biomedical knowledge,metadata},
  language = {en}
}

@article{amosUMLSUsersUses2020,
  title = {{{UMLS}} Users and Uses: A Current Overview},
  shorttitle = {{{UMLS}} Users and Uses},
  author = {Amos, Liz and Anderson, David and Brody, Stacy and Ripple, Anna and Humphreys, Betsy L},
  year = {2020},
  month = jul,
  issn = {1527-974X},
  doi = {10.1093/jamia/ocaa084},
  url = {https://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocaa084/5873605},
  urldate = {2020-07-28},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/W6KGX48H/Amos et al_2020_UMLS users and uses.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en}
}

@misc{ATLAS,
  title = {{{ATLAS}}},
  url = {https://github.com/OHDSI/Atlas/wiki},
  urldate = {2020-05-05},
  abstract = {ATLAS is an open source software tool for researchers to conduct scientific analyses on standardized observational data},
  copyright = {Apache-2.0},
  howpublished = {Observational Health Data Sciences and Informatics}
}

@article{bahrElicitingIntensionDrug2017,
  title = {Eliciting the {{Intension}} of {{Drug Value Sets}} \textendash{} {{Principles}} and {{Quality Assurance Applications}}},
  author = {Bahr, Nathan J. and Nelson, Scott D. and Winnenburg, Rainer and Bodenreider, Olivier},
  year = {2017},
  volume = {245},
  pages = {843--847},
  issn = {0926-9630},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5881398/},
  urldate = {2020-05-14},
  abstract = {Value sets (VSs) used in electronic clinical quality measures are lists of codes from standard terminologies (``extensional'' VSs), whose purpose (``intension'') is not always explicitly stated. We elicited the intension for the 09/01/2014 release of extensional medication value sets by comparison to drug classes from the October 2014 release of RxClass. Value sets matched drug classes if they shared common ingredients, as evidenced by Jaccard similarity score. We elicited the intension of 80 extensional value sets. The average Jaccard similarity was 0.65 for single classes and 0.80 for combination classes, with 34\% (27/80) of the value sets having high similarity scores. Manual review by a pharmacist indicated 51\% (41/80) of the drug classes selected as the best mapping for a value set matched the intension reflected in that value set name. This approach has the potential for facilitating the development and maintenance of medication value sets.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/X6I64G9X/Bahr et al_2017_Eliciting the Intension of Drug Value Sets – Principles and Quality Assurance.pdf},
  journal = {Studies in health technology and informatics},
  pmcid = {PMC5881398},
  pmid = {29295218}
}

@article{batchInteractiveVisualizationGap2018,
  title = {The {{Interactive Visualization Gap}} in {{Initial Exploratory Data Analysis}}},
  author = {Batch, Andrea and Elmqvist, Niklas},
  year = {2018},
  month = jan,
  volume = {24},
  pages = {278--287},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2017.2743990},
  url = {http://ieeexplore.ieee.org/document/8017577/},
  urldate = {2020-01-23},
  abstract = {Data scientists and other analytic professionals often use interactive visualization in the dissemination phase at the end of a workflow during which findings are communicated to a wider audience. Visualization scientists, however, hold that interactive representation of data can also be used during exploratory analysis itself. Since the use of interactive visualization is optional rather than mandatory, this leaves a ``visualization gap'' during initial exploratory analysis that is the onus of visualization researchers to fill. In this paper, we explore areas where visualization would be beneficial in applied research by conducting a design study using a novel variation on contextual inquiry conducted with professional data analysts. Based on these interviews and experiments, we propose a set of interactive initial exploratory visualization guidelines which we believe will promote adoption by this type of user.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PWUJE6CC/Batch_Elmqvist_2018_The Interactive Visualization Gap in Initial Exploratory Data Analysis.pdf},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  language = {en},
  number = {1}
}

@article{becnelBRIDGDomainInformation2017,
  title = {{{BRIDG}}: A Domain Information Model for Translational and Clinical Protocol-Driven Research},
  author = {Becnel, Lauren B and Hastak, Smita and Ver Hoef, Wendy and Milius, Robert P and Slack, Maryann and Wold, Diane and Glickman, Michael L and Brodsky, Boris and Jaffe, Charles and Kush, Rebecca and Helton, Edward},
  year = {2017},
  month = sep,
  volume = {24},
  pages = {882--890},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocx004},
  url = {http://dx.doi.org/10.1093/jamia/ocx004},
  abstract = {Background: It is critical to integrate and analyze data from biological,
translational, and clinical studies with data from health systems;
however, electronic artifacts are stored in thousands of disparate systems
that are often unable to readily exchange data. Objective: To facilitate
meaningful data exchange, a model that presents a common understanding of
biomedical research concepts and their relationships with health care
semantics is required. The Biomedical Research Integrated Domain Group
(BRIDG) domain information model fulfills this need. Software systems
created from BRIDG have shared meaning "baked in," enabling
interoperability among disparate systems. For nearly 10 years, the
Clinical Data Standards Interchange Consortium, the National Cancer
Institute, the US Food and Drug Administration, and Health Level 7
International have been key stakeholders in developing BRIDG. Methods:
BRIDG is an open-source Unified Modeling Language-class model developed
through use cases and harmonization with other models. Results: With its
4+ releases, BRIDG includes clinical and now translational research
concepts in its Common, Protocol Representation, Study Conduct, Adverse
Events, Regulatory, Statistical Analysis, Experiment, Biospecimen, and
Molecular Biology subdomains. Interpretation: The model is a Clinical Data
Standards Interchange Consortium, Health Level 7 International, and
International Standards Organization standard that has been utilized in
national and international standards-based software development projects.
It will continue to mature and evolve in the areas of clinical imaging,
pathology, ontology, and vocabulary support. BRIDG 4.1.1 and prior
releases are freely available at https://bridgmodel.nci.nih.gov .},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/G2PQTLKQ/Becnel et al_2017_BRIDG.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,clinical trials,data modeling,data sharing,pharmacogenetics,translational medical research},
  number = {5}
}

@article{benchimolDevelopmentUseReporting2011,
  title = {Development and Use of Reporting Guidelines for Assessing the Quality of Validation Studies of Health Administrative Data},
  author = {Benchimol, Eric I. and Manuel, Douglas G. and To, Teresa and Griffiths, Anne M. and Rabeneck, Linda and Guttmann, Astrid},
  year = {2011},
  month = aug,
  volume = {64},
  pages = {821--829},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2010.10.006},
  abstract = {BACKGROUND AND OBJECTIVES: Validation of health administrative data for identifying patients with different health states (diseases and conditions) is a research priority, but no guidelines exist for ensuring quality. We created reporting guidelines for studies validating administrative data identification algorithms and used them to assess the quality of reporting of validation studies in the literature.
METHODS: Using Standards for Reporting of Diagnostic accuracy (STARD) criteria as a guide, we created a 40-item checklist of items with which identification accuracy studies should be reported. A systematic review identified studies that validated identification algorithms using administrative data. We used the checklist to assess the quality of reporting.
RESULTS: In 271 included articles, goals and data sources were well reported but few reported four or more statistical estimates of accuracy (36.9\%). In 65.9\% of studies reporting positive predictive value (PPV)/negative predictive value (NPV), the prevalence of disease in the validation cohort was higher than in the administrative data, potentially falsely elevating predictive values. Subgroup accuracy (53.1\%) and 95\% confidence intervals for accuracy measures (35.8\%) were also underreported.
CONCLUSIONS: The quality of studies validating health states in the administrative data varies, with significant deficits in reporting of markers of diagnostic accuracy, including the appropriate estimation of PPV and NPV. These omissions could lead to misclassification bias and incorrect estimation of incidence and health services utilization rates. Use of a reporting checklist, such as the one created for this study by modifying the STARD criteria, could improve the quality of reporting of validation studies, allowing for accurate application of algorithms, and interpretation of research using health administrative data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/Y7T8RIAE/Benchimol et al_2011_Development and use of reporting guidelines for assessing the quality of.pdf},
  journal = {Journal of Clinical Epidemiology},
  keywords = {Algorithms,Checklist,Forms and Records Control,Guidelines as Topic,Health Services Research,Health Status,Hospital Records,Humans,International Classification of Diseases,Quality Control,Translational Medical Research,Validation Studies as Topic},
  language = {eng},
  number = {8},
  pmid = {21194889}
}

@article{benchimolREportingStudiesConducted2015,
  title = {The {{REporting}} of Studies {{Conducted}} Using {{Observational Routinely}}-Collected Health {{Data}} ({{RECORD}}) {{Statement}}},
  author = {Benchimol, Eric I. and Smeeth, Liam and Guttmann, Astrid and Harron, Katie and Moher, David and Petersen, Irene and S{\o}rensen, Henrik T. and {von Elm}, Erik and Langan, Sin{\'e}ad M. and {RECORD Working Committee}},
  year = {2015},
  month = oct,
  volume = {12},
  pages = {e1001885},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001885},
  url = {https://dx.plos.org/10.1371/journal.pmed.1001885},
  urldate = {2020-04-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GUNHW7Y9/Benchimol et al_2015_The REporting of studies Conducted using Observational Routinely-collected.pdf},
  journal = {PLOS Medicine},
  language = {en},
  number = {10}
}

@book{bensonPrinciplesHealthInteroperability2016,
  title = {Principles of Health Interoperability: {{SNOMED CT}}, {{HL7}} and {{FHIR}}},
  shorttitle = {Principles of Health Interoperability},
  author = {Benson, Tim and Grieve, Grahame},
  year = {2016},
  publisher = {{Springer}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8CR3HANS/Benson_Grieve_2016_Principles of health interoperability.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/CX8RJYD2/10.html}
}

@article{bergMultipleBodiesMedical1997,
  title = {The Multiple Bodies of the Medical Record},
  author = {Berg, M and Bowker, G},
  year = {1997},
  issn = {0038-0253},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1533-8525.1997.tb00490.x/full},
  abstract = {Abstract This article argues that the medical record is an important focus
for sociological research. In medical work, the modern patient's body that
Foucault has so aptly described is produced through embodied, materially
heterogeneous work, and the medical record plays},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RZ8DXEL8/Berg_Bowker_1997_The multiple bodies of the medical record.pdf},
  journal = {Sociol. Q.},
  keywords = {ISchool/INST888-Butler/Leading INST888,People/Geof Bowker,Random stuff to show Rachel Paperpile}
}

@book{bloorKeywordsQualitativeMethods2006,
  title = {Keywords in {{Qualitative Methods}}},
  author = {Bloor, Michael and Wood, Fiona},
  year = {2006},
  publisher = {{SAGE Publications Ltd}},
  address = {{1 Oliver's Yard,~55 City Road,~London~England~EC1Y 1SP~United Kingdom}},
  doi = {10.4135/9781849209403},
  url = {http://methods.sagepub.com/book/keywords-in-qualitative-methods},
  urldate = {2020-08-04},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6LUCX8SZ/keywords-in-qualitative-methods.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/REQ45Q77/Professor Michael Bloor, Dr Fiona Wood - Keywords in Qualitative Methods_ A Vocabulary of Research Concepts-Sage Publications Ltd (2006).pdf},
  isbn = {978-0-7619-4330-3 978-1-84920-940-3}
}

@article{bodenreiderNLMValueSet2013,
  ids = {bodenreiderNLMValueSet2013},
  title = {The {{NLM Value Set Authority Center}}},
  author = {Bodenreider, Olivier and Nguyen, Duc and Chiang, Pishing and Chuang, Philip and Madden, Maureen and Winnenburg, Rainer and McClure, Rob and Emrick, Steve and D'Souza, Ivor},
  year = {2013},
  volume = {192},
  pages = {1224},
  issn = {0926-9630},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4300102/},
  urldate = {2019-03-09},
  abstract = {The Value Set Authority Center (VSAC) at the National Library of Medicine (NLM) provides downloadable access to all official versions of vocabulary value sets contained in the Clinical Quality Measures (CQMs) used in the certification criteria for electronic health record systems (``Meaningful Use'' incentive program). Each value set consists of the numerical values (codes) and human-readable names (descriptions), drawn from standard vocabularies such as LOINC, RxNorm and SNOMED CT\textregistered, that are used to define clinical data elements used in clinical quality measures (e.g., patients with diabetes, tricyclic antidepressants). The content of the VSAC will gradually expand to incorporate value sets for other use cases, as well as for new measures and updates to existing measures.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/KHJ94MZG/Bodenreider et al_2013_The NLM value set authority center.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/VIY9K466/Bodenreider et al_2013_The NLM Value Set Authority Center.pdf},
  journal = {Studies in health technology and informatics},
  pmcid = {PMC4300102},
  pmid = {23920998}
}

@article{bodenreiderReportBoardScientific2014,
  title = {A {{Report}} to the {{Board}} of {{Scientific Counselors September}} 2014},
  author = {Bodenreider, Olivier and Winnenburg, Rainer},
  year = {2014},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PDTMHY6R/Bodenreider_Winnenburg_2014_A Report to the Board of Scientific Counselors September 2014.pdf}
}

@article{bodenreiderRxNavSemanticNavigation2004,
  title = {{{RxNav}}: A Semantic Navigation Tool for Clinical Drugs},
  author = {Bodenreider, Olivier and Nelson, Stuart J},
  year = {2004},
  volume = {1530},
  url = {http://morc2.nlm.nih.gov/pubs/pdf/2004-medinfo-ob-poster.pdf},
  abstract = {The RxNorm project1 aims at creating a consistent representation for
clinical drugs in the Unified Medical Language System\textregistered (UMLS\textregistered ). A semantic
normal form for a clinical drug, designed to represent the meaning of an
expression typically seen in a practitioner's},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/SX6WSSFK/Bodenreider_Nelson_2004_RxNav.pdf},
  journal = {Medinfo}
}

@article{bodenreiderUMLSSemanticIntegration2009,
  title = {{{UMLS}} and Semantic Integration},
  author = {Bodenreider, Olivier},
  year = {2009},
  url = {http://morc1.nlm.nih.gov/pubs/pres/20090518-LifeWatch.pdf},
  abstract = {An adrenal disease characterized by the progressive destruction of the
adrenal cortex, resulting in insufficient production of aldosterone and
hydrocortisone. Clinical symptoms include anorexia; nausea; weight loss;
muscle ewakness; and hyperpigmentation of the skin},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8HPLYI67/Bodenreider_2009_UMLS and semantic integration.pdf}
}

@article{bodenreiderUMLSSemanticWeb2008,
  title = {The {{UMLS}} and the {{Semantic Web}}},
  author = {Bodenreider, Olivier},
  year = {2008},
  url = {http://mor2.nlm.nih.gov/pubs/pres/20080922-BioRDF.pdf},
  abstract = {\ldots{} Identifiers for biomedical entities Page 23. Lister Hill National Center
for Biomedical Communications 23 References \ding{117} UMLS umlsinfo.nlm.nih.gov \ding{117}
UMLS browsers (free, but UMLS license required) \ding{108} Knowledge Source Server:
umlsks.nlm.nih.gov \ding{108} Semantic Navigator:},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CFRRDJI7/Bodenreider_2008_The UMLS and the Semantic Web.pdf}
}

@article{bodenreiderVisualizationToolsBiomedical,
  title = {Visualization {{Tools}} for {{Biomedical Knowledge}}},
  author = {Bodenreider, Olivier},
  url = {http://mor.nlm.nih.gov/pubs/pres/20060602-HCIL_HSW.pdf},
  abstract = {Page 1. Olivier Bodenreider Lister Hill National Center for Biomedical
Communications Bethesda, Maryland - USA Visualization Tools for Biomedical
Knowledge University of Maryland Human-Computer Interaction Laboratory
23rd Annual Symposium Workshop on Humans and},
  journal = {mor.nlm.nih.gov}
}

@inproceedings{bosca2014modeling,
  title = {Modeling, Managing, Exposing, and Linking Ontologies with a Wiki-Based Tool},
  booktitle = {Proceedings of {{LREC}}},
  author = {Bosca, Alessio and Casu, Matteo and Dragoni, Mauro and Rexha, Andi},
  year = {2014},
  pages = {1668},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RXATQJDR/Bosca et al_2014_Modeling, managing, exposing, and linking ontologies with a wiki-based tool.pdf}
}

@inproceedings{bossenDataworkHealthcareNew2016,
  title = {Data-Work in {{Healthcare}}: {{The New Work Ecologies}} of {{Healthcare Infrastructures}}},
  shorttitle = {Data-Work in {{Healthcare}}},
  booktitle = {Proceedings of the 19th {{ACM Conference}} on {{Computer Supported Cooperative Work}} and {{Social Computing Companion}}},
  author = {Bossen, Claus and Pine, Kathleen and Elllingsen, Gunnar and Cabitza, Federico},
  year = {2016},
  month = feb,
  pages = {509--514},
  publisher = {{Association for Computing Machinery}},
  address = {{San Francisco, California, USA}},
  doi = {10.1145/2818052.2855505},
  url = {http://doi.org/10.1145/2818052.2855505},
  urldate = {2020-01-28},
  abstract = {The workshop focuses on the new work ecologies emerging from implementation and use of information infrastructures in healthcare (IIH). As IIH ``grows'' through organizational and regulatory mechanisms, CSCW researchers grapple with the shifting nature of healthcare data. CSCW has long been concerned with coordination, cooperation, and communication among interdisciplinary occupations in healthcare. Yet, while medical record keeping is still a primary function of IIH, second order data usages are increasingly large foci of IIH design and use. Facilitating development of health data practice and infrastructure is an area ripe for CSCW research. Critical topics include but are not limited to: re-use of clinical data for second order usages; design of artifacts and infrastructures; politics of creating and using data; algorithmic authority of IIH and effects on the exercise of expertise and discretion of healthcare professions; new forms of healthcare data work, including new occupations; data-driven accountability and management in healthcare''},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/Y65A4V74/Bossen et al_2016_Data-work in Healthcare.pdf},
  isbn = {978-1-4503-3950-6},
  keywords = {Accountability,cooperation,coordination,data,datadriven management,healthcare,information infrastructures,transparency,work},
  series = {{{CSCW}} '16 {{Companion}}}
}

@inproceedings{bouamraneOverviewElectronicHealth2012,
  title = {An Overview of Electronic Health Information Management Systems Quality Assessment},
  booktitle = {Proceedings of the 2nd International Workshop on {{Managing}} Interoperability and {{compleXity}} in Health Systems},
  author = {Bouamrane, Matt-Mouley and Mair, Frances and Tao, Cui},
  year = {2012},
  month = oct,
  pages = {37--46},
  publisher = {{Association for Computing Machinery}},
  address = {{Maui, Hawaii, USA}},
  doi = {10.1145/2389672.2389680},
  url = {https://doi.org/10.1145/2389672.2389680},
  urldate = {2020-03-05},
  abstract = {The efficient management and usage of information within integrated care delivery systems will have substantial impacts on patients' care outcomes. Electronic health information management systems need to guarantee the integrity of clinical data capture and the quality of information processing, in order to deliver actionable knowledge to health professionals at the point of care. Generic tools and evaluation frameworks are needed to assess the quality of eHealth information systems for a wide range of stakeholders: end-users, including health professionals and patients, healthcare organisations and policymakers. We present an overview of data and information quality assessment in electronic health systems. We use the model of the patient / clinician encounter of Brown and Warmington (2002) to describe how issues of poor data quality and information mismanagement impact on the clinical encounter. We then use the 6 dimensions model of quality in information systems first proposed by DeLone \& McLean (1992) to propose a comprehensive description of data quality issues in eHealth.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/QI2MSV9B/Bouamrane et al_2012_An overview of electronic health information management systems quality.pdf},
  isbn = {978-1-4503-1710-8},
  keywords = {ehealth,electronic health systems,health care information management,health information quality assessment},
  series = {{{MIXHS}} '12}
}

@misc{bowkerSortingThingsOut2000,
  title = {Sorting {{Things Out}}},
  author = {Bowker, Geoffrey C and Star, Susan Leigh},
  year = {2000},
  month = aug,
  url = {https://mitpress.mit.edu/books/sorting-things-out},
  urldate = {2017-09-26},
  keywords = {ISchool/CDM in HRR temp,ISchool/INST888-Butler/Leading INST888}
}

@incollection{braunThematicAnalysis2012,
  title = {Thematic Analysis.},
  booktitle = {{{APA}} Handbook of Research Methods in Psychology, {{Vol}} 2: {{Research}} Designs: {{Quantitative}}, Qualitative, Neuropsychological, and Biological.},
  author = {Braun, Virginia and Clarke, Victoria},
  editor = {Cooper, Harris and Camic, Paul M. and Long, Debra L. and Panter, A. T. and Rindskopf, David and Sher, Kenneth J.},
  year = {2012},
  pages = {57--71},
  publisher = {{American Psychological Association}},
  address = {{Washington}},
  doi = {10.1037/13620-004},
  url = {http://content.apa.org/books/13620-004},
  urldate = {2020-01-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CWAE3M6I/Braun_Clarke_2012_Thematic analysis.pdf},
  isbn = {978-1-4338-1005-3},
  language = {en}
}

@article{brown2006statin,
  title = {Statin-Use Phenotyping in the Advanced Elderly-Validation in a Large, Population-Based {{DNA Biobank}}},
  author = {{Brown-Switzer}, Christa and Sirohi, Ekta and Peissig, Peggy and Berg, Richard L and Ghebranious, Nader and McCarty, Catherine A and Wilke, Russell A},
  year = {2006},
  publisher = {{Federation of American Societies for Experimental Biology}}
}

@incollection{carageaMetadataRegistryISO2009,
  title = {Metadata {{Registry}}, {{ISO}}/{{IEC}} 11179},
  booktitle = {Encyclopedia of {{Database Systems}}},
  author = {Caragea, Cornelia and Honavar, Vasant and Boncz, Peter and Boncz, Peter and Larson, Per-{\AA}ke and Dietrich, Suzanne W. and Navarro, Gonzalo and Thuraisingham, Bhavani and Luo, Yan and Wolfson, Ouri and Beitzel, Steven M. and Jensen, Eric C. and Frieder, Ophir and Jensen, Christian S. and Tradi{\v s}auskas, Nerius and Munson, Ethan V. and Wun, Alex and Goda, Kazuo and E. Fienberg, Stephen and Jin, Jiashun and Liu, Guimei and Craswell, Nick and Pedersen, Torben Bach and Pautasso, Cesare and Moro, Mirella M. and Manegold, Stefan and Manegold, Stefan and Carminati, Barbara and Blanton, Marina and Bouchenak, Sara and {de Palma}, No{\"e}l and Tang, Wei and Quix, Christoph and Tang, Wei and Jeusfeld, Manfred A. and Pon, Raymond K. and Buttler, David J. and Jeusfeld, Manfred A. and Meng, Weiyi and Zezula, Pavel and Batko, Michal and Dohnal, Vlastislav and {Domingo-Ferrer}, Josep and {Domingo-Ferrer}, Josep and Barbosa, Denilson and Manolescu, Ioana and Xu Yu, Jeffrey and {Domingo-Ferrer}, Josep and Cecchet, Emmanuel and Qu{\'e}ma, Vivien and Yan, Xifeng and Wolfson, Ouri and Santucci, Giuseppe and {Zeinalipour-Yazti}, Demetrios and Chrysanthis, Panos K. and Quix, Christoph and Deshpande, Amol and Guestrin, Carlos and Madden, Sam and Leung, Carson Kai-Sang and G{\"u}ting, Ralf Hartmut and G{\"u}ting, Ralf Hartmut and Gupta, Amarnath and Pedersen, Torben Bach and Tao Shen, Heng and Weikum, Gerhard and Thuraisingham, Bhavani and Weikum, Gerhard and Jain, Ramesh and Yu, Jeffrey Xu and Ciaccia, Paolo and Candan, K. Selcuk and Sapino, Maria Luisa and Yu, Jeffrey Xu and Jain, Ramesh and Meghini, Carlo and Sebastiani, Fabrizio and Straccia, Umberto and Nack, Frank and Subrahmanian, V. S. and Martinez, Maria Vanina and Reforgiato, Dr. and Yu, Jeffrey Xu and Westerveld, Thijs and Sebillo, Monica and Vitiello, Giuliana and De Marsico, Maria and Voruganti, Kaladhar and Parent, Christine and Spaccapietra, Stefano and Vangenot, Christelle and Zim{\'a}nyi, Esteban and Roy, Prasan and Sudarshan, S. and Puppo, Enrico and Kr{\"o}ger, Peer and Renz, Matthias and Schuldt, Heiko and Kolahi, Solmaz and Unwin, Antony and Cellary, Wojciech},
  editor = {Liu, Ling and {\"O}zsu, M. Tamer},
  year = {2009},
  pages = {1724--1727},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-0-387-39940-9_907},
  url = {http://link.springer.com/10.1007/978-0-387-39940-9_907},
  urldate = {2020-03-28},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6BFITD6R/Caragea et al_2009_Metadata Registry, ISO-IEC 11179.pdf},
  isbn = {978-0-387-35544-3 978-0-387-39940-9},
  language = {en}
}

@misc{centersformedicaremedicaidservicesStatinTherapyPrevention2017,
  title = {Statin {{Therapy}} for the {{Prevention}} and {{Treatment}} of {{Cardiovascular Disease}}},
  author = {{Centers for Medicare \& Medicaid Services} and {Office of the National Coordinator for Health Information Technology}},
  year = {2017},
  month = oct,
  url = {https://ecqi.healthit.gov/ecqm/measures/cms347v1},
  urldate = {2018-03-03}
}

@article{chandranInferringDiseaseSeverity2019,
  title = {Inferring Disease Severity in Rheumatoid Arthritis Using Predictive Modeling in Administrative Claims Databases},
  author = {Chandran, Urmila and Reps, Jenna and Stang, Paul E. and Ryan, Patrick B.},
  editor = {Margiotta, Domenico Paolo Emanuele},
  year = {2019},
  month = dec,
  volume = {14},
  pages = {e0226255},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0226255},
  url = {https://dx.plos.org/10.1371/journal.pone.0226255},
  urldate = {2019-12-28},
  abstract = {Background OPEN ACCESS Citation: Chandran U, Reps J, Stang PE, Ryan PB (2019) Inferring disease severity in rheumatoid arthritis using predictive modeling in administrative claims databases. PLoS ONE 14(12): e0226255. https://doi.org/10.1371/journal.pone.0226255 Confounding by disease severity is an issue in pharmacoepidemiology studies of rheumatoid arthritis (RA), due to channeling of sicker patients to certain therapies. To address the issue of limited clinical data for confounder adjustment, a patient-level prediction model to differentiate between patients prescribed and not prescribed advanced therapies was developed as a surrogate for disease severity, using all available data from a US claims database. Editor: Domenico Paolo Emanuele Margiotta, Campus Bio-Medico University of Roma, ITALY Received: May 17, 2019 Accepted: November 22, 2019 Published: December 18, 2019 Copyright: \textcopyright{} 2019 Chandran et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Data Availability Statement: The source data for this study were licensed by Johnson \& Johnson from IBM MarketScan and Optum, and hence we are not allowed to share the licensed data publicly. However, the same data used in this study are available for purchase by contracting with the database owners, IBM MarketScan Research Databases (contact at: http://www.ibm.com/us-en/ marketplace/marketscan-research-databases) and Optum (contact at: http://www.optum.com/ solutions/data-analytics/data/real-world-dataanalytics-a-cpl/claims-data.html). The authors did not have any special access privileges that other
Methods Data from adult RA patients were used to build regularized logistic regression models to predict current and future disease severity using a biologic or tofacitinib prescription claim as a surrogate for moderate-to-severe disease. Model discrimination was assessed using the area under the receiver (AUC) operating characteristic curve, tested and trained in Optum Clinformatics\textregistered{} Extended DataMart (Optum) and additionally validated in three external IBM MarketScan\textregistered{} databases. The model was further validated in the Optum database across a range of patient cohorts.
Results In the Optum database (n = 68,608), the AUC for discriminating RA patients with a prescription claim for a biologic or tofacitinib versus those without in the 90 days following index diagnosis was 0.80. Model AUCs were 0.77 in IBM CCAE (n = 75,579) and IBM MDCD (n = 7,537) and 0.75 in IBM MDCR (n = 36,090). There was little change in the prediction model assessing discrimination 730 days following index diagnosis (prediction model AUC in Optum was 0.79).
Conclusions A prediction model demonstrated good discrimination across multiple claims databases to identify RA patients with a prescription claim for advanced therapies during different time-at-},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8TAENGGU/Chandran et al_2019_Inferring disease severity in rheumatoid arthritis using predictive modeling in.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {12}
}

@article{cholanSpecificationsClinicalQuality2018,
  title = {Specifications of {{Clinical Quality Measures}} and {{Value Set Vocabularies Shift Over Time}}: {{A Study}} of {{Change}} through {{Implementation Differences}}},
  shorttitle = {Specifications of {{Clinical Quality Measures}} and {{Value Set Vocabularies Shift Over Time}}},
  author = {Cholan, Raja A. and Weiskopf, Nicole G. and Rhoton, Douglas L. and Colin, Nicholas V. and Ross, Rachel L. and Marzullo, Melanie N. and Sachdeva, Bhavaya and Dorr, David A.},
  year = {2018},
  month = apr,
  volume = {2017},
  pages = {575--584},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5977609/},
  urldate = {2020-05-13},
  abstract = {Clinical quality measures (CQMs) aim to identify gaps in care and to promote evidence-based guidelines. Official CQM definitions consist of a measure's logic and grouped, standardized codes to define key concepts. In this study, we used the official CQM update process to understand how CQMs' meanings change over time. First, we identified differences between the narrative description, logic, and the vocabulary specifications offour standardized CQMs' definitions in subsequent versions (2015, 2016, and 2017). Next, we implemented the various versions in a quality measure calculation registry to understand how the differences affected calculated prevalence of risk and measure performance. Global performance rates changed up to 5.32\%, and an increase of up to 28\% new patients was observed for key conditions between versions. Updates to definitions that change a measure's logic and choices to include/exclude codes in value set vocabularies changes measurement of quality and likely introduces variation by implementation.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/B4BYR2KF/Cholan et al_2018_Specifications of Clinical Quality Measures and Value Set Vocabularies Shift.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC5977609},
  pmid = {29854122}
}

@misc{christensen2000iso,
  title = {{{ISO}}/{{IEC CD}} 11179-3 {{Information}} Technology - {{Data Management}} and {{Interchange}} - {{Metadata Registries}} ({{MDR}}) - {{Part}} 3: {{Registry Metamodel}} ({{MDR3}})},
  author = {Christensen, Joe},
  year = {2000},
  url = {http://www.jtc1sc32.org/doc/N0451-0500/32N0490T.doc},
  urldate = {2020-05-27},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6V48IU2X/Christensen_2000_ISO-IEC JTC 0490.doc}
}

@article{chuteClinicalClassificationTerminology2000,
  title = {Clinical {{Classification}} and {{Terminology}}: {{Some History}} and {{Current Observations}}},
  shorttitle = {Clinical {{Classification}} and {{Terminology}}},
  author = {Chute, C. G.},
  year = {2000},
  month = may,
  volume = {7},
  pages = {298--303},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/jamia.2000.0070298},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/jamia.2000.0070298},
  urldate = {2020-02-07},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BGGNGMJW/Chute_2000_Clinical Classification and Terminology.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {3}
}

@article{chuteCopernicanEraHealthcare1998,
  title = {The {{Copernican}} Era of Healthcare Terminology: A Re-Centering of Health Information Systems},
  author = {Chute, C G},
  year = {1998},
  pages = {68--73},
  issn = {1531-605X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/9929184},
  abstract = {Health terminology and classifications have been an unseen backwater in healthcare practice and information systems development. Today however, the recognized need for comparable patient data is driving a new discovery about its strategic importance. Consistent patient descriptions and concept-centered data representations are crucial for efficient discovery of optimal treatments, best outcomes, and efficient practice patterns. The fabled linkage of knowledge sources at the time and place of care requires the conceptual intermediary of common terminology. A brief history overviewing the evolution of health classifications will provide the foundation for considering present and evolving health terminology developments. Their roles in health information systems will be characterized. Discussion will focus on the likely influences of the HIPAA legislation nationally and the new ISO Healthcare Informatics Technical Committee internationally, on terminology adaptation and incorporation.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/TEYF93JU/Chute_1998_The Copernican era of healthcare terminology.pdf},
  journal = {Proceedings. AMIA Symposium},
  keywords = {*Terminology as Topic,*Vocabulary; Controlled,Disease/classification,History; 16th Century,History; 18th Century,History; 19th Century,History; 20th Century,Humans},
  language = {eng}
}

@article{chuteDesiderataClinicalTerminology1999,
  title = {Desiderata for a Clinical Terminology Server},
  author = {Chute, C G and Elkin, P L and Sherertz, D D and Tuttle, M S},
  year = {1999},
  pages = {42--46},
  issn = {1531-605X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/10566317},
  abstract = {Clinical terminology servers are distinguished from more broadly based
terminology servers intended for nomenclature development or mediation
across classifications. Focusing upon the consistent and comparable entry
of clinical observations, findings, and events, key desiderata are
enumerated and expanded. These include 1) word normalization, 2) word
completion, 3) target terminology specification, 4) spelling correction,
5) lexical matching, 6) term completion, 7) semantic locality, 8) term
composition and 9) decomposition. Comparisons of this functionality to
previously published models and specifications are made. Experience with a
clinical terminology server, Metaphrase, is described.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/LFX3LGN5/Chute et al_1999_Desiderata for a clinical terminology server.pdf},
  journal = {Proc. AMIA Symp.},
  keywords = {Active papers/AMIA VS,Active papers/IEEE Vis 2018}
}

@article{ciminoConsistencyHierarchiesUMLS2003,
  title = {Consistency across the Hierarchies of the {{UMLS Semantic Network}} and {{Metathesaurus}}},
  author = {Cimino, J J and Min, H and Perl, Y},
  year = {2003},
  month = dec,
  volume = {36},
  pages = {450--461},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2003.11.001},
  url = {http://dx.doi.org/10.1016/j.jbi.2003.11.001},
  abstract = {OBJECTIVE: To develop and test a method for automatically detecting
inconsistencies between the parent-child is-a relationships in the
Metathesaurus and the ancestor-descendant relationships in the Semantic
Network of the Unified Medical Language System (UMLS). METHODS: We
exploited the fact that each Metathesaurus concept is assigned one or more
semantic types from the UMLS Semantic Network and that the semantic types
are arranged in a hierarchy. We compared the semantic types of each pair
of parent and child concepts to determine if the types "explained" the
Metathesaurus is-a relationships. We considered cases where the semantic
type of the parent was neither the same as, nor an ancestor of, the
semantic type of the child to be "unexplained." We applied this method to
the January 2002 release of the UMLS and examined the unexplained cases we
discovered to determine their causes. RESULTS: We found that 17022 (24.3\%)
of the parent-child is-a relationships in the UMLS Metathesaurus could not
be explained based on the semantic types of the concepts. Causes for these
discrepancies included cases where the parent or child was missing a
semantic type, cases where the semantic type of the child was too general
or the semantic type of the parent was too specific, cases where the
parent-child relationship was incorrect, and cases where an
ancestor-descendant relationship should be added to the UMLS Semantic
network. In many cases, the specific cause of the discrepancy cannot be
resolved without authoritative judgment by the UMLS developers.
CONCLUSIONS: Our method successfully detects inconsistencies between the
hierarchies of the UMLS Metathesaurus and Semantic Network. We believe
that our method should be added to the set of tools that the UMLS
developers use to maintain and audit the UMLS knowledge sources.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/AUUZA9M2/Cimino et al_2003_Consistency across the hierarchies of the UMLS Semantic Network and.pdf},
  journal = {J. Biomed. Inform.},
  number = {6}
}

@article{ciminoControlledVocabulariesIndexing1989,
  title = {Controlled {{Vocabularies}}, {{Indexing}} and {{Medical Language Processing}}. {{Controlled Vocabularies}}: {{Designing}} an {{Introspective}}, {{Multipurpose}}, {{Controlled Medical Vocabulary}}},
  author = {Cimino, J J and Hripcsak, G and Johnson, S B and Clayton, P D},
  year = {1989},
  month = nov,
  pages = {513--518},
  issn = {0195-4210},
  url = {http://europepmc.org/abstract/PMC/pmc2245774},
  urldate = {2017-11-21},
  abstract = {The medical vocabulary used in clinical information systems must be more
than a simple list of terms. We argue that such a vocabulary must have
synonymy, domain completeness and multiple classifications, providing
consistent views and explicit relationships, while remaining unambiguous
and non-redundant. We examine the abilities of existing controlled
vocabularies (ICD9-CM, SNOMED, MeSH, CMIT, CPT4, COSTAR, HELP, DXPLAIN,
and UMLS) to meet these goals and propose an enhanced vocabulary structure
based on a directed, acyclic semantic net. This structure provides a
representation which permits introspection by the vocabulary maintenance
system responsible for providing a terminology which meets our seven
requirements. The vocabulary, which we refer to as the Medical Entities
Dictionary, will serve a variety of applications.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/Y9RH5IMR/Cimino et al_1989_Controlled Vocabularies, Indexing and Medical Language Processing.pdf},
  journal = {Proc. Annu. Symp. Comput. Appl. Med. Care},
  keywords = {Topics/Viz/vocab-viz}
}

@article{ciminoDataKnowledgeConceptoriented2000,
  title = {From Data to Knowledge through Concept-Oriented Terminologies: Experience with the {{Medical Entities Dictionary}}},
  author = {Cimino, J J},
  year = {2000},
  month = may,
  volume = {7},
  pages = {288--297},
  issn = {1067-5027},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/10833166},
  abstract = {Knowledge representation involves enumeration of conceptual symbols and
arrangement of these symbols into some meaningful structure. Medical
knowledge representation has traditionally focused more on the structure
than the symbols. Several significant efforts are under way, at local,
national, and international levels, to address the representation of the
symbols though the creation of high-quality terminologies that are
themselves knowledge based. This paper reviews these efforts, including
the Medical Entities Dictionary (MED) in use at Columbia University and
the New York Presbyterian Hospital. A decade's experience with the MED is
summarized to serve as a proof-of-concept that knowledge-based
terminologies can support the use of coded patient data for a variety of
knowledge-based activities, including the improved understanding of
patient data, the access of information sources relevant to specific
patient care problems, the application of expert systems directly to the
care of patients, and the discovery of new medical knowledge. The
terminological knowledge in the MED has also been used successfully to
support clinical application development and maintenance, including that
of the MED itself. On the basis of this experience, current efforts to
create standard knowledge-based terminologies appear to be justified.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4K6DJHXT/Cimino_2000_From data to knowledge through concept-oriented terminologies.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS},
  number = {3}
}

@article{ciminoDefenseDesiderata2006,
  title = {In Defense of the {{Desiderata}}},
  author = {Cimino, James J},
  year = {2006},
  month = jun,
  volume = {39},
  pages = {299--306},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2005.11.008},
  url = {http://dx.doi.org/10.1016/j.jbi.2005.11.008},
  abstract = {A 1998 paper that delineated desirable characteristics, or desiderata for
controlled medical terminologies attempted to summarize emerging consensus
regarding structural issues of such terminologies. Among the Desiderata
was a call for terminologies to be "concept oriented." Since then,
research has trended toward the extension of terminologies into
ontologies. A paper by Smith, entitled "From Concepts to Clinical Reality:
An Essay on the Benchmarking of Biomedical Terminologies" urges a realist
approach that seeks terminologies composed of universals, rather than
concepts. The current paper addresses issues raised by Smith and attempts
to extend the Desiderata, not away from concepts, but towards recognition
that concepts and universals must both be embraced and can coexist
peaceably in controlled terminologies. To that end, additional Desiderata
are defined that deal with the purpose, rather than the structure, of
controlled medical terminologies.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7TPWQZ7V/Cimino_2006_In defense of the Desiderata.pdf},
  journal = {J. Biomed. Inform.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Informatics/med recs / cdms,ISchool/INST888-Butler/Leading INST888,Topics/Viz/vocab-viz},
  number = {3}
}

@article{ciminoDesiderataControlledMedical1998,
  title = {Desiderata for Controlled Medical Vocabularies in the Twenty-First Century},
  author = {Cimino, JJ},
  year = {1998},
  volume = {37},
  pages = {394--403},
  issn = {0026-1270},
  abstract = {Builders of medical informatics applications need controlled medical vocabularies to support their applications and it is to their advantage to use available standards. In order to do so, however, these standards need to address the requirements of their intended users. Over the past decade, medical informatics researchers have begun to articulate some of these requirements. This paper brings together some of the common themes which have been described, including: vocabulary content, concept orientation, concept permanence, nonsemantic concept identifiers, polyhierarchy, formal definitions, rejection of "not elsewhere classified" terms, multiple granularities, multiple consistent views, context representation, graceful evolution, and recognized redundancy. Standards developers are beginning to recognize and address these desiderata and adapt their offerings to meet them.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/QDX3WFJT/Cimino JJ_1998_Desiderata for controlled medical vocabularies in the twenty-first century.pdf},
  journal = {Methods Inf. Med.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Informatics/med recs / cdms,ISchool/INST888-Butler/Leading INST888,Topics/Viz/vocab-viz,Topics/Viz/Vocabs,Zotero Import (Oct 26)},
  number = {4-5}
}

@article{ciminoKnowledgebasedApproachesMaintenance1994,
  title = {Knowledge-Based Approaches to the Maintenance of a Large Controlled Medical Terminology},
  author = {Cimino, J J and Clayton, P D and Hripcsak, G and Johnson, S B},
  year = {1994},
  month = jan,
  volume = {1},
  pages = {35--50},
  issn = {1067-5027},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/7719786},
  abstract = {OBJECTIVE: Develop a knowledge-based representation for a controlled
terminology of clinical information to facilitate creation, maintenance,
and use of the terminology. DESIGN: The Medical Entities Dictionary (MED)
is a semantic network, based on the Unified Medical Language System
(UMLS), with a directed acyclic graph to represent multiple hierarchies.
Terms from four hospital systems (laboratory, electrocardiography, medical
records coding, and pharmacy) were added as nodes in the network.
Additional knowledge about terms, added as semantic links, was used to
assist in integration, harmonization, and automated classification of
disparate terminologies. RESULTS: The MED contains 32,767 terms and is in
active clinical use. Automated classification was successfully applied to
terms for laboratory specimens, laboratory tests, and medications. One
benefit of the approach has been the automated inclusion of medications
into multiple pharmacologic and allergenic classes that were not present
in the pharmacy system. Another benefit has been the reduction of
maintenance efforts by 90\%. CONCLUSION: The MED is a hybrid of terminology
and knowledge. It provides domain coverage, synonymy, consistency of
views, explicit relationships, and multiple classification while
preventing redundancy, ambiguity (homonymy) and misclassification.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PQB5RALV/Cimino et al_1994_Knowledge-based approaches to the maintenance of a large controlled medical.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  number = {1}
}

@misc{ClinicalVocabulariesEssential,
  title = {Clinical {{Vocabularies}}: {{Essential}} to the {{Future}} of {{Health Information Management}}},
  url = {https://library.ahima.org/doc?oid=59636\#.Xj1cJWhKjup},
  urldate = {2020-02-07},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7TRBC7SK/doc.html}
}

@article{cocchiarellaNominalismConceptualismPredicative1980,
  title = {Nominalism and Conceptualism as Predicative Second-Order Theories of Predication.},
  author = {Cocchiarella, Nino},
  year = {1980},
  volume = {21},
  pages = {481--500},
  publisher = {{University of Notre Dame}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/U5WERLX7/Cocchiarella_1980_Nominalism and conceptualism as predicative second-order theories of predication.pdf},
  journal = {Notre Dame Journal of Formal Logic},
  number = {3}
}

@incollection{collinsrossettiReengineeringApproachesLearning2019,
  title = {Reengineering {{Approaches}} for {{Learning Health Systems}}: {{Applications}} in {{Nursing Research}} to {{Learn}} from {{Safety Information Gaps}} and {{Workarounds}} to {{Overcome Electronic Health Record Silos}}},
  shorttitle = {Reengineering {{Approaches}} for {{Learning Health Systems}}},
  booktitle = {Cognitive {{Informatics}}: {{Reengineering Clinical Workflow}} for {{Safer}} and {{More Efficient Care}}},
  author = {Collins Rossetti, Sarah and Yen, Po-Yin and Dykes, Patricia C. and Schnock, Kumiko and Cato, Kenrick},
  editor = {Zheng, Kai and Westbrook, Johanna and Kannampallil, Thomas G. and Patel, Vimla L.},
  year = {2019},
  pages = {115--148},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-16916-9_8},
  url = {https://doi.org/10.1007/978-3-030-16916-9_8},
  urldate = {2020-01-28},
  abstract = {Health systems engineering is an approach to effectively implement a learning health system to drive more efficient and safer care by adapting and aligning individual structures (e.g., applications) and processes (e.g., workflows) to optimize outcomes within a ``system of systems''. Nurses have been described as particularly adept at identifying and utilizing workarounds to overcome poor system design. Workflows and workarounds are not limited to directly observable patient care activities; they also occur within documentation activities and can be modeled using metadata (data about data) from clinical information systems. This chapter will outline 3 broad approaches that can be triangulated within a systems engineering framework to reengineer nursing and patient care workflows and overcome information silos by actively learning from safety information gaps and workarounds within a health system: (1) ``In the lab'' participatory design and usability evaluation, (2) ``In the wild'' observations, and (3) ``In the metadata'' models of health care processes. Systems engineering methods can be applied to a broad range of healthcare processes to model workflow, data and information flow to support the development, integration, and optimization of health IT applications leveraging a 5-phase approach: problem analysis, design, development, implementation, and evaluation. In this chapter we present use cases of pragmatic applications grounded in theoretical and methodological approaches within a systems engineering framework that demonstrate the iterative nature of health IT evaluation. This chapter highlights the complexity of nursing and patient care workflows and the fact that even well-designed systems that adequately address socio-technical dimensions as part of the development process, require continued attention to workflow during and after implementation. Post-implementation attention to end-users' concerns and feedback provides an opportunity for system optimization. Secondary analysis of EHR data after implementation can provide important clues about alignment with documentation workflows, effective information flow, and accurate data interpretation. These activities are needed to achieve a learning health care system and can be achieved if nursing domain experts work closely with data science experts throughout the system lifecycle to contextualize clinical analyses and help to successfully convert data into knowledge.},
  isbn = {978-3-030-16916-9},
  keywords = {EHR metadata,Health systems engineering,Learning healthcare system,Nursing documentation,Nursing practice,Observations,Usability evaluation,Workarounds,Workflow},
  language = {en},
  series = {Health {{Informatics}}}
}

@article{colomaCombiningElectronicHealthcare2011,
  title = {Combining Electronic Healthcare Databases in {{Europe}} to Allow for Large-Scale Drug Safety Monitoring: The {{EU}}-{{ADR Project}}},
  shorttitle = {Combining Electronic Healthcare Databases in {{Europe}} to Allow for Large-Scale Drug Safety Monitoring},
  author = {Coloma, Preciosa M. and Schuemie, Martijn J. and Trifir{\`o}, Gianluca and Gini, Rosa and Herings, Ron and {Hippisley-Cox}, Julia and Mazzaglia, Giampiero and Giaquinto, Carlo and Corrao, Giovanni and Pedersen, Lars and {van der Lei}, Johan and Sturkenboom, Miriam and {on behalf of the EU-ADR consortium}},
  year = {2011},
  month = jan,
  volume = {20},
  pages = {1--11},
  issn = {10538569},
  doi = {10.1002/pds.2053},
  url = {http://doi.wiley.com/10.1002/pds.2053},
  urldate = {2020-04-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/U88MT9DB/Coloma et al_2011_Combining electronic healthcare databases in Europe to allow for large-scale.pdf},
  journal = {Pharmacoepidemiology and Drug Safety},
  language = {en},
  number = {1}
}

@inproceedings{conlenIdyllMarkupLanguage2018,
  title = {Idyll: {{A Markup Language}} for {{Authoring}} and {{Publishing Interactive Articles}} on the {{Web}}},
  shorttitle = {Idyll},
  booktitle = {Proceedings of the 31st {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Conlen, Matthew and Heer, Jeffrey},
  year = {2018},
  month = oct,
  pages = {977--989},
  publisher = {{Association for Computing Machinery}},
  address = {{Berlin, Germany}},
  doi = {10.1145/3242587.3242600},
  url = {http://doi.org/10.1145/3242587.3242600},
  urldate = {2020-03-06},
  abstract = {The web has matured as a publishing platform: news outlets regularly publish rich, interactive stories while technical writers use animation and interaction to communicate complex ideas. This style of interactive media has the potential to engage a large audience and more clearly explain concepts, but is expensive and time consuming to produce. Drawing on industry experience and interviews with domain experts, we contribute design tools to make it easier to author and publish interactive articles. We introduce Idyll, a novel "compile-to-the-web" language for web-based interactive narratives. Idyll implements a flexible article model, allowing authors control over document style and layout, reader-driven events (such as button clicks and scroll triggers), and a structured interface to JavaScript components. Through both examples and first-use results from undergraduate computer science students, we show how Idyll reduces the amount of effort and custom code required to create interactive articles.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BU9NISEH/Conlen_Heer_2018_Idyll.pdf},
  isbn = {978-1-4503-5948-1},
  keywords = {artifact or system,interactiondesign,programming languages,programming/development support,prototyping/implementation,storytelling,visualization},
  series = {{{UIST}} '18}
}

@article{conwayAnalyzingHeterogeneityComplexity2011,
  title = {Analyzing the Heterogeneity and Complexity of {{Electronic Health Record}} Oriented Phenotyping Algorithms},
  author = {Conway, Mike and Berg, Richard L. and Carrell, David and Denny, Joshua C. and Kho, Abel N. and Kullo, Iftikhar J. and Linneman, James G. and Pacheco, Jennifer A. and Peissig, Peggy and Rasmussen, Luke and Weston, Noah and Chute, Christopher G. and Pathak, Jyotishman},
  year = {2011},
  volume = {2011},
  pages = {274--283},
  issn = {1942-597X},
  abstract = {The need for formal representations of eligibility criteria for clinical trials - and for phenotyping more generally - has been recognized for some time. Indeed, the availability of a formal computable representation that adequately reflects the types of data and logic evidenced in trial designs is a prerequisite for the automatic identification of study-eligible patients from Electronic Health Records. As part of the wider process of representation development, this paper reports on an analysis of fourteen Electronic Health Record oriented phenotyping algorithms (developed as part of the eMERGE project) in terms of their constituent data elements, types of logic used and temporal characteristics. We discovered that the majority of eMERGE algorithms analyzed include complex, nested boolean logic and negation, with several dependent on cardinality constraints and complex temporal logic. Insights gained from the study will be used to augment the CDISC Protocol Representation Model.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/QMYQDX5B/Conway et al_2011_Analyzing the heterogeneity and complexity of Electronic Health Record oriented.pdf},
  journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
  keywords = {Algorithms,Diagnosis; Differential,Electronic Health Records,Hashimoto Disease,Humans,Hypothyroidism,Phenotype},
  language = {eng},
  pmcid = {PMC3243189},
  pmid = {22195079}
}

@book{corbinBasicsQualitativeResearch2008,
  title = {Basics of {{Qualitative Research}} (3rd Ed.): {{Techniques}} and {{Procedures}} for {{Developing Grounded Theory}}},
  shorttitle = {Basics of {{Qualitative Research}} (3rd Ed.)},
  author = {Corbin, Juliet and Strauss, Anselm},
  year = {2008},
  publisher = {{SAGE Publications, Inc.}},
  address = {{2455 Teller Road,~Thousand Oaks~California~91320~United States}},
  doi = {10.4135/9781452230153},
  url = {http://methods.sagepub.com/book/basics-of-qualitative-research},
  urldate = {2020-03-06},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/5LXV3KMH/Corbin_Strauss_2008_Basics of Qualitative Research (3rd ed.pdf},
  isbn = {978-1-4129-0644-9 978-1-4522-3015-3},
  language = {en}
}

@article{cornetHealthConceptKnowledge2016,
  title = {Health {{Concept}} and {{Knowledge Management}}: {{Twenty}}-Five {{Years}} of {{Evolution}}},
  shorttitle = {Health {{Concept}} and {{Knowledge Management}}},
  author = {Cornet, R. and Chute, C. G.},
  year = {2016},
  volume = {25},
  pages = {S32-S41},
  publisher = {{Georg Thieme Verlag KG}},
  issn = {0943-4747, 2364-0502},
  doi = {10.15265/IYS-2016-s037},
  url = {http://www.thieme.connect.de/DOI/DOI?10.15265/IYS-2016-s037},
  urldate = {2020-03-25},
  abstract = {Objectives: The fields of health terminology, classification, ontology, and related information models have evolved dramatically over the past 25 years. Our objective was to review notable trends, described emerging or enabling technologies, and highlight major terminology systems during the interval.

  Methods: We review the progression in health terminology systems informed by our own experiences as part of the community involved in this work, reinforced with literature review and citation.

  Results: The transformation in size, scope, complexity, and adoption of health terminological systems and information models has been tremendous, on the scale of orders of magnitude.

  Conclusion: The present ``big science'' era of inference and discovery in biomedicine would not have been possible or scalable absent the growth and maturation of health terminology systems and information models over the past 25 years.},
  copyright = {Georg Thieme Verlag KG Stuttgart},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/9BJBV5DY/Cornet_Chute_2016_Health Concept and Knowledge Management.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/PPRRGZL8/IYS-2016-s037.html},
  journal = {Yearbook of Medical Informatics},
  language = {en},
  number = {S 01}
}

@article{corrigan-curayRealWorldEvidenceRealWorld2018,
  title = {Real-{{World Evidence}} and {{Real}}-{{World Data}} for {{Evaluating Drug Safety}} and {{Effectiveness}}},
  author = {{Corrigan-Curay}, Jacqueline and Sacks, Leonard and Woodcock, Janet},
  year = {2018},
  month = sep,
  volume = {320},
  pages = {867--868},
  issn = {0098-7484},
  doi = {10.1001/jama.2018.10136},
  url = {https://jamanetwork.com/journals/jama/fullarticle/2697359},
  urldate = {2019-09-16},
  abstract = {In this Viewpoint, Janet Woodcock and CDER colleagues discuss recent FDA initiatives to investigate the adequacy of~electronic health record (EHR) and patient database data for research purposes and to understand if and how real-world observational data might be analyzed in ways that mimic or can be...},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/MZVWKYXJ/Corrigan-Curay et al_2018_Real-World Evidence and Real-World Data for Evaluating Drug Safety and.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/7BPSUS8M/2697359.html},
  journal = {JAMA},
  language = {en},
  number = {9}
}

@inproceedings{Cross2000,
  title = {Contextual Inquiry: {{Quantification}} and Use in Videotaped Analysis},
  booktitle = {Extended Abstracts of the {{ACM}} Conference on Human Factors in Computing Systems},
  author = {Cross, Karen and Warmack, Adrienne},
  year = {2000},
  pages = {317--318},
  publisher = {{ACM}},
  address = {{New York, NY, USA}}
}

@article{curtisDesignConsiderationsArchitecture2012,
  title = {Design Considerations, Architecture, and Use of the {{Mini}}-{{Sentinel}} Distributed Data System},
  author = {Curtis, Lesley H and Weiner, Mark G and Boudreau, Denise M and Cooper, William O and Daniel, Gregory W and Nair, Vinit P and Raebel, Marsha A and Beaulieu, Nicolas U and Rosofsky, Robert and Woodworth, Tiffany S and Brown, Jeffrey S},
  year = {2012},
  month = jan,
  volume = {21 Suppl 1},
  pages = {23--31},
  issn = {1053-8569},
  doi = {10.1002/pds.2336},
  url = {http://dx.doi.org/10.1002/pds.2336},
  abstract = {PURPOSE: We describe the design, implementation, and use of a large,
multiorganizational distributed database developed to support the
Mini-Sentinel Pilot Program of the US Food and Drug Administration (FDA).
As envisioned by the US FDA, this implementation will inform and
facilitate the development of an active surveillance system for monitoring
the safety of medical products (drugs, biologics, and devices) in the USA.
METHODS: A common data model was designed to address the priorities of the
Mini-Sentinel Pilot and to leverage the experience and data of
participating organizations and data partners. A review of existing common
data models informed the process. Each participating organization designed
a process to extract, transform, and load its source data, applying the
common data model to create the Mini-Sentinel Distributed Database.
Transformed data were characterized and evaluated using a series of
programs developed centrally and executed locally by participating
organizations. A secure communications portal was designed to facilitate
queries of the Mini-Sentinel Distributed Database and transfer of
confidential data, analytic tools were developed to facilitate rapid
response to common questions, and distributed querying software was
implemented to facilitate rapid querying of summary data. RESULTS: As of
July 2011, information on 99,260,976 health plan members was included in
the Mini-Sentinel Distributed Database. The database includes 316,009,067
person-years of observation time, with members contributing, on average,
27.0 months of observation time. All data partners have successfully
executed distributed code and returned findings to the Mini-Sentinel
Operations Center. CONCLUSION: This work demonstrates the feasibility of
building a large, multiorganizational distributed data system in which
organizations retain possession of their data that are used in an active
surveillance system.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/D62A3TMJ/Curtis et al_2012_Design considerations, architecture, and use of the Mini-Sentinel distributed.pdf},
  journal = {Pharmacoepidemiol. Drug Saf.},
  keywords = {Active papers/AMIA VS,Informatics/med recs / cdms}
}

@article{defalcoApplyingStandardizedDrug2013,
  title = {Applying Standardized Drug Terminologies to Observational Healthcare Databases: A Case Study on Opioid Exposure},
  author = {DeFalco, Frank J and Ryan, Patrick B and Soledad Cepeda, M},
  year = {2013},
  month = mar,
  volume = {13},
  pages = {58--67},
  issn = {1387-3741},
  doi = {10.1007/s10742-012-0102-1},
  url = {https://doi.org/10.1007/s10742-012-0102-1},
  abstract = {Observational healthcare databases represent a valuable resource for
health economics, outcomes research, quality of care, drug safety,
epidemiology and comparative effectiveness research. The methods used to
identify a population for study in an observational healthcare database
with the desired drug exposures of interest are complex and not consistent
nor apparent in the published literature. Our research evaluates three
drug classification systems and their impact on prevalence in the analysis
of observational healthcare databases using opioids as a case in point.
The standard terminologies compiled in the Observational Medical Outcomes
Partnership's Common Data Model vocabulary were used to facilitate the
identification of populations with opioid exposures. This study analyzed
three distinct observational healthcare databases and identified patients
with at least one exposure to an opioid as defined by drug codes derived
through the application of three classification systems. Opioid code sets
were created for each of the three classification systems and the number
of identified codes was summarized. We estimated the prevalence of opioid
exposure in three observational healthcare databases using the three
defined code sets. In addition we compared the number of drug codes and
distinct ingredients that were identified using these classification
systems. We found substantial variation in the prevalence of opioid
exposure identified using an individual classification system versus a
composite method using multiple classification systems. To ensure
transparent and reproducible research publications should include a
description of the process used to develop code sets and the complete code
set used in studies.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/NB7T34A2/DeFalco et al_2013_Applying standardized drug terminologies to observational healthcare databases.pdf},
  journal = {Health Serv. Outcomes Res. Methodol.},
  number = {1}
}

@article{dennyChapter13Mining2012,
  title = {Chapter 13: {{Mining}} Electronic Health Records in the Genomics Era},
  shorttitle = {Chapter 13},
  author = {Denny, Joshua C.},
  year = {2012},
  volume = {8},
  pages = {e1002823},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002823},
  abstract = {The combination of improved genomic analysis methods, decreasing genotyping costs, and increasing computing resources has led to an explosion of clinical genomic knowledge in the last decade. Similarly, healthcare systems are increasingly adopting robust electronic health record (EHR) systems that not only can improve health care, but also contain a vast repository of disease and treatment data that could be mined for genomic research. Indeed, institutions are creating EHR-linked DNA biobanks to enable genomic and pharmacogenomic research, using EHR data for phenotypic information. However, EHRs are designed primarily for clinical care, not research, so reuse of clinical EHR data for research purposes can be challenging. Difficulties in use of EHR data include: data availability, missing data, incorrect data, and vast quantities of unstructured narrative text data. Structured information includes billing codes, most laboratory reports, and other variables such as physiologic measurements and demographic information. Significant information, however, remains locked within EHR narrative text documents, including clinical notes and certain categories of test results, such as pathology and radiology reports. For relatively rare observations, combinations of simple free-text searches and billing codes may prove adequate when followed by manual chart review. However, to extract the large cohorts necessary for genome-wide association studies, natural language processing methods to process narrative text data may be needed. Combinations of structured and unstructured textual data can be mined to generate high-validity collections of cases and controls for a given condition. Once high-quality cases and controls are identified, EHR-derived cases can be used for genomic discovery and validation. Since EHR data includes a broad sampling of clinically-relevant phenotypic information, it may enable multiple genomic investigations upon a single set of genotyped individuals. This chapter reviews several examples of phenotype extraction and their application to genetic research, demonstrating a viable future for genomic discovery using EHR-linked data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/UQGBSIQ9/Denny_2012_Chapter 13.pdf},
  journal = {PLoS computational biology},
  keywords = {Continental Population Groups,Drug Therapy,Ethnic Groups,Genome; Human,Humans,Information Storage and Retrieval,Medical Records Systems; Computerized,Phenotype},
  language = {eng},
  number = {12},
  pmcid = {PMC3531280},
  pmid = {23300414}
}

@article{ellisFrameworkProblemBasedResearch2008,
  title = {Towards a Guide for Novice Researchers on Research Methodology: {{Review}} and Proposed Methods.},
  author = {Ellis, Timothy J and Levy, Yair},
  year = {2009},
  volume = {6},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/DS7T8ZBH/Ellis_Levy_2009_Towards a guide for novice researchers on research methodology.pdf},
  journal = {Issues in Informing Science \& Information Technology}
}

@article{embiClinicalResearchInformatics2009,
  title = {Clinical {{Research Informatics}}: {{Challenges}}, {{Opportunities}} and {{Definition}} for an {{Emerging Domain}}},
  shorttitle = {Clinical {{Research Informatics}}},
  author = {Embi, P. J. and Payne, P. R. O.},
  year = {2009},
  month = may,
  volume = {16},
  pages = {316--327},
  issn = {1067-5027, 1527-974X},
  doi = {10.1197/jamia.M3005},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1197/jamia.M3005},
  urldate = {2020-04-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/WDIK5NT3/Embi_Payne_2009_Clinical Research Informatics.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {3}
}

@misc{EMISWebUnderstanding,
  title = {{{EMIS Web}} - {{Understanding}} Code Hierarchies},
  url = {https://www.emisnow.com/csm?id=kb_article_view\&sys_kb_id=9bb5f8031bf07b008ceaa64c2e4bcb54},
  urldate = {2020-02-11},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/D9Q6NW3P/csm.html}
}

@article{ennisImpactPatientInvolvement2013,
  title = {Impact of Patient Involvement in Mental Health Research: Longitudinal Study},
  shorttitle = {Impact of Patient Involvement in Mental Health Research},
  author = {Ennis, Liam and Wykes, Til},
  year = {2013},
  month = nov,
  volume = {203},
  pages = {381--386},
  issn = {0007-1250, 1472-1465},
  doi = {10.1192/bjp.bp.112.119818},
  url = {https://www.cambridge.org/core/product/identifier/S0007125000053642/type/journal_article},
  urldate = {2020-06-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/DRT4MRZX/Ennis_Wykes_2013_Impact of patient involvement in mental health research.pdf},
  journal = {British Journal of Psychiatry},
  language = {en},
  number = {5}
}

@incollection{fecherOpenScienceOne2014,
  title = {Open {{Science}}: {{One Term}}, {{Five Schools}} of {{Thought}}},
  shorttitle = {Open {{Science}}},
  booktitle = {Opening {{Science}}: {{The Evolving Guide}} on {{How}} the {{Internet}} Is {{Changing Research}}, {{Collaboration}} and {{Scholarly Publishing}}},
  author = {Fecher, Benedikt and Friesike, Sascha},
  editor = {Bartling, S{\"o}nke and Friesike, Sascha},
  year = {2014},
  pages = {17--47},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-00026-8_2},
  url = {https://doi.org/10.1007/978-3-319-00026-8_2},
  urldate = {2020-02-27},
  abstract = {Open Science is an umbrella term encompassing a multitude of assumptions about the future of knowledge creation and dissemination. Based on a literature review, this chapter aims at structuring the overall discourse by proposing five Open Science schools of thought: The infrastructure school (which is concerned with the technological architecture), the public school (which is concerned with the accessibility of knowledge creation), the measurement school (which is concerned with alternative impact measurement), the democratic school (which is concerned with access to knowledge) and the pragmatic school (which is concerned with collaborative research).},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/JWRM7FZI/Fecher_Friesike_2014_Open Science.pdf},
  isbn = {978-3-319-00026-8},
  keywords = {Citizen Science,Knowledge Creation,Open Access Journal,Scientific Impact,Scientific Practice},
  language = {en}
}

@article{fitzhenryCreatingCommonData2015,
  title = {Creating a {{Common Data Model}} for {{Comparative Effectiveness}} with the {{Observational Medical Outcomes Partnership}}},
  author = {FitzHenry, F and Resnic, F S and Robbins, S L and Denton, J and Nookala, L and Meeker, D and {Ohno-Machado}, L and Matheny, M E},
  year = {2015},
  month = aug,
  volume = {6},
  pages = {536--547},
  issn = {1869-0327},
  doi = {10.4338/ACI-2014-12-CR-0121},
  url = {http://dx.doi.org/10.4338/ACI-2014-12-CR-0121},
  abstract = {BACKGROUND: Adoption of a common data model across health systems is a key
infrastructure requirement to allow large scale distributed comparative
effectiveness analyses. There are a growing number of common data models
(CDM), such as Mini-Sentinel, and the Observational Medical Outcomes
Partnership (OMOP) CDMs. OBJECTIVES: In this case study, we describe the
challenges and opportunities of a study specific use of the OMOP CDM by
two health systems and describe three comparative effectiveness use cases
developed from the CDM. METHODS: The project transformed two health system
databases (using crosswalks provided) into the OMOP CDM. Cohorts were
developed from the transformed CDMs for three comparative effectiveness
use case examples. Administrative/billing, demographic, order history,
medication, and laboratory were included in the CDM transformation and
cohort development rules. RESULTS: Record counts per person month are
presented for the eligible cohorts, highlighting differences between the
civilian and federal datasets, e.g. the federal data set had more
outpatient visits per person month (6.44 vs. 2.05 per person month). The
count of medications per person month reflected the fact that one system's
medications were extracted from orders while the other system had pharmacy
fills and medication administration records. The federal system also had a
higher prevalence of the conditions in all three use cases. Both systems
required manual coding of some types of data to convert to the CDM.
CONCLUSIONS: The data transformation to the CDM was time consuming and
resources required were substantial, beyond requirements for collecting
native source data. The need to manually code subsets of data limited the
conversion. However, once the native data was converted to the CDM, both
systems were then able to use the same queries to identify cohorts. Thus,
the CDM minimized the effort to develop cohorts and analyze the results
across the sites.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RK4IG457/FitzHenry et al_2015_Creating a Common Data Model for Comparative Effectiveness with the.pdf},
  journal = {Appl. Clin. Inform.},
  keywords = {big data,Common data model,comparative effectiveness},
  number = {3}
}

@article{fleurenceLaunchingPCORnetNational2014,
  title = {Launching {{PCORnet}}, a National Patient-Centered Clinical Research Network},
  author = {Fleurence, R. L. and Curtis, L. H. and Califf, R. M. and Platt, R. and Selby, J. V. and Brown, J. S.},
  year = {2014},
  month = jul,
  volume = {21},
  pages = {578--582},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/amiajnl-2014-002747},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2014-002747},
  urldate = {2020-06-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/5P85D4IS/Fleurence et al_2014_Launching PCORnet, a national patient-centered clinical research network.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {4}
}

@article{flynnKnowledgeObjectReference2018,
  title = {The {{Knowledge Object Reference Ontology}} ({{KORO}}): {{A}} Formalism to Support Management and Sharing of Computable Biomedical Knowledge for Learning Health Systems},
  shorttitle = {The {{Knowledge Object Reference Ontology}} ({{KORO}})},
  author = {Flynn, Allen J. and Friedman, Charles P. and Boisvert, Peter and Landis-Lewis, Zachary and Lagoze, Carl},
  year = {2018},
  volume = {2},
  pages = {e10054},
  issn = {2379-6146},
  doi = {10.1002/lrh2.10054},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/lrh2.10054},
  urldate = {2020-01-28},
  abstract = {Introduction Health systems are challenged by care underutilization, overutilization, disparities, and related harms. One problem is a multiyear latency between discovery of new best practice knowledge and its widespread adoption. Decreasing this latency requires new capabilities to better manage and more rapidly share biomedical knowledge in computable forms. Knowledge objects package machine-executable knowledge resources in a way that easily enables knowledge as a service. To help improve knowledge management and accelerate knowledge sharing, the Knowledge Object Reference Ontology (KORO) defines what knowledge objects are in a formal way. Methods Development of KORO began with identification of terms for classes of entities and for properties. Next, we established a taxonomical hierarchy of classes for knowledge objects and their parts. Development continued by relating these parts via formally defined properties. We evaluated the logical consistency of KORO and used it to answer several competency questions about parthood. We also applied it to guide knowledge object implementation. Results As a realist ontology, KORO defines what knowledge objects are and provides details about the parts they have and the roles they play. KORO provides sufficient logic to answer several basic but important questions about knowledge objects competently. KORO directly supports creators of knowledge objects by providing a formal model for these objects. Conclusion KORO provides a formal, logically consistent ontology about knowledge objects and their parts. It exists to help make computable biomedical knowledge findable, accessible, interoperable, and reusable. KORO is currently being used to further develop and improve computable knowledge infrastructure for learning health systems.},
  copyright = {\textcopyright{} 2018 The Authors. Learning Health Systems published by Wiley Periodicals, Inc. on behalf of the University of Michigan},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/KULWLMB5/Flynn et al_2018_The Knowledge Object Reference Ontology (KORO).pdf;../../../../../citation-data/Zotero-after-paperpile/storage/KSG4CE9K/lrh2.html},
  journal = {Learning Health Systems},
  keywords = {BFO,IAO,knowledge management,knowledge object,KORO,ontology},
  language = {en},
  number = {2}
}

@misc{foleyProfessorCharlesFriedman2015,
  title = {Professor {{Charles Friedman Interview}}},
  author = {Foley, Thomas John and Fairmichael, Fergus},
  year = {2015},
  month = jun,
  url = {http://www.learninghealthcareproject.org/section/evidence/46/50/professor-charles-friedman-interview},
  urldate = {2020-03-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XL55XZDR/professor-charles-friedman-interview.html},
  journal = {The Learning Healthcare Project}
}

@article{foleyWhatRoleLearning2017,
  title = {What Role for Learning Health Systems in Quality Improvement within Healthcare Providers?},
  author = {Foley, Thomas John and Vale, Luke},
  year = {2017},
  month = oct,
  volume = {1},
  pages = {e10025},
  issn = {23796146},
  doi = {10.1002/lrh2.10025},
  url = {http://doi.wiley.com/10.1002/lrh2.10025},
  urldate = {2020-03-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/F28KI84R/Foley_Vale_2017_What role for learning health systems in quality improvement within healthcare.pdf},
  journal = {Learning Health Systems},
  language = {en},
  number = {4}
}

@inproceedings{fradeBuildingSemanticInteroperability2012,
  title = {Building Semantic Interoperability through the Federation of Semantic Asset Repositories},
  booktitle = {Proceedings of the 8th {{International Conference}} on {{Semantic Systems}}},
  author = {Frade, Jo{\~a}o Rodrigues and Di Giacomo, Debora and Goedertier, Stijn and Loutas, Nikolaos and Peristeras, Vassilios},
  year = {2012},
  month = sep,
  pages = {185--188},
  publisher = {{Association for Computing Machinery}},
  address = {{Graz, Austria}},
  doi = {10.1145/2362499.2362528},
  url = {https://doi.org/10.1145/2362499.2362528},
  urldate = {2020-03-05},
  abstract = {According to the Interoperability Solutions for European Public Administrations (ISA) Programme of the European Commission, interoperability relates to the ability of disparate organisations to interact towards mutually beneficial and agreed goals, involving the sharing of information and knowledge [1]. Semantic assets and the agreements associated with them are essential elements for organisations to understand the meaning of the information they exchange - without them this information would be of little use. In this paper, semantic assets are defined as ontologies, data models, data dictionaries, code lists, XML and RDF schemas which are used for information exchange and that can be reused by implementers of Information Systems, in particular, as part of machine-to-machine interfaces. However, field research has shown that developers, practitioners and researchers working in the field of semantic interoperability in eGovernment tend to reinvent the wheel and semantic assets are rarely reused. In order to encourage and bootstrap the reuse of semantic assets in the EU and beyond, this paper introduces two important initiatives driven by the ISA Programme: the Asset Description Metadata Schema (ADMS) and the ADMS-enabled federation of semantic asset repositories on Joinup.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/DYYPDGKA/Frade et al_2012_Building semantic interoperability through the federation of semantic asset.pdf},
  isbn = {978-1-4503-1112-0},
  keywords = {ADMS,e-government,metadata management,RDF,semantic interoperability,syndication of content,XML},
  series = {I-{{SEMANTICS}} '12}
}

@article{fridsmaMakingGenericGuidelines1996,
  title = {Making Generic Guidelines Site-Specific.},
  author = {Fridsma, D. B. and Gennari, J. H. and Musen, M. A.},
  year = {1996},
  pages = {597},
  url = {https://www-ncbi-nlm-nih-gov.proxy-um.researchport.umd.edu/pmc/articles/PMC2232947/},
  urldate = {2020-02-05},
  abstract = {Health care providers are more likely to follow a clinical guideline if the guideline's recommendations are consistent with the way in which their organization does its work. Unfortunately, developing guidelines that are specific to an organization is ...},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/F6JYVLEP/Fridsma et al_1996_Making generic guidelines site-specific.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/9Z76XPIZ/PMC2232947.html},
  journal = {Proceedings of the AMIA Annual Fall Symposium},
  language = {en},
  pmid = {8947736}
}

@misc{friedmanCompleteSustainableLearning2014,
  title = {Toward {{Complete}} \& {{Sustainable Learning Systems}}},
  author = {Friedman, Charles P and Macy, Josiah},
  year = {2014},
  month = dec,
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/M3HJIH22/Friedman_Macy_2014_Toward Complete & Sustainable Learning Systems.pdf},
  language = {en}
}

@article{friedmanInformationInfrastructureGlobal2017,
  title = {Toward an {{Information Infrastructure}} for {{Global Health Improvement}}},
  author = {Friedman, C. P. and Rubin, J. C. and Sullivan, K. J.},
  year = {2017},
  month = aug,
  volume = {26},
  pages = {16--23},
  issn = {2364-0502},
  doi = {10.15265/IY-2017-004},
  abstract = {Profound global challenges to individual and population health, alongside the opportunities to benefit from digital technology, have spawned the concept of the Learning Health System. Learning Health Systems (LHSs)--which can function at organizational, network, regional, and national levels of scale--have the capability of continuous data-driven self-study that promotes change and improvement. The LHS concept, which originated in the U.S. in 2007, is rapidly gaining attention around the world. LHSs require, but also transcend, the secondary use of health data. This paper describes the key features of LHSs, argues that effective and sustainable LHSs must be supported by infrastructures that allow them to function with economies of scale and scope, and describes the services that such infrastructures must provide. While it is relatively straightforward to describe LHSs, achieving them at the high level of capability necessary to promote significant health benefits will require advancements in science and engineering, engaging the field of informatics among a wider range of disciplines. It also follows from this vision that LHSs cannot be built from an imposed blueprint; LHSs will more likely evolve from efforts at smaller scales that compose into larger systems.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/A8A6BJJT/Friedman et al_2017_Toward an Information Infrastructure for Global Health Improvement.pdf},
  journal = {Yearbook of Medical Informatics},
  keywords = {Global Health,Humans,Medical Informatics Applications,Quality Improvement},
  language = {eng},
  number = {1},
  pmcid = {PMC6239237},
  pmid = {28480469}
}

@article{friedmanScienceLearningHealth2016,
  title = {The Science of {{Learning Health Systems}}: {{Foundations}} for a New Journal},
  shorttitle = {The Science of {{Learning Health Systems}}},
  author = {Friedman, Charles P. and Allee, Nancy J. and Delaney, Brendan C. and Flynn, Allen J. and Silverstein, Jonathan C. and Sullivan, Kevin and Young, Kathleen A.},
  year = {2016},
  month = nov,
  volume = {1},
  issn = {2379-6146},
  doi = {10.1002/lrh2.10020},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6516721/},
  urldate = {2020-05-27},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/VG3PHSXY/Friedman et al_2016_The science of Learning Health Systems.pdf},
  journal = {Learning Health Systems},
  number = {1},
  pmcid = {PMC6516721},
  pmid = {31245555}
}

@incollection{fungKnowledgeRepresentationOntologies2012,
  title = {Knowledge Representation and Ontologies. | {{National Library}} of {{Medicine}}},
  booktitle = {Clinical Research Informatics},
  author = {Fung, Kin Wah and Bodenreider, Olivier},
  editor = {Richesson, Rachel L and Andrews, JE},
  year = {2012},
  pages = {255--275},
  publisher = {{Springer-Verlag}},
  url = {https://lhncbc.nlm.nih.gov/publication/lhncbc-2012-015},
  urldate = {2020-01-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RWLTL2WB/Fung_Bodenreider_2012_Knowledge representation and ontologies.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/D2JV42JT/lhncbc-2012-015.html}
}

@article{fungUseInterterminologyMaps2019,
  title = {The {{Use}} of {{Inter}}-Terminology {{Maps}} for the {{Creation}} and {{Maintenance}} of {{Value Sets}}},
  author = {Fung, Kin Wah and Xu, Julia and Gold, Sigfried},
  year = {2019},
  abstract = {Value sets play an important role in activities such as electronic clinical quality measures (eCQM) and patient cohort definition. Creation and maintenance of value sets is labor intensive and error prone. Existing inter-terminology maps can help to identify candidate codes in value sets defined in more than one terminology. For 197 eCQM value sets defined by SNOMED CT in combination with ICD-9-CM and/or ICD-10-CM, the map-generated codes showed good concordance with the value set codes, with Jaccard scores 0.3 to 0.5. Many of the map-generated codes not in the original value set should be considered for inclusion. This could potentially augment the ICD-9-CM codes by 45\% (1.5 codes), ICD-10-CM codes by 25\% (1.8 codes) and SNOMED CT codes by 21-42\% (2.4-4.7 codes) per value set on average. The mapping between SNOMED CT and ICD-10-PCS did not perform as well, probably because of the granularity discrepancy in the map.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/UESQIE8K/Fung et al_2019_The Use of Inter-terminology Maps for the Creation and Maintenance of Value Sets.pdf},
  journal = {American Medical Informatics Association Annual Symposium Proceedings 2019}
}

@article{gardeSemanticInteroperabilityElectronic2007,
  title = {Towards {{Semantic Interoperability}} for {{Electronic Health Records}}: {{Domain Knowledge Governance}} for {{openEHR Archetypes}}},
  shorttitle = {Towards {{Semantic Interoperability}} for {{Electronic Health Records}}},
  author = {Garde, S. and Knaup, P. and Hovenga, E. J. S. and Heard, S.},
  year = {2007},
  volume = {46},
  pages = {332--343},
  issn = {0026-1270, 2511-705X},
  doi = {10.1160/ME5001},
  url = {http://www.thieme-connect.de/DOI/DOI?10.1160/ME5001},
  urldate = {2020-03-18},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XTMBC9RT/Garde et al_2007_Towards Semantic Interoperability for Electronic Health Records.pdf},
  journal = {Methods of Information in Medicine},
  language = {en},
  number = {03}
}

@article{gillumPapyrusElectronicTablet2013,
  title = {From Papyrus to the Electronic Tablet: A Brief History of the Clinical Medical Record with Lessons for the Digital Age},
  author = {Gillum, Richard F},
  year = {2013},
  month = oct,
  volume = {126},
  pages = {853--857},
  issn = {0002-9343},
  doi = {10.1016/j.amjmed.2013.03.024},
  url = {http://dx.doi.org/10.1016/j.amjmed.2013.03.024},
  abstract = {A major transition is underway in documentation of patient-related data in
clinical settings with rapidly accelerating adoption of the electronic
health record and electronic medical record. This article examines the
history of the development of medical records in the West in order to
suggest lessons applicable to the current transition. The first documented
major transition in the evolution of the clinical medical record occurred
in antiquity, with the development of written case history reports for
didactic purposes. Benefiting from Classical and Hellenistic models
earlier than physicians in the West, medieval Islamic physicians continued
the development of case histories for didactic use. A forerunner of modern
medical records first appeared in Paris and Berlin by the early 19th
century. Development of the clinical record in America was pioneered in
the 19th century in major teaching hospitals. However, a clinical medical
record useful for direct patient care in hospital and ambulatory settings
was not developed until the 20th century. Several lessons are drawn from
the 4000-year history of the medical record that may help physicians
improve patient care in the digital age.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/QABZYVR2/Gillum_2013_From papyrus to the electronic tablet.pdf},
  journal = {Am. J. Med.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper,History; 18th century,History; 19th century,Humans,Medical records},
  number = {10}
}

@article{goldCHRONOSCohortExploration2016,
  title = {{{CHRONOS}}: {{Cohort}} Exploration through Individual Patient Profiles},
  author = {Gold, Sigfried and Blacketer, Clair and Sena, Anthony and De Falco, Frank J},
  year = {2016},
  url = {http://www.ohdsi.org/web/wiki/lib/exe/fetch.php?media=resources:chronos_poster_abstract_for_ohdsi_2016_final.pdf},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/LTU4NQRP/Gold et al_CHRONOS.pdf},
  keywords = {Personal/Viz — by me}
}

@article{goldClinicalConceptValue2018,
  title = {Clinical {{Concept Value Sets}} and {{Interoperability}} in {{Health Data Analytics}}},
  author = {Gold, Sigfried and Batch, Andrea and McClure, Robert and Jiang, Guoqian and Kharrazi, Hadi and Saripalle, Rishi and Huser, Vojtech and Weng, Chunhua and Roderer, Nancy and Szarfman, Ana and Elmqvist, Niklas and Gotz, David},
  year = {2018},
  month = dec,
  volume = {2018},
  pages = {480--489},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6371254/},
  urldate = {2019-03-11},
  abstract = {This paper focuses on value sets as an essential component in the health analytics ecosystem. We discuss shared repositories of reusable value sets and offer recommendations for their further development and adoption. In order to motivate these contributions, we explain how value sets fit into specific analytic tasks and the health analytics landscape more broadly; their growing importance and ubiquity with the advent of Common Data Models, Distributed Research Networks, and the availability of higher order, reusable analytic resources like electronic phenotypes and electronic clinical quality measures; the formidable barriers to value set reuse; and our introduction of a concept-agnostic orientation to vocabulary collections. The costs of ad hoc value set management and the benefits of value set reuse are described or implied throughout. Our standards, infrastructure, and design recommendations are not systematic or comprehensive but invite further work to support value set reuse for health analytics. The views represented in the paper do not necessarily represent the views of the institutions or of all the co-authors.},
  copyright = {All rights reserved},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/MIBKETDS/Gold et al_2018_Clinical Concept Value Sets and Interoperability in Health Data Analytics.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC6371254},
  pmid = {30815088}
}

@article{goldExtractingStructuredMedication2008,
  title = {Extracting Structured Medication Event Information from Discharge Summaries},
  author = {Gold, Sigfried and Elhadad, No{\'e}mie and Zhu, Xinxin and Cimino, James J and Hripcsak, George},
  year = {2008},
  month = nov,
  pages = {237--241},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/18999147},
  abstract = {We present a method that extracts medication information from discharge
summaries. The program relies on parsing rules written as a set of regular
expressions and on a user-configurable drug lexicon. Our evaluation shows
a precision of 94\% and recall of 83\% in the extraction of medication
information. We use a broader definition of medication information than
previous studies, including drug names appearing with and without dosage
information, misspelled drug names, and contextual information.},
  copyright = {All rights reserved},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RLL4JZRT/Gold et al_2008_Extracting structured medication event information from discharge summaries.pdf},
  journal = {AMIA Annu. Symp. Proc.},
  keywords = {Personal/By me,Random stuff to show Rachel Paperpile}
}

@article{gossEvaluatingStandardTerminologies2013,
  title = {Evaluating Standard Terminologies for Encoding Allergy Information},
  author = {Goss, Foster R and Zhou, Li and Plasek, Joseph M and Broverman, Carol and Robinson, George and Middleton, Blackford and Rocha, Roberto A},
  year = {2013},
  month = sep,
  volume = {20},
  pages = {969--979},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2012-000816},
  url = {http://dx.doi.org/10.1136/amiajnl-2012-000816},
  abstract = {OBJECTIVE: Allergy documentation and exchange are vital to ensuring
patient safety. This study aims to analyze and compare various existing
standard terminologies for representing allergy information. METHODS: Five
terminologies were identified, including the Systemized Nomenclature of
Medical Clinical Terms (SNOMED CT), National Drug File-Reference
Terminology (NDF-RT), Medication Dictionary for Regulatory Activities
(MedDRA), Unique Ingredient Identifier (UNII), and RxNorm. A qualitative
analysis was conducted to compare desirable characteristics of each
terminology, including content coverage, concept orientation, formal
definitions, multiple granularities, vocabulary structure, subset
capability, and maintainability. A quantitative analysis was also
performed to compare the content coverage of each terminology for (1)
common food, drug, and environmental allergens and (2) descriptive
concepts for common drug allergies, adverse reactions (AR), and no known
allergies. RESULTS: Our qualitative results show that SNOMED CT fulfilled
the greatest number of desirable characteristics, followed by NDF-RT,
RxNorm, UNII, and MedDRA. Our quantitative results demonstrate that RxNorm
had the highest concept coverage for representing drug allergens, followed
by UNII, SNOMED CT, NDF-RT, and MedDRA. For food and environmental
allergens, UNII demonstrated the highest concept coverage, followed by
SNOMED CT. For representing descriptive allergy concepts and adverse
reactions, SNOMED CT and NDF-RT showed the highest coverage. Only SNOMED
CT was capable of representing unique concepts for encoding no known
allergies. CONCLUSIONS: The proper terminology for encoding a patient's
allergy is complex, as multiple elements need to be captured to form a
fully structured clinical finding. Our results suggest that while gaps
still exist, a combination of SNOMED CT and RxNorm can satisfy most
criteria for encoding common allergies and provide sufficient content
coverage.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/LLDVUVMQ/Goss et al_2013_Evaluating standard terminologies for encoding allergy information.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Allergy,Drug Intolerance,Hypersensitivity,Standards,Terminology,Vocabulary; Controlled},
  number = {5}
}

@article{guiseMindGapPutting2018,
  title = {Mind the {{Gap}}: {{Putting Evidence}} into {{Practice}} in the {{Era}} of {{Learning Health Systems}}},
  shorttitle = {Mind the {{Gap}}},
  author = {Guise, Jeanne-Marie and Savitz, Lucy A. and Friedman, Charles P.},
  year = {2018},
  month = dec,
  volume = {33},
  pages = {2237--2239},
  issn = {0884-8734, 1525-1497},
  doi = {10.1007/s11606-018-4633-1},
  url = {http://link.springer.com/10.1007/s11606-018-4633-1},
  urldate = {2020-06-29},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/SKBHGFYB/Guise et al_2018_Mind the Gap.pdf},
  journal = {Journal of General Internal Medicine},
  language = {en},
  number = {12}
}

@article{guMethodologyPartitioningVocabulary1999,
  title = {A Methodology for Partitioning a Vocabulary Hierarchy into {{trees1This}} Research Was (Partially) Done under a Cooperative Agreement between the {{National Institute}} of {{Standards}} and {{Technology Advanced Technology Program}} (under the {{HIIT}} Contract \#{{70NANB5H1011}}) and the {{Healthcare Open Systems}} and {{Trials}}, {{Inc}}. Consortium, and the {{Center}} for {{Manufacturing Systems}}.1},
  author = {Gu, Huanying (Helen) and Perl, Yehoshua and Geller, James and Halper, Michael and Singh, Mansnimar},
  year = {1999},
  month = jan,
  volume = {15},
  pages = {77--98},
  issn = {0933-3657},
  doi = {10.1016/S0933-3657(98)00046-3},
  url = {http://www.sciencedirect.com/science/article/pii/S0933365798000463},
  urldate = {2019-11-21},
  abstract = {Controlled medical vocabularies are useful in application areas such as medical information systems and decision-support systems. However, such vocabularies are large and complex, and working with them can be daunting. It is important to provide a means for orienting vocabulary designers and users to the vocabulary's contents. We describe a methodology for partitioning a vocabulary based on an IS-A hierarchy into small meaningful pieces. The methodology uses our disciplined modeling framework to refine the IS-A hierarchy according to prescribed rules in a process carried out by a user in conjunction with the computer. The partitioning of the hierarchy implies a partitioning of the vocabulary. We demonstrate the methodology with respect to a complex sample of the MED, an existing medical vocabulary.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/V5MKZ5YW/Gu et al_1999_A methodology for partitioning a vocabulary hierarchy into trees1This research.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/39PVHW7W/S0933365798000463.html},
  journal = {Artificial Intelligence in Medicine},
  keywords = {Controlled medical vocabulary,Object-oriented modeling,Ontology,Partitioning,Semantic network},
  language = {en},
  number = {1},
  series = {Terminology and {{Concept Representation}}}
}

@article{guRepresentingUMLSObjectoriented2000,
  title = {Representing the {{UMLS}} as an Object-Oriented Database: Modeling Issues and Advantages},
  author = {Gu, H and Perl, Y and Geller, J and Halper, M and Liu, L M and Cimino, J J},
  year = {2000},
  month = jan,
  volume = {7},
  pages = {66--80},
  issn = {1067-5027},
  doi = {10.1136/jamia.2000.0070066},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/10641964},
  abstract = {OBJECTIVE: The Unified Medical Language System (UMLS) combines many
well-established authoritative medical informatics terminologies in one
knowledge representation system. Such a resource is very valuable to the
health care community and industry. However, the UMLS is very large and
complex and poses serious comprehension problems for users and maintenance
personnel. The authors present a representation to support the user's
comprehension and navigation of the UMLS. DESIGN: An object-oriented
database (OODB) representation is used to represent the two major
components of the UMLS-the Metathesaurus and the Semantic Network-as a
unified system. The semantic types of the Semantic Network are modeled as
semantic type classes. Intersection classes are defined to model concepts
of multiple semantic types, which are removed from the semantic type
classes. RESULTS: The authors provide examples of how the intersection
classes help expose omissions of concepts, highlight errors of semantic
type classification, and uncover ambiguities of concepts in the UMLS. The
resulting UMLS OODB schema is deeper and more refined than the Semantic
Network, since intersection classes are introduced. The Metathesaurus is
classified into more mutually exclusive, uniform sets of concepts. The
schema improves the user's comprehension and navigation of the
Metathesaurus. CONCLUSIONS: The UMLS OODB schema supports the user's
comprehension and navigation of the Metathesaurus. It also helps expose
and resolve modeling problems in the UMLS.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/D3AYRKHX/Gu et al_2000_Representing the UMLS as an object-oriented database.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  number = {1}
}

@article{hannan1996electronic,
  title = {Electronic Medical Records},
  author = {Hannan, Terry J},
  year = {1996},
  volume = {133},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FQBQPUFX/Hannan_1996_Electronic medical records.pdf},
  journal = {Health informatics: An overview}
}

@article{heitjanDistinguishingMissingRandom1996,
  title = {Distinguishing ``{{Missing}} at {{Random}}'' and ``{{Missing Completely}} at {{Random}}''},
  author = {Heitjan, Daniel F. and Basu, Srabashi},
  year = {1996},
  month = aug,
  volume = {50},
  pages = {207--213},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.1996.10474381},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10474381},
  urldate = {2020-03-21},
  journal = {The American Statistician},
  language = {en},
  number = {3}
}

@article{herrettDataResourceProfile2015,
  title = {Data {{Resource Profile}}: {{Clinical Practice Research Datalink}} ({{CPRD}})},
  shorttitle = {Data {{Resource Profile}}},
  author = {Herrett, Emily and Gallagher, Arlene M and Bhaskaran, Krishnan and Forbes, Harriet and Mathur, Rohini and {van Staa}, Tjeerd and Smeeth, Liam},
  year = {2015},
  month = jun,
  volume = {44},
  pages = {827--836},
  issn = {0300-5771, 1464-3685},
  doi = {10.1093/ije/dyv098},
  url = {https://academic.oup.com/ije/article-lookup/doi/10.1093/ije/dyv098},
  urldate = {2020-07-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/T74PAMZ9/Herrett et al_2015_Data Resource Profile.pdf},
  journal = {International Journal of Epidemiology},
  language = {en},
  number = {3}
}

@incollection{hirstOntologyLexicon2009,
  title = {Ontology and the Lexicon},
  booktitle = {Handbook on Ontologies},
  author = {Hirst, Graeme},
  year = {2009},
  pages = {269--292},
  publisher = {{Springer}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/G8X2HEAG/Hirst_2009_Ontology and the lexicon.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/Y3RQNGKX/978-3-540-92673-3_12.html}
}

@misc{HL7StandardClinical,
  title = {{{HL7 Standard}}: {{Clinical Quality Language Specification}}},
  url = {https://cql.hl7.org/},
  urldate = {2020-07-03},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/LZR7THYE/cql.hl7.org.html}
}

@misc{HL7StandardsProduct2017,
  title = {{{HL7 Standards Product Brief}} - {{HL7 Specification}}: {{Characteristics}} of a {{Formal Value Set Definition}}, {{Release}} 1},
  year = {2017},
  url = {http://www.hl7.org/implement/standards/product_brief.cfm?product_id=437},
  urldate = {2018-03-08}
}

@article{Holtzblatt1993,
  title = {Making Customer-Centered Design Work for Teams},
  author = {Holtzblatt, Karen and Beyer, Hugh},
  year = {1993},
  month = oct,
  volume = {36},
  pages = {92--103},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/163430.164050},
  journal = {Communications of the ACM},
  number = {10},
  numpages = {12}
}

@article{hosnyArtificialIntelligenceRadiology2018,
  title = {Artificial Intelligence in Radiology},
  author = {Hosny, Ahmed and Parmar, Chintan and Quackenbush, John and Schwartz, Lawrence H. and Aerts, Hugo J. W. L.},
  year = {2018},
  month = aug,
  volume = {18},
  pages = {500--510},
  issn = {1474-1768},
  doi = {10.1038/s41568-018-0016-5},
  url = {http://www.nature.com/articles/s41568-018-0016-5},
  urldate = {2020-02-09},
  abstract = {In this Opinion article, Hosny et al. discuss the application of artificial intelligence to image-based tasks in the field of radiology and consider the advantages and challenges of its clinical implementation.},
  copyright = {2018 Macmillan Publishers Ltd., part of Springer Nature},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CXQKHBJN/Hosny et al_2018_Artificial intelligence in radiology.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/IBYU4KQ5/s41568-018-0016-5.html},
  journal = {Nature Reviews Cancer},
  language = {en},
  number = {8}
}

@article{hripcsakCharacterizingTreatmentPathways2016,
  title = {Characterizing Treatment Pathways at Scale Using the {{OHDSI}} Network},
  author = {Hripcsak, George and Ryan, Patrick B. and Duke, Jon D. and Shah, Nigam H. and Park, Rae Woong and Huser, Vojtech and Suchard, Marc A. and Schuemie, Martijn J. and DeFalco, Frank J. and Perotte, Adler and Banda, Juan M. and Reich, Christian G. and Schilling, Lisa M. and Matheny, Michael E. and Meeker, Daniella and Pratt, Nicole and Madigan, David},
  year = {2016},
  month = jul,
  volume = {113},
  pages = {7329--7336},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1510502113},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1510502113},
  urldate = {2020-07-20},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PEWIQP2C/Hripcsak et al_2016_Characterizing treatment pathways at scale using the OHDSI network.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {27}
}

@article{hripcsakFacilitatingPhenotypeTransfer2019,
  title = {Facilitating Phenotype Transfer Using a Common Data Model},
  author = {Hripcsak, George and Shang, Ning and Peissig, Peggy L. and Rasmussen, Luke V. and Liu, Cong and Benoit, Barbara and Carroll, Robert J. and Carrell, David S. and Denny, Joshua C. and Dikilitas, Ozan and Gainer, Vivian S. and Howell, Kayla Marie and Klann, Jeffrey G. and Kullo, Iftikhar J. and Lingren, Todd and Mentch, Frank D. and Murphy, Shawn N. and Natarajan, Karthik and Pacheco, Jennifer A. and Wei, Wei-Qi and Wiley, Ken and Weng, Chunhua},
  year = {2019},
  month = aug,
  volume = {96},
  pages = {103253},
  issn = {15320464},
  doi = {10.1016/j.jbi.2019.103253},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046419301728},
  urldate = {2020-05-05},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/YJ8WUCII/Hripcsak et al_2019_Facilitating phenotype transfer using a common data model.pdf},
  journal = {Journal of Biomedical Informatics},
  language = {en}
}

@article{hripcsakHighfidelityPhenotypingRichness2018,
  title = {High-Fidelity Phenotyping: Richness and Freedom from Bias},
  shorttitle = {High-Fidelity Phenotyping},
  author = {Hripcsak, George and Albers, David J},
  year = {2018},
  month = mar,
  volume = {25},
  pages = {289--294},
  issn = {1067-5027, 1527-974X},
  doi = {10.1093/jamia/ocx110},
  url = {https://academic.oup.com/jamia/article/25/3/289/4484121},
  urldate = {2020-08-04},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CIGL2JFB/Hripcsak_Albers_2018_High-fidelity phenotyping.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {3}
}

@article{hripcsakNextgenerationPhenotypingElectronic2013,
  title = {Next-Generation Phenotyping of Electronic Health Records},
  author = {Hripcsak, George and Albers, David J},
  year = {2013},
  month = jan,
  volume = {20},
  pages = {117--121},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2012-001145},
  url = {http://dx.doi.org/10.1136/amiajnl-2012-001145},
  abstract = {The national adoption of electronic health records (EHR) promises to make
an unprecedented amount of data available for clinical research, but the
data are complex, inaccurate, and frequently missing, and the record
reflects complex processes aside from the patient's physiological state.
We believe that the path forward requires studying the EHR as an object of
interest in itself, and that new models, learning from data, and
collaboration will lead to efficient use of the valuable information
currently locked in health records.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8X5L3Q76/Hripcsak_Albers_2013_Next-generation phenotyping of electronic health records.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Common Data Models in Health Records Research,Informatics/med recs / cdms},
  number = {1}
}

@article{hripcsakObservationalHealthData2015,
  title = {Observational {{Health Data Sciences}} and {{Informatics}} ({{OHDSI}}): {{Opportunities}} for {{Observational Researchers}}},
  author = {Hripcsak, George and Duke, Jon D and Shah, Nigam H and Reich, Christian G and Huser, Vojtech and Schuemie, Martijn J and Suchard, Marc A and Park, Rae Woong and Wong, Ian Chi Kei and Rijnbeek, Peter R and {van der Lei}, Johan and Pratt, Nicole and Nor{\'e}n, G Niklas and Li, Yu-Chuan and Stang, Paul E and Madigan, David and Ryan, Patrick B},
  year = {2015},
  volume = {216},
  pages = {574--578},
  issn = {0926-9630},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/26262116},
  abstract = {The vision of creating accessible, reliable clinical evidence by accessing
the clincial experience of hundreds of millions of patients across the
globe is a reality. Observational Health Data Sciences and Informatics
(OHDSI) has built on learnings from the Observational Medical Outcomes
Partnership to turn methods research and insights into a suite of
applications and exploration tools that move the field closer to the
ultimate goal of generating evidence about all aspects of healthcare to
serve the needs of patients, clinicians and all other decision-makers
around the world.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/W7J2LTDV/Hripcsak et al_2015_Observational Health Data Sciences and Informatics (OHDSI).pdf},
  journal = {Stud. Health Technol. Inform.}
}

@article{huservDesiderataHealthcareIntegrated2013,
  title = {Desiderata for Healthcare Integrated Data Repositories Based on Architectural Comparison of Three Public Repositories},
  author = {{Huser V} and {Cimino JJ}},
  year = {2013},
  volume = {2013},
  pages = {648--656},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/AL2B9BMQ/Huser V_Cimino JJ_2013_Desiderata for healthcare integrated data repositories based on architectural.pdf},
  journal = {AMIA Annu. Symp. Proc.},
  keywords = {Active papers/AMIA VS,Active papers/IEEE Vis 2018,Active papers/interoperability paper/background,Informatics/med recs / cdms,Topics/Viz/vocab-viz,Topics/Viz/Vocabs,Zotero Import (Oct 26)}
}

@misc{IHTSDOHealthdataanalytics2020,
  title = {{{IHTSDO}}/Health-Data-Analytics},
  year = {2020},
  month = jan,
  url = {https://github.com/IHTSDO/health-data-analytics},
  urldate = {2020-01-20},
  abstract = {Health Data Analytics Demonstrator. Contribute to IHTSDO/health-data-analytics development by creating an account on GitHub.},
  copyright = {Apache-2.0},
  howpublished = {SNOMED International},
  keywords = {data-analysis,opensource,snomed,snomed-api,snomed-ct}
}

@book{instituteofmedicineCrossingQualityChasm2001,
  title = {Crossing the {{Quality Chasm}}: {{A New Health System}} for the 21st {{Century}}},
  shorttitle = {Crossing the {{Quality Chasm}}},
  author = {{Institute of Medicine} and {Committee on Quality of Health Care in America}},
  year = {2001},
  month = jul,
  publisher = {{National Academies Press}},
  address = {{Washington, D.C.}},
  doi = {10.17226/10027},
  url = {http://www.nap.edu/catalog/10027},
  urldate = {2020-03-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/NLQ5CUUE/Institute of Medicine_Committee on Quality of Health Care in America_2001_Crossing the Quality Chasm.pdf},
  isbn = {978-0-309-07280-9}
}

@misc{ISO11179Term,
  title = {{{ISO}} 11179 {{Term Definitions}} - {{caDSR}} - {{National Cancer Institute}} - {{Confluence Wiki}}},
  url = {https://wiki.nci.nih.gov/display/caDSR/ISO+11179+Term+Definitions},
  urldate = {2020-03-28},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/YMFMKQLJ/ISO+11179+Term+Definitions.html}
}

@misc{isotheinternationalorganizationforstandardizationandiectheinternationalelectrotechnicalcommissionISOIEC11179,
  title = {{{ISO}}/{{IEC}} 11179 {{Information}} Technology \textemdash{} {{Metadata}} Registries ({{MDR}})},
  shorttitle = {{{ISO}} 11179},
  author = {{ISO (the International Organization for Standardization) and IEC (the International Electrotechnical Commission)}},
  url = {https://standards.iso.org/ittf/PubliclyAvailableStandards/index.html},
  urldate = {2020-05-27},
  abstract = {ISO/IEC 11179 addresses the semantics of data, the representation of data and the registration of
the descriptions of that data. It is through these descriptions that an accurate understanding of the
semantics and a useful depiction of the data are found.
The purposes of ISO/IEC 11179 is to promote the following:
\textemdash{} standard description of data;
\textemdash{} common understanding of data across organizational elements and between organizations;
\textemdash{} re-use and standardization of data over time, space, and applications;
\textemdash{} harmonization and standardization of data within an organization and across organizations;
\textemdash{} management of the components of descriptions of data;
\textemdash{} re-use of the components of descriptions of data.
Each part of ISO/IEC 11179 is devoted to addressing a different aspect of these needs:
\textemdash{} Part 1: Framework \textendash{} Contains an overview of the Standard and describes the basic concepts;
\textemdash{} Part 2: Classification \textendash{} Describes how to manage a classification scheme in a metadata registry;
\textemdash{} Part 3: Registry metamodel and basic attributes \textendash{} Provides the conceptual model, including the basic
attributes and relationships, for a metadata registry;
\textemdash{} Part 4: Formulation of data definitions \textendash{} Gives rules and guidelines for forming quality definitions for
data elements and their components;
\textemdash{} Part 5: Naming principles \textendash{} Describes how to form conventions for naming data elements and
their components;
\textemdash{} Part 6: Registration \textendash{} Specifies the roles and requirements for the registration process in an
ISO/IEC 11179 metadata registry.
Generally, descriptive data are known as metadata. Metadata can describe books, phone calls, data, etc.
ISO/IEC 11179 focuses upon metadata that describes data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/3RB8HAP3/c061932_ISO_IEC_11179-1_2015.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/5A9BA8KR/c060341_ISO_IEC_11179-5_2015.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/K2Z3N2NA/ISO (the International Organization for Standardization) and IEC (the International Electrotechnical_Commission)_ISO-IEC 11179 Information technology — Metadata registries (MDR).pdf;../../../../../citation-data/Zotero-after-paperpile/storage/M4UGME92/c050340_ISO_IEC_11179-3_2013.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/XQ9URS6X/c060342_ISO_IEC_11179-6_2015.pdf}
}

@article{jagannathanAssessmentCommercialNLP2009,
  title = {Assessment of Commercial {{NLP}} Engines for Medication Information Extraction from Dictated Clinical Notes},
  author = {Jagannathan, V. and Mullett, Charles J. and Arbogast, James G. and Halbritter, Kevin A. and Yellapragada, Deepthi and Regulapati, Sushmitha and Bandaru, Pavani},
  year = {2009},
  month = apr,
  volume = {78},
  pages = {284--291},
  issn = {1386-5056},
  doi = {10.1016/j.ijmedinf.2008.08.006},
  url = {http://www.sciencedirect.com/science/article/pii/S1386505608001536},
  urldate = {2020-02-09},
  abstract = {Purpose
We assessed the current state of commercial natural language processing (NLP) engines for their ability to extract medication information from textual clinical documents.
Methods
Two thousand de-identified discharge summaries and family practice notes were submitted to four commercial NLP engines with the request to extract all medication information. The four sets of returned results were combined to create a comparison standard which was validated against a manual, physician-derived gold standard created from a subset of 100 reports. Once validated, the individual vendor results for medication names, strengths, route, and frequency were compared against this automated standard with precision, recall, and F measures calculated.
Results
Compared with the manual, physician-derived gold standard, the automated standard was successful at accurately capturing medication names (F measure=93.2\%), but performed less well with strength (85.3\%) and route (80.3\%), and relatively poorly with dosing frequency (48.3\%). Moderate variability was seen in the strengths of the four vendors. The vendors performed better with the structured discharge summaries than with the clinic notes in an analysis comparing the two document types.
Conclusion
Although automated extraction may serve as the foundation for a manual review process, it is not ready to automate medication lists without human intervention.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/3FAFWJVC/Jagannathan et al_2009_Assessment of commercial NLP engines for medication information extraction from.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/UKZGWFED/S1386505608001536.html},
  journal = {International Journal of Medical Informatics},
  keywords = {Medication extraction,Natural language processing (NLP),Text mining},
  language = {en},
  number = {4}
}

@article{jarowMultidimensionalEvidenceGeneration2017,
  title = {Multidimensional {{Evidence Generation}} and {{FDA Regulatory Decision Making}}: {{Defining}} and {{Using}} ``{{Real}}-{{World}}'' {{Data}}},
  shorttitle = {Multidimensional {{Evidence Generation}} and {{FDA Regulatory Decision Making}}},
  author = {Jarow, Jonathan P. and LaVange, Lisa and Woodcock, Janet},
  year = {2017},
  month = aug,
  volume = {318},
  pages = {703},
  issn = {0098-7484},
  doi = {10.1001/jama.2017.9991},
  url = {http://jama.jamanetwork.com/article.aspx?doi=10.1001/jama.2017.9991},
  urldate = {2020-04-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/J8VFIZL8/Jarow et al. - 2017 - Multidimensional Evidence Generation and FDA Regul.pdf},
  journal = {JAMA},
  language = {en},
  number = {8}
}

@incollection{jiang2017developing,
  title = {Developing a Semantic Web-Based Framework for Executing the Clinical Quality Language Using {{FHIR}}},
  author = {Jiang, Guoqian and Prud'Hommeaux, Eric and Xiao, Guohui and Solbrig, Harold R},
  year = {2017},
  publisher = {{CEUR-WS. org}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CFZLBZ8H/Jiang et al_2017_Developing a semantic web-based framework for executing the clinical quality.pdf}
}

@article{jiangBuildingInteroperableFHIRBased2017,
  title = {Building {{Interoperable FHIR}}-{{Based Vocabulary Mapping Services}}: {{A Case Study}} of {{OHDSI Vocabularies}} and {{Mappings}}},
  author = {Jiang, Guoqian and Kiefer, Richard and Prud'hommeaux, Eric and Solbrig, Harold R},
  year = {2017},
  volume = {245},
  pages = {1327},
  issn = {0926-9630},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/29295408},
  abstract = {The OHDSI Common Data Model (CDM) is a deep information model, in which
its vocabulary component plays a critical role in enabling consistent
coding and query of clinical data. The objective of the study is to create
methods and tools to expose the OHDSI vocabularies and mappings as the
vocabulary mapping services using two HL7 FHIR core terminology resources
ConceptMap and ValueSet. We discuss the benefits and challenges in
building the FHIR-based terminology services.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/U2D545GT/Jiang et al_2017_Building Interoperable FHIR-Based Vocabulary Mapping Services.pdf},
  journal = {Stud. Health Technol. Inform.},
  keywords = {Controlled,Observational Study,Reference Standards,Vocabulary}
}

@article{jiangCollaborativeFrameworkRepresentation2010,
  title = {A {{Collaborative Framework}} for {{Representation}} and {{Harmonization}} of {{Clinical Study Data Elements Using Semantic MediaWiki}}},
  author = {Jiang, Guoqian and Solbrig, Harold R. and {Iberson-Hurst}, Dave and Kush, Rebecca D. and Chute, Christopher G.},
  year = {2010},
  month = mar,
  volume = {2010},
  pages = {11--15},
  issn = {2153-6430},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041544/},
  urldate = {2020-01-31},
  abstract = {Semantic interoperability among terminologies, data elements, and information models is fundamental and critical for sharing information from the scientific bench to the clinical bedside and back among systems. To meet this need, the vision for CDISC is to build a global, accessible electronic library, which enables precise and standardized data element definitions that can be used in applications and studies to improve biomedical research and its link with health care. As a pilot study, we propose a representation and harmonization framework for clinical study data elements and implement a prototype CDISC Shared Health and Research Electronic Library (CSHARE) using Semantic MediaWiki. We report the preliminary observations of how the components worked and the lessons learnt. In summary, the wiki provided a useful prototyping tool from a process standpoint.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/YRNWE2EI/Jiang et al_2010_A Collaborative Framework for Representation and Harmonization of Clinical.pdf},
  journal = {Summit on Translational Bioinformatics},
  pmcid = {PMC3041544},
  pmid = {21347136}
}

@article{jiangConsensusBasedApproachHarmonizing2017,
  title = {A {{Consensus}}-{{Based Approach}} for {{Harmonizing}} the {{OHDSI Common Data Model}} with {{HL7 FHIR}}},
  author = {Jiang, Guoqian and Kiefer, Richard C and Sharma, Deepak K and Prud'hommeaux, Eric and Solbrig, Harold R},
  year = {2017},
  volume = {245},
  pages = {887--891},
  issn = {0926-9630},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/29295227},
  abstract = {A variety of data models have been developed to provide a standardized
data interface that supports organizing clinical research data into a
standard structure for building the integrated data repositories. HL7 Fast
Healthcare Interoperability Resources (FHIR) is emerging as a next
generation standards framework for facilitating health care and electronic
health records-based data exchange. The objective of the study was to
design and assess a consensus-based approach for harmonizing the OHDSI CDM
with HL7 FHIR. We leverage a FHIR W5 (Who, What, When, Where, and Why)
Classification System for designing the harmonization approaches and
assess their utility in achieving the consensus among curators using a
standard inter-rater agreement measure. Moderate agreement was achieved
for the model-level harmonization (kappa = 0.50) whereas only fair
agreement was achieved for the property-level harmonization (kappa =
0.21). FHIR W5 is a useful tool in designing the harmonization approaches
between data models and FHIR, and facilitating the consensus achievement.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/NSRTEUZZ/Jiang et al_2017_A Consensus-Based Approach for Harmonizing the OHDSI Common Data Model with HL7.pdf},
  journal = {Stud. Health Technol. Inform.},
  keywords = {controlled,Observational study,Reference standards,Vocabulary}
}

@article{jiangDevelopingDataElement2016,
  title = {Developing a Data Element Repository to Support {{EHR}}-Driven Phenotype Algorithm Authoring and Execution},
  author = {Jiang, Guoqian and Kiefer, Richard C. and Rasmussen, Luke V. and Solbrig, Harold R. and Mo, Huan and Pacheco, Jennifer A. and Xu, Jie and Montague, Enid and Thompson, William K. and Denny, Joshua C. and Chute, Christopher G. and Pathak, Jyotishman},
  year = {2016},
  month = aug,
  volume = {62},
  pages = {232--242},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2016.07.008},
  url = {http://www.sciencedirect.com/science/article/pii/S1532046416300624},
  urldate = {2020-04-27},
  abstract = {The Quality Data Model (QDM) is an information model developed by the National Quality Forum for representing electronic health record (EHR)-based electronic clinical quality measures (eCQMs). In conjunction with the HL7 Health Quality Measures Format (HQMF), QDM contains core elements that make it a promising model for representing EHR-driven phenotype algorithms for clinical research. However, the current QDM specification is available only as descriptive documents suitable for human readability and interpretation, but not for machine consumption. The objective of the present study is to develop and evaluate a data element repository (DER) for providing machine-readable QDM data element service APIs to support phenotype algorithm authoring and execution. We used the ISO/IEC 11179 metadata standard to capture the structure for each data element, and leverage Semantic Web technologies to facilitate semantic representation of these metadata. We observed there are a number of underspecified areas in the QDM, including the lack of model constraints and pre-defined value sets. We propose a harmonization with the models developed in HL7 Fast Healthcare Interoperability Resources (FHIR) and Clinical Information Modeling Initiatives (CIMI) to enhance the QDM specification and enable the extensibility and better coverage of the DER. We also compared the DER with the existing QDM implementation utilized within the Measure Authoring Tool (MAT) to demonstrate the scalability and extensibility of our DER-based approach.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/28U3INSG/Jiang et al_2016_Developing a data element repository to support EHR-driven phenotype algorithm.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/CBBFMYH9/S1532046416300624.html},
  journal = {Journal of Biomedical Informatics},
  keywords = {HL7 Fast Healthcare Interoperability Resources (FHIR),Metadata standards,Phenotype algorithms,Quality Data Model (QDM),Semantic Web technology},
  language = {en}
}

@article{jiangQualityEvaluationCancer2011,
  title = {Quality Evaluation of Cancer Study {{Common Data Elements}} Using the {{UMLS Semantic Network}}},
  author = {Jiang, Guoqian and Solbrig, Harold R and Chute, Christopher G},
  year = {2011},
  month = dec,
  volume = {44 Suppl 1},
  pages = {S78-85},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2011.08.001},
  url = {http://dx.doi.org/10.1016/j.jbi.2011.08.001},
  abstract = {The binding of controlled terminology has been regarded as important for
standardization of Common Data Elements (CDEs) in cancer research.
However, the potential of such binding has not yet been fully explored,
especially its quality assurance aspect. The objective of this study is to
explore whether there is a relationship between terminological annotations
and the UMLS Semantic Network (SN) that can be exploited to improve those
annotations. We profiled the terminological concepts associated with the
standard structure of the CDEs of the NCI Cancer Data Standards Repository
(caDSR) using the UMLS SN. We processed 17798 data elements and extracted
17526 primary object class/property concept pairs. We identified dominant
semantic types for the categories "object class" and "property" and
determined that the preponderance of the instances were disjoint (i.e. the
intersection of semantic types between the two categories is empty). We
then performed a preliminary evaluation on the data elements whose
asserted primary object class/property concept pairs conflict with this
observation - where the semantic type of the object class fell into a SN
category typically used by property or visa-versa. In conclusion, the UMLS
SN based profiling approach is feasible for the quality assurance and
accessibility of the cancer study CDEs. This approach could provide useful
insight about how to build mechanisms of quality assurance in a meta-data
repository.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/VJZWDF73/Jiang et al_2011_Quality evaluation of cancer study Common Data Elements using the UMLS Semantic.pdf},
  journal = {J. Biomed. Inform.},
  keywords = {Active papers/AMIA VS}
}

@article{jiangQualityEvaluationValue2012,
  title = {Quality Evaluation of Value Sets from Cancer Study Common Data Elements Using the {{UMLS}} Semantic Groups},
  author = {Jiang, Guoqian and Solbrig, Harold R and Chute, Christopher G},
  year = {2012},
  month = jun,
  volume = {19},
  pages = {e129-36},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2011-000739},
  url = {http://dx.doi.org/10.1136/amiajnl-2011-000739},
  abstract = {OBJECTIVE: The objective of this study is to develop an approach to
evaluate the quality of terminological annotations on the value set (ie,
enumerated value domain) components of the common data elements (CDEs) in
the context of clinical research using both unified medical language
system (UMLS) semantic types and groups. MATERIALS AND METHODS: The CDEs
of the National Cancer Institute (NCI) Cancer Data Standards Repository,
the NCI Thesaurus (NCIt) concepts and the UMLS semantic network were
integrated using a semantic web-based framework for a SPARQL-enabled
evaluation. First, the set of CDE-permissible values with corresponding
meanings in external controlled terminologies were isolated. The
corresponding value meanings were then evaluated against their NCI- or
UMLS-generated semantic network mapping to determine whether all of the
meanings fell within the same semantic group. RESULTS: Of the enumerated
CDEs in the Cancer Data Standards Repository, 3093 (26.2\%) had elements
drawn from more than one UMLS semantic group. A random sample (n=100) of
this set of elements indicated that 17\% of them were likely to have been
misclassified. DISCUSSION: The use of existing semantic web tools can
support a high-throughput mechanism for evaluating the quality of large
CDE collections. This study demonstrates that the involvement of multiple
semantic groups in an enumerated value domain of a CDE is an effective
anchor to trigger an auditing point for quality evaluation activities.
CONCLUSION: This approach produces a useful quality assurance mechanism
for a clinical study CDE repository.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FQINVJ7H/Jiang et al_2012_Quality evaluation of value sets from cancer study common data elements using.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS},
  number = {e1}
}

@article{jingComplementaryGraphicalMethod2014,
  title = {A {{Complementary Graphical Method}} for {{Reducing}} and {{Analyzing Large Data Sets}}},
  author = {Jing, X. and Cimino, J. J.},
  year = {2014},
  volume = {53},
  pages = {173--185},
  issn = {0026-1270, 2511-705X},
  doi = {10.3414/ME13-01-0075},
  url = {http://www.thieme-connect.de/DOI/DOI?10.3414/ME13-01-0075},
  urldate = {2019-11-17},
  abstract = {{$<$}p{$>$} \textbf{Objectives:} Graphical displays can make data more understandable; however, large graphs can challenge human comprehension. We have previously described a filtering method to provide high-level summary views of large data sets. In this paper we demonstrate our method for setting and selecting thresholds to limit graph size while retaining important information by applying it to large single and paired data sets, taken from patient and bibliographic databases.{$<$}/p{$>$} {$<$}p{$>$} \textbf{Methods:} Four case studies are used to illustrate our method. The data are either patient discharge diagnoses (coded using the International Classification of Diseases, Clinical Modifications [ICD9-CM]) or Medline citations (coded using the Medical Subject Headings [MeSH]). We use combinations of different thresholds to obtain filtered graphs for detailed analysis. The thresholds setting and selection, such as thresholds for node counts, class counts, ratio values, p values (for diff data sets), and percentiles of selected class count thresholds, are demonstrated with details in case studies. The main steps include: data preparation, data manipulation, computation, and threshold selection and visualization. We also describe the data models for different types of thresholds and the considerations for thresholds selection.{$<$}/p{$>$} {$<$}p{$>$} \textbf{Results:} The filtered graphs are 1\%-3\% of the size of the original graphs. For our case studies, the graphs provide 1) the most heavily used ICD9-CM codes, 2) the codes with most patients in a research hospital in 2011, 3) a profile of publications on ``heavily represented topics'' in MEDLINE in 2011, and 4) validated knowledge about adverse effects of the medication of rosiglitazone and new interesting areas in the ICD9-CM hierarchy associated with patients taking the medication of pioglitazone.{$<$}/p{$>$} {$<$}p{$>$} \textbf{Conclusions:} Our filtering method reduces large graphs to a manageable size by re -moving relatively unimportant nodes. The graphical method provides summary views based on computation of usage frequency and semantic context of hierarchical ter -minology. The method is applicable to large data sets (such as a hundred thousand records or more) and can be used to generate new hypotheses from data sets coded with hierarchical terminologies.{$<$}/p{$>$}},
  copyright = {Schattauer GmbH},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/LBN2TSBU/Jing_Cimino_2014_A Complementary Graphical Method for Reducing and Analyzing Large Data Sets.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/4FBK9EWD/ME13-01-0075.html},
  journal = {Methods of Information in Medicine},
  language = {en},
  number = {03}
}

@article{jingVisualInteractiveAnalytic2019,
  title = {A Visual Interactive Analytic Tool for Filtering and Summarizing Large Health Data Sets Coded with Hierarchical Terminologies ({{VIADS}})},
  author = {Jing, Xia and Emerson, Matthew and Masters, David and Brooks, Matthew and Buskirk, Jacob and Abukamail, Nasseef and Liu, Chang and Cimino, James J. and Shubrook, Jay and De Lacalle, Sonsoles and Zhou, Yuchun and Patel, Vimla L.},
  year = {2019},
  month = feb,
  volume = {19},
  pages = {31},
  issn = {1472-6947},
  doi = {10.1186/s12911-019-0750-y},
  url = {https://doi.org/10.1186/s12911-019-0750-y},
  urldate = {2019-11-17},
  abstract = {Vast volumes of data, coded through hierarchical terminologies (e.g., International Classification of Diseases, Tenth Revision\textendash Clinical Modification [ICD10-CM], Medical Subject Headings [MeSH]), are generated routinely in electronic health record systems and medical literature databases. Although graphic representations can help to augment human understanding of such data sets, a graph with hundreds or thousands of nodes challenges human comprehension. To improve comprehension, new tools are needed to extract the overviews of such data sets. We aim to develop a visual interactive analytic tool for filtering and summarizing large health data sets coded with hierarchical terminologies (VIADS) as an online, and publicly accessible tool. The ultimate goals are to filter, summarize the health data sets, extract insights, compare and highlight the differences between various health data sets by using VIADS. The results generated from VIADS can be utilized as data-driven evidence to facilitate clinicians, clinical researchers, and health care administrators to make more informed clinical, research, and administrative decisions. We utilized the following tools and the development environments to develop VIADS: Django, Python, JavaScript, Vis.js, Graph.js, JQuery, Plotly, Chart.js, Unittest, R, and MySQL.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/5C2RK73B/Jing et al_2019_A visual interactive analytic tool for filtering and summarizing large health.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/W9IEAQ2I/s12911-019-0750-y.html},
  journal = {BMC Medical Informatics and Decision Making},
  number = {1}
}

@article{jirotkaSupportingScientificCollaboration2013,
  title = {Supporting {{Scientific Collaboration}}: {{Methods}}, {{Tools}} and {{Concepts}}},
  shorttitle = {Supporting {{Scientific Collaboration}}},
  author = {Jirotka, Marina and Lee, Charlotte P. and Olson, Gary M.},
  year = {2013},
  month = aug,
  volume = {22},
  pages = {667--715},
  issn = {1573-7551},
  doi = {10.1007/s10606-012-9184-0},
  url = {https://doi.org/10.1007/s10606-012-9184-0},
  urldate = {2020-02-27},
  abstract = {This paper discusses the interrelationship between e-Science and CSCW in terms of key substantive, methodological and conceptual innovations made in both fields. In so doing, we hope to draw out the existing relationship between CSCW and e-Science research, and to map out some key future challenges where the two areas of research may become more closely aligned. In considering what may be required to draw the two more closely together, the paper focuses primarily on investigations that have been undertaken in two dedicated initiatives into e-Science, along with the key issues emerging from these studies.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/WY6VHDFR/Jirotka et al_2013_Supporting Scientific Collaboration.pdf},
  journal = {Computer Supported Cooperative Work (CSCW)},
  language = {en},
  number = {4}
}

@article{kahnHarmonizedDataQuality2016,
  title = {A {{Harmonized Data Quality Assessment Terminology}} and {{Framework}} for the {{Secondary Use}} of {{Electronic Health Record Data}}},
  author = {Kahn, Michael G and Callahan, Tiffany J and Barnard, Juliana and Bauck, Alan E and Brown, Jeff and Davidson, Bruce N and Estiri, Hossein and Goerg, Carsten and Holve, Erin and Johnson, Steven G and Liaw, Siaw-Teng and {Hamilton-Lopez}, Marianne and Meeker, Daniella and Ong, Toan C and Ryan, Patrick and Shang, Ning and Weiskopf, Nicole G and Weng, Chunhua and Zozus, Meredith N and Schilling, Lisa},
  year = {2016},
  month = sep,
  volume = {4},
  pages = {1244},
  issn = {2327-9214},
  doi = {10.13063/2327-9214.1244},
  url = {http://dx.doi.org/10.13063/2327-9214.1244},
  abstract = {OBJECTIVE: Harmonized data quality (DQ) assessment terms, methods, and
reporting practices can establish a common understanding of the strengths
and limitations of electronic health record (EHR) data for operational
analytics, quality improvement, and research. Existing published DQ terms
were harmonized to a comprehensive unified terminology with definitions
and examples and organized into a conceptual framework to support a common
approach to defining whether EHR data is 'fit' for specific uses.
MATERIALS AND METHODS: DQ publications, informatics and analytics experts,
managers of established DQ programs, and operational manuals from several
mature EHR-based research networks were reviewed to identify potential DQ
terms and categories. Two face-to-face stakeholder meetings were used to
vet an initial set of DQ terms and definitions that were grouped into an
overall conceptual framework. Feedback received from data producers and
users was used to construct a draft set of harmonized DQ terms and
categories. Multiple rounds of iterative refinement resulted in a set of
terms and organizing framework consisting of DQ categories, subcategories,
terms, definitions, and examples. The harmonized terminology and logical
framework's inclusiveness was evaluated against ten published DQ
terminologies. RESULTS: Existing DQ terms were harmonized and organized
into a framework by defining three DQ categories: (1) Conformance (2)
Completeness and (3) Plausibility and two DQ assessment contexts: (1)
Verification and (2) Validation. Conformance and Plausibility categories
were further divided into subcategories. Each category and subcategory was
defined with respect to whether the data may be verified with
organizational data, or validated against an accepted gold standard,
depending on proposed context and uses. The coverage of the harmonized DQ
terminology was validated by successfully aligning to multiple published
DQ terminologies. DISCUSSION: Existing DQ concepts, community input, and
expert review informed the development of a distinct set of terms,
organized into categories and subcategories. The resulting DQ terms
successfully encompassed a wide range of disparate DQ terminologies.
Operational definitions were developed to provide guidance for
implementing DQ assessment procedures. The resulting structure is an
inclusive DQ framework for standardizing DQ assessment and reporting.
While our analysis focused on the DQ issues often found in EHR data, the
new terminology may be applicable to a wide range of electronic health
data such as administrative, research, and patient-reported data.
CONCLUSION: A consistent, common DQ terminology, organized into a logical
framework, is an initial step in enabling data owners and users, patients,
and policy makers to evaluate and communicate data quality findings in a
well-defined manner with a shared vocabulary. Future work will leverage
the framework and terminology to develop reusable data quality assessment
and reporting methods.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/I6E8N6VA/Kahn et al_2016_A Harmonized Data Quality Assessment Terminology and Framework for the.pdf},
  journal = {EGEMS (Wash DC)},
  keywords = {Active papers/AMIA VS,data completeness,data use \& quality,Electronic health records},
  number = {1}
}

@article{kamdarPhLeGrAGraphAnalytics2017,
  title = {{{PhLeGrA}}: {{Graph Analytics}} in {{Pharmacology}} over the {{Web}} of {{Life Sciences Linked Open Data}}},
  shorttitle = {{{PhLeGrA}}},
  author = {Kamdar, Maulik R. and Musen, Mark A.},
  year = {2017},
  month = apr,
  volume = {2017},
  pages = {321--329},
  doi = {10.1145/3038912.3052692},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5824722/},
  urldate = {2019-11-21},
  abstract = {Integrated approaches for pharmacology are required for the mechanism-based predictions of adverse drug reactions that manifest due to concomitant intake of multiple drugs. These approaches require the integration and analysis of biomedical data and knowledge from multiple, heterogeneous sources with varying schemas, entity notations, and formats. To tackle these integrative challenges, the Semantic Web community has published and linked several datasets in the Life Sciences Linked Open Data (LSLOD) cloud using established W3C standards. We present the PhLeGrA platform for Linked Graph Analytics in Pharmacology in this paper. Through query federation, we integrate four sources from the LSLOD cloud and extract a drug\textendash reaction network, composed of distinct entities. We represent this graph as a hidden conditional random field (HCRF), a discriminative latent variable model that is used for structured output predictions. We calculate the underlying probability distributions in the drug\textendash reaction HCRF using the datasets from the U.S. Food and Drug Administration's Adverse Event Reporting System. We predict the occurrence of 146 adverse reactions due to multiple drug intake with an AUROC statistic greater than 0.75. The PhLeGrA platform can be extended to incorporate other sources published using Semantic Web technologies, as well as to discover other types of pharmacological associations.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GEEQ4PEZ/Kamdar_Musen_2017_PhLeGrA.pdf},
  journal = {Proceedings of the ... International World-Wide Web Conference. International WWW Conference},
  pmcid = {PMC5824722},
  pmid = {29479581}
}

@article{kennellClinicalInformaticsResearcher2017,
  title = {Clinical {{Informatics Researcher}}'s {{Desiderata}} for the {{Data Content}} of the {{Next Generation Electronic Health Record}}},
  author = {Kennell, Jr, Timothy I and Willig, James H and Cimino, James J},
  year = {2017},
  month = oct,
  volume = {8},
  pages = {1159--1172},
  issn = {1869-0327},
  doi = {10.4338/ACI-2017-06-R-0101},
  url = {http://dx.doi.org/10.4338/ACI-2017-06-R-0101},
  abstract = {OBJECTIVE: Clinical informatics researchers depend on the availability of
high-quality data from the electronic health record (EHR) to design and
implement new methods and systems for clinical practice and research.
However, these data are frequently unavailable or present in a format that
requires substantial revision. This article reports the results of a
review of informatics literature published from 2010 to 2016 that
addresses these issues by identifying categories of data content that
might be included or revised in the EHR. MATERIALS AND METHODS: We used an
iterative review process on 1,215 biomedical informatics research
articles. We placed them into generic categories, reviewed and refined the
categories, and then assigned additional articles, for a total of three
iterations. RESULTS: Our process identified eight categories of data
content issues: Adverse Events, Clinician Cognitive Processes, Data
Standards Creation and Data Communication, Genomics, Medication List Data
Capture, Patient Preferences, Patient-reported Data, and Phenotyping.
DISCUSSION: These categories summarize discussions in biomedical
informatics literature that concern data content issues restricting
clinical informatics research. These barriers to research result from data
that are either absent from the EHR or are inadequate (e.g., in narrative
text form) for the downstream applications of the data. In light of these
categories, we discuss changes to EHR data storage that should be
considered in the redesign of EHRs, to promote continued innovation in
clinical informatics. CONCLUSION: Based on published literature of
clinical informaticians' reuse of EHR data, we characterize eight types of
data content that, if included in the next generation of EHRs, would find
immediate application in advanced informatics tools and techniques.},
  journal = {Appl. Clin. Inform.},
  keywords = {Active papers/AMIA VS},
  number = {4}
}

@article{khambeteGroundedTheoryEffective2010,
  title = {Grounded {{Theory}}: {{An Effective Method}} for {{User Experience Design Research}}},
  author = {Khambete, Pramod and Athavankar, Uday},
  year = {2010},
  pages = {14},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/ITMIMTHS/Khambete_Athavankar_2010_Grounded Theory.pdf},
  language = {en}
}

@article{kharraziProposedNationalResearch2017,
  title = {A Proposed National Research and Development Agenda for Population Health Informatics: Summary Recommendations from a National Expert Workshop},
  author = {Kharrazi, Hadi and Lasser, Elyse C and Yasnoff, William A and Loonsk, John and Advani, Aneel and Lehmann, Harold P and Chin, David C and Weiner, Jonathan P},
  year = {2017},
  month = jan,
  volume = {24},
  pages = {2--12},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocv210},
  url = {http://dx.doi.org/10.1093/jamia/ocv210},
  abstract = {OBJECTIVE: The Johns Hopkins Center for Population Health IT hosted a
1-day symposium sponsored by the National Library of Medicine to help
develop a national research and development (R\&D) agenda for the emerging
field of population health informatics (PopHI). MATERIAL AND METHODS: The
symposium provided a venue for national experts to brainstorm, identify,
discuss, and prioritize the top challenges and opportunities in the PopHI
field, as well as R\&D areas to address these. RESULTS: This manuscript
summarizes the findings of the PopHI symposium. The symposium
participants' recommendations have been categorized into 13 overarching
themes, including policy alignment, data governance, sustainability and
incentives, and standards/interoperability. DISCUSSION: The proposed
consensus-based national agenda for PopHI consisted of 18 priority
recommendations grouped into 4 broad goals: (1) Developing a standardized
collaborative framework and infrastructure, (2) Advancing technical tools
and methods, (3) Developing a scientific evidence and knowledge base, and
(4) Developing an appropriate framework for policy, privacy, and
sustainability. There was a substantial amount of agreement between all
the participants on the challenges and opportunities for PopHI as well as
on the actions that needed to be taken to address these. CONCLUSION: PopHI
is a rapidly growing field that has emerged to address the population
dimension of the Triple Aim. The proposed PopHI R\&D agenda is
comprehensive and timely, but should be considered only a starting-point,
given that ongoing developments in health policy, population health
management, and informatics are very dynamic, suggesting that the agenda
will require constant monitoring and updating.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/ZQE46V6Y/Kharrazi et al_2017_A proposed national research and development agenda for population health.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,informatics agenda,ISchool/INST800/final paper,population health informatics,public health informatics},
  number = {1}
}

@inproceedings{khatipovCreatingMaintainingPublishing2014,
  title = {Creating, {{Maintaining}} and {{Publishing Value Sets}} in the {{VSAC}}},
  booktitle = {{{AMIA}}},
  author = {Khatipov, Emir and Madden, Maureen and Chiang, Pishing and Chuang, Philip and Nguyen, Duc Manh and D'Souza, Ivor and Winnenburg, Rainer and Bodenreider, Olivier and Skapik, Julia and McClure, Robert C. and Emrick, Steven},
  year = {2014},
  pages = {1},
  abstract = {The Value Set Authority Center (VSAC, https://vsac.nlm.nih.gov/) is developed by the NLM in collaboration with ONC and Centers for Medicare \& Medicaid Services (CMS). VSAC provides access to value sets that are used to define concepts used in clinical quality measures and to support effective health information exchange and many other biomedical informatics applications and programs. VSAC has fulfilled the immediate need for a comprehensive resource that supports the creation and maintenance of value sets used by data elements in 2014 electronic Clinical Quality Measures (eCQMs). It currently continues to expand its repository beyond the Meaningful Use (MU) domain into such areas, as Patient Assessment Instruments, Common Data Elements for research, public health, the ONC S\&I Framework, and other clinical modeling efforts. In October 2013, NLM launched the VSAC Authoring Tool that allows authors to create, edit, clone, update and publish value sets. VSAC also provides data integration with the CMS Measure Authoring Tool (MAT) via a REST Application Programming Interface (API) that uses the Integrating the Healthcare Enterprise (IHE) Sharing Value Sets (SVS) specification.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8YZQVC3H/Khatipov et al_2014_Creating, Maintaining and Publishing Value Sets in the VSAC.pdf},
  keywords = {Application programming interface,Informatics,Information exchange,NetWare Loadable Module,Open Network Computing Remote Procedure Call}
}

@article{kimQualityImprovementModel2010,
  title = {A Quality Improvement Model for Healthcare Terminologies},
  author = {Kim, Tae Youn and Coenen, Amy and Hardiker, Nicholas},
  year = {2010},
  month = dec,
  volume = {43},
  pages = {1036--1043},
  issn = {15320464},
  doi = {10.1016/j.jbi.2010.08.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046410001176},
  urldate = {2020-04-08},
  journal = {Journal of Biomedical Informatics},
  language = {en},
  number = {6}
}

@article{kirbyPheKBCatalogWorkflow2016,
  title = {{{PheKB}}: A Catalog and Workflow for Creating Electronic Phenotype Algorithms for Transportability},
  shorttitle = {{{PheKB}}},
  author = {Kirby, Jacqueline C. and Speltz, Peter and Rasmussen, Luke V. and Basford, Melissa and Gottesman, Omri and Peissig, Peggy L. and Pacheco, Jennifer A. and Tromp, Gerard and Pathak, Jyotishman and Carrell, David S. and Ellis, Stephen B. and Lingren, Todd and Thompson, Will K. and Savova, Guergana and Haines, Jonathan and Roden, Dan M. and Harris, Paul A. and Denny, Joshua C.},
  year = {2016},
  month = nov,
  volume = {23},
  pages = {1046--1052},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocv202},
  abstract = {OBJECTIVE: Health care generated data have become an important source for clinical and genomic research. Often, investigators create and iteratively refine phenotype algorithms to achieve high positive predictive values (PPVs) or sensitivity, thereby identifying valid cases and controls. These algorithms achieve the greatest utility when validated and shared by multiple health care systems.Materials and Methods We report the current status and impact of the Phenotype KnowledgeBase (PheKB, http://phekb.org), an online environment supporting the workflow of building, sharing, and validating electronic phenotype algorithms. We analyze the most frequent components used in algorithms and their performance at authoring institutions and secondary implementation sites.
RESULTS: As of June 2015, PheKB contained 30 finalized phenotype algorithms and 62 algorithms in development spanning a range of traits and diseases. Phenotypes have had over 3500 unique views in a 6-month period and have been reused by other institutions. International Classification of Disease codes were the most frequently used component, followed by medications and natural language processing. Among algorithms with published performance data, the median PPV was nearly identical when evaluated at the authoring institutions (n = 44; case 96.0\%, control 100\%) compared to implementation sites (n = 40; case 97.5\%, control 100\%).
DISCUSSION: These results demonstrate that a broad range of algorithms to mine electronic health record data from different health systems can be developed with high PPV, and algorithms developed at one site are generally transportable to others.
CONCLUSION: By providing a central repository, PheKB enables improved development, transportability, and validity of algorithms for research-grade phenotypes using health care generated data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6B7HF4LB/Kirby et al_2016_PheKB.pdf},
  journal = {Journal of the American Medical Informatics Association: JAMIA},
  keywords = {Algorithms,clinical research,Data Mining,electronic health records,Electronic Health Records,electronic phenotyping,genomic research,Genomics,Humans,International Classification of Diseases,Knowledge Bases,natural language processing,Natural Language Processing,Phenotype},
  language = {eng},
  number = {6},
  pmcid = {PMC5070514},
  pmid = {27026615}
}

@incollection{klenkOpenScienceFuture2019,
  title = {Open {{Science}} and the {{Future}} of {{Data Analytics}}},
  booktitle = {Consumer {{Informatics}} and {{Digital Health}}: {{Solutions}} for {{Health}} and {{Health Care}}},
  author = {Klenk, Juergen and Payne, Philip R. O. and Shrestha, Rasu and Edmunds, Margo},
  editor = {Edmunds, Margo and Hass, Christopher and Holve, Erin},
  year = {2019},
  pages = {337--357},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-96906-0_18},
  url = {https://doi.org/10.1007/978-3-319-96906-0_18},
  urldate = {2020-02-27},
  abstract = {Open science is the idea that all those working to unlock solutions to the world's most vexing problems will collaborate and share data, algorithms, tried and failed combinations, and more, so that new discoveries can be made more quickly. Increasingly, open science also means full appreciation of the value of data and opening virtual floodgates that allow massive amounts of data to flow freely within and across the health sector and healthcare systems. Data-intensive computing and analytics allow researchers to generate new insights and discoveries in ways that were almost unimaginable until recently. The possibilities for open science fueled by cognitive computing, advances in machine and deep learning, and burgeoning data are endless and exciting. However, there are a number of hurdles that must be overcome before open science is truly established. This chapter will provide a view of what is possible in the health sector in an era of augmented intelligence and cognitive computing committed to unprecedented collaboration and discovery. We will discuss what is involved in overcoming barriers and systemic inertia to achieve real-world adoption and engage, train, and expand the skills of a next-generation workforce.},
  isbn = {978-3-319-96906-0},
  keywords = {Artificial intelligence,Artificial neural networks,Augmented intelligence,Blockchain,Cognitive computing,Collaboration platforms,Data analytics,Data commons,Data sharing,Deep learning,Discovery science,Open APIs,Open data,Open science,Precision medicine,Reproducibility,Systems science,Team science,Trust},
  language = {en}
}

@article{kronkDevelopmentGenderSex2020,
  title = {Development of the {{Gender}}, {{Sex}}, and {{Sexual Orientation}} Ontology: {{Evaluation}} and Workflow},
  shorttitle = {Development of the {{Gender}}, {{Sex}}, and {{Sexual Orientation}} Ontology},
  author = {Kronk, Clair A and Dexheimer, Judith W},
  year = {2020},
  month = jul,
  volume = {27},
  pages = {1110--1115},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocaa061},
  url = {https://academic.oup.com/jamia/article/27/7/1110/5858296},
  urldate = {2020-07-30},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PH4WNKTT/Kronk_Dexheimer_2020_Development of the Gender, Sex, and Sexual Orientation ontology.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {7}
}

@book{lazarResearchMethodsHuman2017,
  title = {Research Methods in Human Computer Interaction},
  author = {Lazar, Jonathan},
  year = {2017},
  edition = {2nd edition},
  publisher = {{Elsevier}},
  address = {{Cambridge, MA}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/YW7YLQWN/Lazar_2017_Research methods in human computer interaction.PDF},
  isbn = {978-0-12-805390-4}
}

@article{leung2019fair,
  title = {{{FAIR}} Principles for Clinical Practice Guidelines in a Learning Health System.},
  author = {Leung, Tiffany I and Dumontier, Michel},
  year = {2019},
  volume = {264},
  pages = {1690--1691},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/S3MZDQ34/Leung_Dumontier_2019_FAIR principles for clinical practice guidelines in a learning health system.pdf},
  journal = {Studies in health technology and informatics}
}

@article{lovinsIssuesVocabularyManagement,
  title = {Issues in {{Vocabulary Management}}: {{A Technical Report}} of the {{National Information Standards Organization}}},
  shorttitle = {Issues in {{Vocabulary Management}}},
  author = {Lovins, Daniel and Adkins, Alexis and Bulick, Natalie},
  url = {https://www.academia.edu/35337032/Issues_in_Vocabulary_Management_A_Technical_Report_of_the_National_Information_Standards_Organization},
  urldate = {2019-11-25},
  abstract = {NISO TR-06-2017 Issues in Vocabulary Management: A Technical Report of the National Information Standards Organization . Approved September 25, 2017. NISO, 2017. ISBN: 978-1-937522-79-7.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/SIKXNYGB/Issues_in_Vocabulary_Management_A_Technical_Report_of_the_National_Information_Standards_Organi.html},
  journal = {NISO TR-06-2017},
  language = {en}
}

@article{lowPragmaticDefinitionConcept2019,
  title = {A {{Pragmatic Definition}} of the {{Concept}} of {{Theoretical Saturation}}},
  author = {Low, Jacqueline},
  year = {2019},
  month = apr,
  volume = {52},
  pages = {131--139},
  issn = {0038-0237, 2162-1128},
  doi = {10.1080/00380237.2018.1544514},
  url = {https://www.tandfonline.com/doi/full/10.1080/00380237.2018.1544514},
  urldate = {2020-08-04},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/QDTN6ARS/Low_2019_A Pragmatic Definition of the Concept of Theoretical Saturation.pdf},
  journal = {Sociological Focus},
  language = {en},
  number = {2}
}

@article{luttersBoundaryObjectsCollaborative2007,
  title = {Beyond {{Boundary Objects}}: {{Collaborative Reuse}} in {{Aircraft Technical Support}}},
  shorttitle = {Beyond {{Boundary Objects}}},
  author = {Lutters, Wayne and Ackerman, Mark},
  year = {2007},
  month = jun,
  volume = {16},
  pages = {341--372},
  doi = {10.1007/s10606-006-9036-x},
  abstract = {ABSTRACT Boundary objects are a critical, but understudied, theoretical construct in CSCW. Through a field study of aircraft technical support, we examined the role of boundary objects in the practical achievement of safety by service engineers. Their resolution of repair requests was preserved in the organization's memory,via three compound boundary objects. These crystallizations did not manifest a static interpretation, but instead were continually re-interpreted in light of meta-negotiations. This suggests design implications for organizational memory,systems which can more fluidly represent the meta-negotiations surrounding boundary objects. KEYWORDS},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/A9WXLAX4/Lutters_Ackerman_2007_Beyond Boundary Objects.pdf},
  journal = {Computer Supported Cooperative Work}
}

@article{maloneRealWorldEvidenceUseful2018,
  title = {Real-{{World Evidence}}: {{Useful}} in the {{Real World}} of {{US Payer Decision Making}}? {{How}}? {{When}}? {{And What Studies}}?},
  shorttitle = {Real-{{World Evidence}}},
  author = {Malone, Daniel C. and Brown, Mary and Hurwitz, Jason T. and Peters, Loretta and Graff, Jennifer S.},
  year = {2018},
  month = mar,
  volume = {21},
  pages = {326--333},
  issn = {10983015},
  doi = {10.1016/j.jval.2017.08.3013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1098301517333478},
  urldate = {2020-04-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XDTNAHPH/Malone et al_2018_Real-World Evidence.pdf},
  journal = {Value in Health},
  language = {en},
  number = {3}
}

@phdthesis{margawatiUNDERSTANDINGVARIABILITYVALUE2019,
  title = {{{UNDERSTANDING THE VARIABILITY IN VALUE SETS}}: {{THE ROLE OF STEWARD}}},
  author = {Margawati, Dwi},
  year = {2019},
  month = aug,
  address = {{Baltimore, MD}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/DB974MGZ/Margawati_2019_UNDERSTANDING THE VARIABILITY IN VALUE SETS.pdf},
  language = {en},
  school = {Johns Hopkins University},
  type = {Master's {{Thesis}}}
}

@article{markus2001toward,
  title = {Toward a Theory of Knowledge Reuse: {{Types}} of Knowledge Reuse Situations and Factors in Reuse Success},
  author = {Markus, Lynne M},
  year = {2001},
  volume = {18},
  pages = {57--93},
  publisher = {{Taylor \& Francis}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FVECEDLU/Markus_2001_Toward a theory of knowledge reuse.pdf},
  journal = {Journal of management information systems},
  number = {1}
}

@article{mccormickValidityDiagnosticCodes2015,
  title = {Validity of {{Diagnostic Codes}} for {{Acute Stroke}} in {{Administrative Databases}}: {{A Systematic Review}}},
  shorttitle = {Validity of {{Diagnostic Codes}} for {{Acute Stroke}} in {{Administrative Databases}}},
  author = {McCormick, Natalie and Bhole, Vidula and Lacaille, Diane and {Avina-Zubieta}, J. Antonio},
  editor = {Quinn, Terence J},
  year = {2015},
  month = aug,
  volume = {10},
  pages = {e0135834},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0135834},
  url = {https://dx.plos.org/10.1371/journal.pone.0135834},
  urldate = {2020-07-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/642WK3LJ/McCormick et al_2015_Validity of Diagnostic Codes for Acute Stroke in Administrative Databases.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {8}
}

@article{mcquiltonHelpingConsumersProducers2019,
  ids = {mcquiltonHelpingConsumersProducers2019a},
  title = {Helping the {{Consumers}} and {{Producers}} of {{Standards}}, {{Repositories}} and                     {{Policies}} to {{Enable FAIR Data}}},
  author = {McQuilton, Peter and Batista, Dominique and Beyan, Oya and Granell, Ramon and Coles, Simon and Izzo, Massimiliano and Lister, Allyson                             L. and Pergl, Robert and {Rocca-Serra}, Philippe and Schaap, Ben and Shanahan, Hugh and Thurston, Milo and Sansone, Susanna-Assunta},
  year = {2019},
  month = nov,
  volume = {2},
  pages = {151--157},
  doi = {10.1162/dint_a_00037},
  url = {https://doi.org/10.1162/dint_a_00037},
  urldate = {2020-02-27},
  abstract = {Thousands of community-developed (meta)data guidelines, models, ontologies,                     schemas and formats have been created and implemented by several thousand data                     repositories and knowledge-bases, across all disciplines. These resources are                     necessary to meet government, funder and publisher expectations of greater                     transparency and access to and preservation of data related to research                     publications. This obligates researchers to ensure their data is FAIR, share                     their data using the appropriate standards, store their data in sustainable and                     community-adopted repositories, and to conform to funder and publisher data                     policies. FAIR data sharing also plays a key role in enabling researchers to                     evaluate, re-analyse and reproduce each other's work. We can map the                     landscape of relationships between community-adopted standards and repositories,                     and the journal publisher and funder data policies that recommend their use. In                     this paper, we show how the work of the GO-FAIR FAIR Standards, Repositories and                     Policies (StRePo) Implementation Network serves as a central integration and                     cross-fertilisation point for the reuse of FAIR standards, repositories and data                     policies in general. Pivotal to this effort, the FAIRsharing, an endorsed                     flagship resource of the Research Data Alliance that maps the landscape of                     relationships between community-adopted standards and repositories, and the                     journal publisher and funder data policies that recommend their use. Lastly, we                     highlight a number of activities around FAIR tools, services and educational                     efforts to raise awareness and encourage participation.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/2YJD48PX/dint_a_00037.html;../../../../../citation-data/Zotero-after-paperpile/storage/E3Y54ZJJ/dint_a_00037.html},
  journal = {Data Intelligence},
  number = {1-2}
}

@article{moDecompositionalApproachExecuting2016,
  title = {A {{Decompositional Approach}} to {{Executing Quality Data Model Algorithms}} on the I2b2 {{Platform}}},
  author = {Mo, Huan and Jiang, Guoqian and Pacheco, Jennifer A and Kiefer, Richard and Rasmussen, Luke V and Pathak, Jyotishman and Denny, Joshua C and Thompson, William K},
  year = {2016},
  month = jul,
  volume = {2016},
  pages = {167--175},
  issn = {2153-4063},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/27570665},
  abstract = {The Quality Data Model (QDM) is an established standard for representing
electronic clinical quality measures on electronic health record (EHR)
repositories. The Informatics for Integrated Biology and the Bedside
(i2b2) is a widely used platform for implementing clinical data
repositories. However, translation from QDM to i2b2 is challenging, since
QDM allows for complex queries beyond the capability of single i2b2
messages. We have developed an approach to decompose complex QDM
algorithms into workflows of single i2b2 messages, and execute them on the
KNIME data analytics platform. Each workflow operation module is composed
of parameter lists, a template for the i2b2 message, an mechanism to
create parameter updates, and a web service call to i2b2. The
communication between workflow modules relies on passing keys ofi2b2
result sets. As a demonstration of validity, we describe the
implementation and execution of a type 2 diabetes mellitus phenotype
algorithm against an i2b2 data repository.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RAANGVB5/Mo et al_2016_A Decompositional Approach to Executing Quality Data Model Algorithms on the.pdf},
  journal = {AMIA Jt Summits Transl Sci Proc},
  keywords = {Informatics/Phenotyping}
}

@article{moDesiderataComputableRepresentations2015,
  title = {Desiderata for Computable Representations of Electronic Health Records-Driven Phenotype Algorithms},
  author = {Mo, Huan and Thompson, William K and Rasmussen, Luke V and Pacheco, Jennifer A and Jiang, Guoqian and Kiefer, Richard and Zhu, Qian and Xu, Jie and Montague, Enid and Carrell, David S and Lingren, Todd and Mentch, Frank D and Ni, Yizhao and Wehbe, Firas H and Peissig, Peggy L and Tromp, Gerard and Larson, Eric B and Chute, Christopher G and Pathak, Jyotishman and Denny, Joshua C and Speltz, Peter and Kho, Abel N and Jarvik, Gail P and Bejan, Cosmin A and Williams, Marc S and Borthwick, Kenneth and Kitchner, Terrie E and Roden, Dan M and Harris, Paul A},
  year = {2015},
  month = nov,
  volume = {22},
  pages = {1220--1230},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocv112},
  url = {http://dx.doi.org/10.1093/jamia/ocv112},
  abstract = {BACKGROUND: Electronic health records (EHRs) are increasingly used for
clinical and translational research through the creation of phenotype
algorithms. Currently, phenotype algorithms are most commonly represented
as noncomputable descriptive documents and knowledge artifacts that detail
the protocols for querying diagnoses, symptoms, procedures, medications,
and/or text-driven medical concepts, and are primarily meant for human
comprehension. We present desiderata for developing a computable phenotype
representation model (PheRM). METHODS: A team of clinicians and
informaticians reviewed common features for multisite phenotype algorithms
published in PheKB.org and existing phenotype representation platforms. We
also evaluated well-known diagnostic criteria and clinical decision-making
guidelines to encompass a broader category of algorithms. RESULTS: We
propose 10 desired characteristics for a flexible, computable PheRM: (1)
structure clinical data into queryable forms; (2) recommend use of a
common data model, but also support customization for the variability and
availability of EHR data among sites; (3) support both human-readable and
computable representations of phenotype algorithms; (4) implement set
operations and relational algebra for modeling phenotype algorithms; (5)
represent phenotype criteria with structured rules; (6) support defining
temporal relations between events; (7) use standardized terminologies and
ontologies, and facilitate reuse of value sets; (8) define representations
for text searching and natural language processing; (9) provide interfaces
for external software algorithms; and (10) maintain backward
compatibility. CONCLUSION: A computable PheRM is needed for true phenotype
portability and reliability across different EHR products and healthcare
systems. These desiderata are a guide to inform the establishment and
evolution of EHR phenotype algorithm authoring platforms and languages.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/KBP8ZWNF/Mo et al_2015_Desiderata for computable representations of electronic health records-driven.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Active papers/IEEE Vis 2018,Active papers/interoperability paper/background,computable representation,data models,Electronic health records,Informatics/med recs / cdms,Informatics/Phenotyping,phenotype algorithms,phenotype standardization,Topics/Viz/vocab-viz},
  number = {6}
}

@techreport{monroeVisualizingPatternsDrug2013a,
  title = {Visualizing Patterns of Drug Prescriptions with Eventflow: {{A}} Pilot Study of Asthma Medications in the Military Health System},
  author = {Monroe, Megan and Meyer, Tamra E and Plaisant, Catherine and Lan, Rongjian and Wongsuphasawat, Krist and Coster, Trinka S and Gold, Sigfried and Millstein, Jeff and Shneiderman, Ben},
  year = {2013},
  institution = {{OFFICE OF THE SURGEON GENERAL (ARMY) FALLS CHURCH VA}},
  abstract = {The Food and Drug Administration and Department of Defense were interested in detecting sub-optimal use of long-acting beta-agonists (LABAs) in asthmatics within the Military Health System (MHS). Visualizing the patterns of asthma medication use surrounding a LABA prescription is a quick way to detect possible sub-optimal use for further evaluation. The US Army, Office of the Surgeon General, Pharmacovigilance Center (PVC) selected a random sample of 100 asthma patients under age 65 with a new LABA prescription from January 1, 2006-March 1, 2010 in MHS healthcare claims. Analysis was conducted in EventFlow, a novel interactive visualization tool being developed by the University of Maryland Human Computer Interaction Lab (HCIL) to display and summarize time- point and interval data. EventFlow groups individuals that share the same sequence of medications and displays the average interval times between events. We found that EventFlow was effective in uncovering clinically relevant patterns in the data. Epidemiologists reported that EventFlow was a powerful tool for rapidly visualizing possible patterns of sub-optimal LABA use that can be targeted for intervention.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/W8EMC5SK/Monroe et al_2013_Visualizing patterns of drug prescriptions with eventflow.pdf}
}

@article{monsCloudyIncreasinglyFAIR2017,
  title = {Cloudy, Increasingly {{FAIR}}; Revisiting the {{FAIR Data}} Guiding Principles for the {{European Open Science Cloud}}},
  author = {Mons, Barend and Neylon, Cameron and Velterop, Jan and Dumontier, Michel and {da Silva Santos}, Luiz Olavo Bonino and Wilkinson, Mark D.},
  year = {2017},
  month = jan,
  volume = {37},
  pages = {49--56},
  issn = {0167-5265},
  doi = {10.3233/ISU-170824},
  url = {https://content.iospress.com/articles/information-services-and-use/isu824},
  urldate = {2020-02-27},
  abstract = {The FAIR Data Principles propose that all scholarly output should be Findable, Accessible, Interoperable, and Reusable. As a set of guiding principles, expressing only the kinds of behaviours that researchers should expect from contemporary data reso},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/3C6IVETN/Mons et al_2017_Cloudy, increasingly FAIR\; revisiting the FAIR Data guiding principles for the.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/QX9YBUAD/isu824.html},
  journal = {Information Services \& Use},
  language = {en},
  number = {1}
}

@article{moPrototypeExecutablePortable2015,
  title = {A {{Prototype}} for {{Executable}} and {{Portable Electronic Clinical Quality Measures Using}} the {{KNIME Analytics Platform}}},
  author = {Mo, Huan and Pacheco, Jennifer A. and Rasmussen, Luke V. and Speltz, Peter and Pathak, Jyotishman and Denny, Joshua C. and Thompson, William K.},
  year = {2015},
  month = mar,
  volume = {2015},
  pages = {127--131},
  issn = {2153-4063},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4525225/},
  urldate = {2020-05-14},
  abstract = {Electronic clinical quality measures (eCQMs) based on the Quality Data Model (QDM) cannot currently be executed against non-standardized electronic health record (EHR) data. To address this gap, we prototyped an implementation of a QDM-based eCQM using KNIME, an open-source platform comprising a wide array of computational workflow tools that are collectively capable of executing QDM-based logic, while also giving users the flexibility to customize mappings from site-specific EHR data. To prototype this capability, we implemented eCQM CMS30 (titled: Statin Prescribed at Discharge) using KNIME. The implementation contains value set modules with connections to the National Library of Medicine's Value Set Authority Center, QDM Data Elements that can query a local EHR database, and logical and temporal operators. We successfully executed the KNIME implementation of CMS30 using data from the Vanderbilt University and Northwestern University EHR systems.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/X53HM7GH/Mo et al_2015_A Prototype for Executable and Portable Electronic Clinical Quality Measures.pdf},
  journal = {AMIA Summits on Translational Science Proceedings},
  pmcid = {PMC4525225},
  pmid = {26306254}
}

@article{morleyDefiningDiseasePhenotypes2014,
  title = {Defining {{Disease Phenotypes Using National Linked Electronic Health Records}}: {{A Case Study}} of {{Atrial Fibrillation}}},
  shorttitle = {Defining {{Disease Phenotypes Using National Linked Electronic Health Records}}},
  author = {Morley, Katherine I. and Wallace, Joshua and Denaxas, Spiros C. and Hunter, Ross J. and Patel, Riyaz S. and Perel, Pablo and Shah, Anoop D. and Timmis, Adam D. and Schilling, Richard J. and Hemingway, Harry},
  editor = {Kiechl, Stefan},
  year = {2014},
  month = nov,
  volume = {9},
  pages = {e110900},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0110900},
  url = {https://dx.plos.org/10.1371/journal.pone.0110900},
  urldate = {2020-01-16},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/NBCNK4TD/Morley et al_2014_Defining Disease Phenotypes Using National Linked Electronic Health Records.pdf},
  journal = {PLoS ONE},
  language = {en},
  number = {11}
}

@techreport{mouginMappingDataElements2006,
  title = {Mapping Data Elements to Terminological Resources for Integrating Biomedical Data Sources},
  author = {Mougin, Fleur and Burgun, Anita and Bodenreider, Olivier},
  year = {2006},
  month = nov,
  volume = {7},
  pages = {1--10},
  institution = {{BioMed Central}},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-7-S3-S6},
  url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-S3-S6},
  urldate = {2020-03-24},
  abstract = {Data integration is a crucial task in the biomedical domain and integrating data sources is one approach to integrating data. Data elements (DEs) in particular play an important role in data integration. We combine schema- and instance-based approaches to mapping DEs to terminological resources in order to facilitate data sources integration. We extracted DEs from eleven disparate biomedical sources. We compared these DEs to concepts and/or terms in biomedical controlled vocabularies and to reference DEs. We also exploited DE values to disambiguate underspecified DEs and to identify additional mappings. 82.5\% of the 474 DEs studied are mapped to entries of a terminological resource and 74.7\% of the whole set can be associated with reference DEs. Only 6.6\% of the DEs had values that could be semantically typed. Our study suggests that the integration of biomedical sources can be achieved automatically with limited precision and largely facilitated by mapping DEs to terminological resources.},
  copyright = {2006 Mougin et al; licensee BioMed Central Ltd.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/L7EHT7QF/Mougin et al_2006_Mapping data elements to terminological resources for integrating biomedical.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/JXMX8HCV/1471-2105-7-S3-S6.html},
  journal = {BMC Bioinformatics},
  language = {en},
  number = {3},
  type = {Report}
}

@article{mPerformanceComparisonTwo2016,
  title = {Performance {{Comparison}} between {{Two Solutions}} for {{Filtering Data Sets}} with {{Hierarchical Structures}}},
  author = {M, Levine and D, Osei and Jj, Cimino and C, Liu and Bo, Phillips and Jh, Shubrook and X, Jing},
  year = {2016},
  month = dec,
  volume = {2016},
  issn = {2324-9307},
  doi = {10.4172/2324-9307.S1-003},
  url = {https://www.scitechnol.com/abstract/performance-comparison-between-two-solutions-for-filtering-data-sets-with-hierarchical-structures-5229.html},
  urldate = {2019-11-17},
  abstract = {Performance Comparison between Two Solutions for Filtering Data Sets with Hierarchical Structures Controlled terminologies with hierarchical structures are utilized widely to code diagnoses (e.g., International Classification of Diseases, ICD) and other medical concepts (e.g., Medical Subject Headings, MeSH) in healthcare data sets. The coded data sets can be useful for advanced statistical analysis or to explore aggregated effects by using multiple data sets across institutions. The analysis of results can be evidence for administrative decisions (e.g., resources allocation) or to validate hypotheses. However, publicly accessible analytic tools for such data sets are lacking. Our research team has developed and published the methods for filtering, analysing and visualizing such data sets. Current work focuses on the development of an online tool to assist other researchers with applying our methods. We report on a comparison of two approaches to developing the tool in order to provide evidence about the selection of tools and programming language.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/Y54CLPGD/performance-comparison-between-two-solutions-for-filtering-data-sets-with-hierarchical-structur.html},
  journal = {Journal of Computer Engineering \& Information Technology},
  language = {en}
}

@article{mulrowSystematicReviewsRationale1994,
  title = {Systematic {{Reviews}}: {{Rationale}} for Systematic Reviews},
  shorttitle = {Systematic {{Reviews}}},
  author = {Mulrow, C D},
  year = {1994},
  month = sep,
  volume = {309},
  pages = {597--599},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.309.6954.597},
  url = {http://www.bmj.com/cgi/doi/10.1136/bmj.309.6954.597},
  urldate = {2020-06-29},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RXXU668Y/Mulrow_1994_Systematic Reviews.pdf},
  journal = {BMJ},
  language = {en},
  number = {6954}
}

@article{murphyIntegrationClinicalGenetic2006,
  title = {Integration of Clinical and Genetic Data in the I2b2 Architecture},
  author = {Murphy, Shawn N and Mendis, Michael E and Berkowitz, David A and Kohane, Isaac and Chueh, Henry C},
  year = {2006},
  pages = {1040},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/17238659},
  abstract = {The Informatics for Integrating Biology and the Bedside (i2b2) is one of
the sponsored initiatives of the NIH Roadmap National Centers for
Biomedical Computing (http://www.bisti.nih.gov/ncbc/). One of the goals of
i2b2 is to provide clinical investigators broadly with the software tools
necessary to collect and manage project-related clinical research data in
the genomics age as a cohesive entity - a software suite to construct and
manage the modern clinical research chart.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/A76SQFWZ/Murphy et al_2006_Integration of clinical and genetic data in the i2b2 architecture.pdf},
  journal = {AMIA Annu. Symp. Proc.}
}

@article{murphyServingEnterpriseInformatics2010,
  title = {Serving the Enterprise and beyond with Informatics for Integrating Biology and the Bedside (I2b2)},
  author = {Murphy, Shawn N and Weber, Griffin and Mendis, Michael and Gainer, Vivian and Chueh, Henry C and Churchill, Susanne and Kohane, Isaac},
  year = {2010},
  month = mar,
  volume = {17},
  pages = {124--130},
  issn = {1067-5027},
  doi = {10.1136/jamia.2009.000893},
  url = {http://dx.doi.org/10.1136/jamia.2009.000893},
  abstract = {Informatics for Integrating Biology and the Bedside (i2b2) is one of seven
projects sponsored by the NIH Roadmap National Centers for Biomedical
Computing (http://www.ncbcs.org). Its mission is to provide clinical
investigators with the tools necessary to integrate medical record and
clinical research data in the genomics age, a software suite to construct
and integrate the modern clinical research chart. i2b2 software may be
used by an enterprise's research community to find sets of interesting
patients from electronic patient medical record data, while preserving
patient privacy through a query tool interface. Project-specific
mini-databases ("data marts") can be created from these sets to make
highly detailed data available on these specific patients to the
investigators on the i2b2 platform, as reviewed and restricted by the
Institutional Review Board. The current version of this software has been
released into the public domain and is available at the URL:
http://www.i2b2.org/software.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GTFTRY76/Murphy et al_2010_Serving the enterprise and beyond with informatics for integrating biology and.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  number = {2}
}

@misc{nationalcancerinstituteCaDSRISO111792016,
  title = {{{caDSR}} and {{ISO}} 11179},
  shorttitle = {{{caDSR Wiki}}},
  author = {{National Cancer Institute}},
  year = {2016},
  month = nov,
  url = {https://wiki.nci.nih.gov/display/caDSR/caDSR+and+ISO+11179},
  urldate = {2020-05-26},
  abstract = {The ISO/IEC 11179 Information Technology: Metadata Registries (MDR) specification Exit Disclaimer logo developed by the International Organization for Standardization and the IEC (International Electrotechnical Commission) defines a number of fields and relationships for Metadata Registries.

Included is a detailed metamodel for defining and registering administered items. The primary component of that metamodel is a Data Element. The diagram below illustrates how the various components of the metamodel relate to each other. Each box in the diagram contains the name of an ISO/IEC 11179 administered item type, and underneath an example of metadata describing the various parts of a CDE.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/EWER8X6S/ISO11179andNCI75p.png;../../../../../citation-data/Zotero-after-paperpile/storage/ASV2QG74/caDSR+and+ISO+11179.html},
  journal = {Cancer Data Standards Registry and Repository}
}

@book{nirenburgOntologicalSemantics2004,
  title = {Ontological Semantics},
  author = {Nirenburg, Sergei and Raskin, Victor},
  year = {2004},
  publisher = {{Mit Press}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BY2IJECF/books.html}
}

@misc{observationalhealthdatasciencesandinformaticsOHDSIAtlas2020,
  title = {{{OHDSI}}/{{Atlas}}},
  year = {2020},
  month = may,
  url = {https://github.com/OHDSI/Atlas/wiki},
  urldate = {2020-05-05},
  abstract = {ATLAS is an open source software tool for researchers to conduct scientific analyses on standardized observational data},
  collaborator = {{Observational Health Data Sciences {and} Informatics}},
  copyright = {Apache-2.0},
  howpublished = {Observational Health Data Sciences and Informatics}
}

@misc{odysseusdataservicesAthenaOHDSIVocabulariesHierarchy,
  title = {Athena-{{OHDSI Vocabularies Hierarchy}} with {{Aggregation}}},
  author = {Odysseus Data Services, Inc And Ohdsi Community},
  url = {http://athena.ohdsi.org/search-terms/terms/4101796/graph?levels=10\&standardsOnly=false\&zoomLevel=3},
  urldate = {2018-05-14}
}

@book{ohdsiBookOHDSI2020,
  title = {The {{Book}} of {{OHDSI}}},
  author = {{OHDSI}},
  year = {2020},
  edition = {2020-04-16},
  publisher = {{Observational Health Data Sciences and Informatics}},
  url = {http://book.ohdsi.org},
  urldate = {2020-06-17},
  abstract = {A book about the Observational Health Data Sciences and Informatics (OHDSI). It describes the OHDSI community, open standards and open source software.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/IPASIJSE/TheBookOfOhdsi.html},
  isbn = {978-1-08-885519-5},
  language = {English}
}

@article{overhageValidationCommonData2012,
  title = {Validation of a Common Data Model for Active Safety Surveillance Research},
  author = {Overhage, J Marc and Ryan, Patrick B and Reich, Christian G and Hartzema, Abraham G and Stang, Paul E},
  year = {2012},
  month = jan,
  volume = {19},
  pages = {54--60},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2011-000376},
  url = {http://dx.doi.org/10.1136/amiajnl-2011-000376},
  abstract = {OBJECTIVE: Systematic analysis of observational medical databases for
active safety surveillance is hindered by the variation in data models and
coding systems. Data analysts often find robust clinical data models
difficult to understand and ill suited to support their analytic
approaches. Further, some models do not facilitate the computations
required for systematic analysis across many interventions and outcomes
for large datasets. Translating the data from these idiosyncratic data
models to a common data model (CDM) could facilitate both the analysts'
understanding and the suitability for large-scale systematic analysis. In
addition to facilitating analysis, a suitable CDM has to faithfully
represent the source observational database. Before beginning to use the
Observational Medical Outcomes Partnership (OMOP) CDM and a related
dictionary of standardized terminologies for a study of large-scale
systematic active safety surveillance, the authors validated the model's
suitability for this use by example. VALIDATION BY EXAMPLE: To validate
the OMOP CDM, the model was instantiated into a relational database, data
from 10 different observational healthcare databases were loaded into
separate instances, a comprehensive array of analytic methods that operate
on the data model was created, and these methods were executed against the
databases to measure performance. CONCLUSION: There was acceptable
representation of the data from 10 observational databases in the OMOP CDM
using the standardized terminologies selected, and a range of analytic
methods was developed and executed with sufficient performance to be
useful for active safety surveillance.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/YUQRHAAH/Overhage et al_2012_Validation of a common data model for active safety surveillance research.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Informatics/med recs / cdms},
  number = {1}
}

@article{pacaciSemanticTransformationMethodology2018,
  title = {A {{Semantic Transformation Methodology}} for the {{Secondary Use}} of {{Observational Healthcare Data}} in {{Postmarketing Safety Studies}}},
  author = {Pacaci, Anil and Gonul, Suat and Sinaci, A Anil and Yuksel, Mustafa and Laleci Erturkmen, Gokce B},
  year = {2018},
  month = apr,
  volume = {9},
  pages = {435},
  issn = {1663-9812},
  doi = {10.3389/fphar.2018.00435},
  url = {http://dx.doi.org/10.3389/fphar.2018.00435},
  abstract = {Background: Utilization of the available observational healthcare datasets
is key to complement and strengthen the postmarketing safety studies. Use
of common data models (CDM) is the predominant approach in order to enable
large scale systematic analyses on disparate data models and vocabularies.
Current CDM transformation practices depend on proprietarily developed
Extract-Transform-Load (ETL) procedures, which require knowledge both on
the semantics and technical characteristics of the source datasets and
target CDM. Purpose: In this study, our aim is to develop a modular but
coordinated transformation approach in order to separate semantic and
technical steps of transformation processes, which do not have a strict
separation in traditional ETL approaches. Such an approach would
discretize the operations to extract data from source electronic health
record systems, alignment of the source, and target models on the semantic
level and the operations to populate target common data repositories.
Approach: In order to separate the activities that are required to
transform heterogeneous data sources to a target CDM, we introduce a
semantic transformation approach composed of three steps: (1)
transformation of source datasets to Resource Description Framework (RDF)
format, (2) application of semantic conversion rules to get the data as
instances of ontological model of the target CDM, and (3) population of
repositories, which comply with the specifications of the CDM, by
processing the RDF instances from step 2. The proposed approach has been
implemented on real healthcare settings where Observational Medical
Outcomes Partnership (OMOP) CDM has been chosen as the common data model
and a comprehensive comparative analysis between the native and
transformed data has been conducted. Results: Health records of \textasciitilde 1 million
patients have been successfully transformed to an OMOP CDM based database
from the source database. Descriptive statistics obtained from the source
and target databases present analogous and consistent results. Discussion
and Conclusion: Our method goes beyond the traditional ETL approaches by
being more declarative and rigorous. Declarative because the use of RDF
based mapping rules makes each mapping more transparent and understandable
to humans while retaining logic-based computability. Rigorous because the
mappings would be based on computer readable semantics which are amenable
to validation through logic-based inference methods.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/F9AZTTYX/Pacaci et al_2018_A Semantic Transformation Methodology for the Secondary Use of Observational.pdf},
  journal = {Front. Pharmacol.},
  keywords = {common data model,healthcare datasets,pharmacovigilance,postmarketing safety study,semantic transformation}
}

@article{pachecoCaseStudyEvaluating2018,
  title = {A Case Study Evaluating the Portability of an Executable Computable Phenotype Algorithm across Multiple Institutions and Electronic Health Record Environments},
  author = {Pacheco, Jennifer A and Rasmussen, Luke V and Kiefer, Richard C and Campion, Thomas R and Speltz, Peter and Carroll, Robert J and Stallings, Sarah C and Mo, Huan and Ahuja, Monika and Jiang, Guoqian and LaRose, Eric R and Peissig, Peggy L and Shang, Ning and Benoit, Barbara and Gainer, Vivian S and Borthwick, Kenneth and Jackson, Kathryn L and Sharma, Ambrish and Wu, Andy Yizhou and Kho, Abel N and Roden, Dan M and Pathak, Jyotishman and Denny, Joshua C and Thompson, William K},
  year = {2018},
  month = aug,
  issn = {1067-5027},
  doi = {10.1093/jamia/ocy101},
  url = {http://dx.doi.org/10.1093/jamia/ocy101},
  abstract = {Electronic health record (EHR) algorithms for defining patient cohorts are
commonly shared as free-text descriptions that require human intervention
both to interpret and implement. We developed the Phenotype Execution and
Modeling Architecture (PhEMA, http://projectphema.org) to author and
execute standardized computable phenotype algorithms. With PhEMA, we
converted an algorithm for benign prostatic hyperplasia, developed for the
electronic Medical Records and Genomics network (eMERGE), into a
standards-based computable format. Eight sites (7 within eMERGE) received
the computable algorithm, and 6 successfully executed it against local
data warehouses and/or i2b2 instances. Blinded random chart review of
cases selected by the computable algorithm shows PPV {$\geq$}90\%, and 3 out of 5
sites had {$>$}90\% overlap of selected cases when comparing the computable
algorithm to their original eMERGE implementation. This case study
demonstrates potential use of PhEMA computable representations to automate
phenotyping across different EHR systems, but also highlights some ongoing
challenges.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7X3NSS6E/Pacheco et al_2018_A case study evaluating the portability of an executable computable phenotype.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Informatics/Phenotyping}
}

@article{panzerIncreasingDemandsQuality2013,
  title = {Increasing {{Demands}} for {{Quality Measurement}}},
  author = {Panzer, Robert J. and Gitomer, Richard S. and Greene, William H. and Webster, Patricia Reagan and Landry, Kevin R. and Riccobono, Charles A.},
  year = {2013},
  month = nov,
  volume = {310},
  pages = {1971--1980},
  publisher = {{American Medical Association}},
  issn = {0098-7484},
  doi = {10.1001/jama.2013.282047},
  url = {https://jamanetwork.com/journals/jama/fullarticle/1769892},
  urldate = {2020-05-31},
  abstract = {{$<$}p{$>$}Measurement of health care quality and patient safety is rapidly evolving, in response to long-term needs and more recent efforts to reform the US health system around ``value.'' Development and choice of quality measures is now guided by a national quality strategy and priorities, with a public-private partnership, the National Quality Forum, helping determine the most worthwhile measures for evaluating and rewarding quality and safety of patient care. Yet there remain a number of challenges, including diverse purposes for quality measurement, limited availability of true clinical measures leading to frequent reliance on claims data with its flaws in determining quality, fragmentation of measurement systems with redundancy and conflicting conclusions, few high-quality comprehensive measurement systems and registries, and rapid expansion of required measures with hundreds of measures straining resources. The proliferation of quality measures at the clinician, hospital, and insurer level has created challenges and logistical problems. Recommendations include raising the bar for qualtiy measurements to achieve transformational rather than incremental change in the US quality measurement system, promoting a logical set of measures for the various levels of the health system, leaving room for internal organizational improvement, harmonizing the various national and local quality measurement systems, anchoring on National Quality Forum additions and subtractions of measures to be applied, reducing reliance on and retiring claims-based measures as quickly as possible, promoting comprehensive measurement such as through registries with deep understanding of patient risk factors and outcomes, reducing attention to proprietary report cards, prompt but careful transition to measures from electronic health records, and allocation of sufficient resources to accomplish the goals of an efficient, properly focused measurement system.{$<$}/p{$>$}},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FUAG6J6L/Panzer et al. - 2013 - Increasing Demands for Quality Measurement.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/FJQY8WIA/1769892.html},
  journal = {JAMA},
  language = {en},
  number = {18}
}

@article{pathakElectronicHealthRecordsdriven2013,
  title = {Electronic Health Records-Driven Phenotyping: Challenges, Recent Advances, and Perspectives},
  shorttitle = {Electronic Health Records-Driven Phenotyping},
  author = {Pathak, Jyotishman and Kho, Abel N and Denny, Joshua C},
  year = {2013},
  month = dec,
  volume = {20},
  pages = {e206-e211},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2013-002428},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3861925/},
  urldate = {2020-07-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/3H98Q4I3/Pathak et al_2013_Electronic health records-driven phenotyping.pdf},
  journal = {Journal of the American Medical Informatics Association : JAMIA},
  number = {e2},
  pmcid = {PMC3861925},
  pmid = {24302669}
}

@article{pathakLexGridFrameworkRepresenting2009,
  title = {{{LexGrid}}: {{A Framework}} for {{Representing}}, {{Storing}}, and {{Querying Biomedical Terminologies}} from {{Simple}} to {{Sublime}}},
  shorttitle = {{{LexGrid}}},
  author = {Pathak, J. and Solbrig, H. R. and Buntrock, J. D. and Johnson, T. M. and Chute, C. G.},
  year = {2009},
  month = may,
  volume = {16},
  pages = {305--315},
  issn = {1067-5027, 1527-974X},
  doi = {10.1197/jamia.M3006},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1197/jamia.M3006},
  urldate = {2020-04-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/IF94VIS6/Pathak et al_2009_LexGrid.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {3}
}

@article{pathakLexValueSetsApproachContextdriven2008,
  title = {{{LexValueSets}}: An Approach for Context-Driven Value Sets Extraction},
  shorttitle = {{{LexValueSets}}},
  author = {Pathak, Jyotishman and Jiang, Guoqian and Dwarkanath, Sridhar O. and Buntrock, James D. and Chute, Christopher G. and Chute, Chris},
  year = {2008},
  month = nov,
  pages = {556--560},
  issn = {1942-597X},
  abstract = {The ability to model, share and re-use value sets across medical information systems is an important requirement. However, generating value sets semi-automatically from a terminology service is an unresolved issue, in part due to the lack of linkage to clinical context patterns that provide the constraints in defining a concept domain and invocation of value sets extraction. Towards this goal, we develop and evaluate an approach for context-driven automatic value sets extraction based on a formal terminology model. The crux of the technique is to identify and define the context patterns from various domains of discourse and leverage them for value set extraction using two complementary ideas based on (i) local terms provided by the Subject Matter Experts (extensional) and (ii) Semantic definition of the concepts in coding schemes (intensional). A prototype was implemented based on SNOMED CT rendered in the LexGrid terminology model and a preliminary evaluation is presented.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/HD7TKHHB/Pathak et al_2008_LexValueSets.pdf},
  journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
  keywords = {Algorithms,Artificial Intelligence,Information Storage and Retrieval,Medical Records Systems; Computerized,Natural Language Processing,Pattern Recognition; Automated,Subject Headings,United States},
  language = {eng},
  pmcid = {PMC2656093},
  pmid = {18998955}
}

@article{pathakMappingClinicalPhenotype2011,
  title = {Mapping Clinical Phenotype Data Elements to Standardized Metadata Repositories and Controlled Terminologies: The {{eMERGE Network}} Experience},
  shorttitle = {Mapping Clinical Phenotype Data Elements to Standardized Metadata Repositories and Controlled Terminologies},
  author = {Pathak, Jyotishman and Wang, Janey and Kashyap, Sudha and Basford, Melissa and Li, Rongling and Masys, Daniel R and Chute, Christopher G},
  year = {2011},
  month = jul,
  volume = {18},
  pages = {376--386},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/amiajnl-2010-000061},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2010-000061},
  urldate = {2020-04-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/TZY2V2N4/Pathak et al_2011_Mapping clinical phenotype data elements to standardized metadata repositories.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {4}
}

@article{pathakNormalizationStandardizationElectronic2013,
  title = {Normalization and Standardization of Electronic Health Records for High-Throughput Phenotyping: The {{SHARPn}} Consortium},
  author = {Pathak, Jyotishman and Bailey, Kent R and Beebe, Calvin E and Bethard, Steven and Carrell, David S and Chen, Pei J and Dligach, Dmitriy and Endle, Cory M and Hart, Lacey A and Haug, Peter J and {Others}},
  year = {2013},
  volume = {20},
  pages = {e341-e348},
  issn = {1067-5027},
  url = {https://academic.oup.com/jamia/article-abstract/20/e2/e341/2909250},
  abstract = {Abstract Research objective To develop scalable informatics infrastructure
for normalization of both structured and unstructured electronic health
record (EHR) data into a unified, concept-based model for high-throughput
phenotype extraction. Materials and methods},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/C5H5AMSH/Pathak et al_2013_Normalization and standardization of electronic health records for.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Informatics/Phenotyping},
  number = {e2}
}

@article{peissigImportanceMultimodalApproaches2012,
  title = {Importance of Multi-Modal Approaches to Effectively Identify Cataract Cases from Electronic Health Records},
  author = {Peissig, Peggy L. and Rasmussen, Luke V. and Berg, Richard L. and Linneman, James G. and McCarty, Catherine A. and Waudby, Carol and Chen, Lin and Denny, Joshua C. and Wilke, Russell A. and Pathak, Jyotishman and Carrell, David and Kho, Abel N. and Starren, Justin B.},
  year = {2012 Mar-Apr},
  volume = {19},
  pages = {225--234},
  issn = {1527-974X},
  doi = {10.1136/amiajnl-2011-000456},
  abstract = {OBJECTIVE: There is increasing interest in using electronic health records (EHRs) to identify subjects for genomic association studies, due in part to the availability of large amounts of clinical data and the expected cost efficiencies of subject identification. We describe the construction and validation of an EHR-based algorithm to identify subjects with age-related cataracts.
MATERIALS AND METHODS: We used a multi-modal strategy consisting of structured database querying, natural language processing on free-text documents, and optical character recognition on scanned clinical images to identify cataract subjects and related cataract attributes. Extensive validation on 3657 subjects compared the multi-modal results to manual chart review. The algorithm was also implemented at participating electronic MEdical Records and GEnomics (eMERGE) institutions.
RESULTS: An EHR-based cataract phenotyping algorithm was successfully developed and validated, resulting in positive predictive values (PPVs) {$>$}95\%. The multi-modal approach increased the identification of cataract subject attributes by a factor of three compared to single-mode approaches while maintaining high PPV. Components of the cataract algorithm were successfully deployed at three other institutions with similar accuracy.
DISCUSSION: A multi-modal strategy incorporating optical character recognition and natural language processing may increase the number of cases identified while maintaining similar PPVs. Such algorithms, however, require that the needed information be embedded within clinical documents.
CONCLUSION: We have demonstrated that algorithms to identify and characterize cataracts can be developed utilizing data collected via the EHR. These algorithms provide a high level of accuracy even when implemented across multiple EHRs and institutional boundaries.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/ED36IBTE/Peissig et al_2012_Importance of multi-modal approaches to effectively identify cataract cases.pdf},
  journal = {Journal of the American Medical Informatics Association: JAMIA},
  keywords = {Adult,Cataract,Databases; Factual,Electronic Health Records,Humans,Information Storage and Retrieval,Natural Language Processing,Phenotype},
  language = {eng},
  number = {2},
  pmcid = {PMC3277618},
  pmid = {22319176}
}

@article{petersonMiningHierarchiesSimilarity2017,
  title = {Mining {{Hierarchies}} and {{Similarity Clusters}} from {{Value Set Repositories}}},
  author = {Peterson, Kevin J. and Jiang, Guoqian and Brue, Scott M. and Shen, Feichen and Liu, Hongfang},
  year = {2017},
  volume = {2017},
  pages = {1372--1381},
  issn = {1942-597X},
  abstract = {A value set is a collection of permissible values used to describe a specific conceptual domain for a given purpose. By helping to establish a shared semantic understanding across use cases, these artifacts are important enablers of interoperability and data standardization. As the size of repositories cataloging these value sets expand, knowledge management challenges become more pronounced. Specifically, discovering value sets applicable to a given use case may be challenging in a large repository. In this study, we describe methods to extract implicit relationships between value sets, and utilize these relationships to overlay organizational structure onto value set repositories. We successfully extract two different structurings, hierarchy and clustering, and show how tooling can leverage these structures to enable more effective value set discovery.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/VV8NIX3V/Peterson et al_2017_Mining Hierarchies and Similarity Clusters from Value Set Repositories.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  keywords = {Cluster Analysis,Data Mining,Health Information Interoperability,Semantics,Vocabulary; Controlled},
  language = {eng},
  pmcid = {PMC5977603},
  pmid = {29854206}
}

@inproceedings{pineWorkReuseBirth2016,
  title = {The {{Work}} of {{Reuse}}: {{Birth Certificate Data}} and {{Healthcare Accountability Measurements}}},
  shorttitle = {The {{Work}} of {{Reuse}}},
  booktitle = {{{iConference}} 2016 {{Proceedings}}},
  author = {Pine, Kathleen},
  year = {2016},
  month = mar,
  publisher = {{iSchools}},
  address = {{Philadelphia, USA}},
  doi = {10.9776/16320},
  url = {https://www.ideals.illinois.edu/handle/2142/89310},
  urldate = {2020-04-20},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GG63KH4C/Pine_2016_The Work of Reuse.pdf},
  isbn = {978-0-9884900-2-4},
  language = {en}
}

@article{plesserReproducibilityVsReplicability2018,
  title = {Reproducibility vs. {{Replicability}}: {{A Brief History}} of a {{Confused Terminology}}},
  shorttitle = {Reproducibility vs. {{Replicability}}},
  author = {Plesser, Hans E.},
  year = {2018},
  month = jan,
  volume = {11},
  issn = {1662-5196},
  doi = {10.3389/fninf.2017.00076},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778115/},
  urldate = {2020-08-09},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/Z6LAFQ5T/Plesser_2018_Reproducibility vs.pdf},
  journal = {Frontiers in Neuroinformatics},
  pmcid = {PMC5778115},
  pmid = {29403370}
}

@inproceedings{puriMultipleOntologiesHealthcare2011,
  title = {Multiple {{Ontologies}} in {{Healthcare Information Technology}}: {{Motivations}} and {{Recommendation}} for {{Ontology Mapping}} and {{Alignment}}},
  booktitle = {{{ICBO}}},
  author = {Puri, Colin A and Gomadam, Karthik and Jain, Prateek and Yeh, Peter Z and Verma, Kunal},
  year = {2011},
  publisher = {{ceur-ws.org}},
  url = {http://ceur-ws.org/Vol-833/paper70.pdf},
  abstract = {\ldots{} Nucleic acids research, 32(suppl 1):D267, 2004. 7. O. Bodenreider .
Visualization tools for the Unified Medical Language System ( Sem ! Nav ),
the Gene Ontology (GenNav), and RxNorm. In Humans and the Semantic Web
HCIL Workshop, 2006 \ldots},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XB8AWKND/Puri et al_2011_Multiple Ontologies in Healthcare Information Technology.pdf}
}

@article{rasmussenConsiderationsImprovingPortability2020,
  title = {Considerations for {{Improving}} the {{Portability}} of {{Electronic Health Record}}-{{Based Phenotype Algorithms}}},
  author = {Rasmussen, Luke V. and Brandt, Pascal S. and Jiang, Guoqian and Kiefer, Richard C. and Pacheco, Jennifer A. and Adekkanattu, Prakash and Ancker, Jessica S. and Wang, Fei and Xu, Zhenxing and Pathak, Jyotishman and Luo, Yuan},
  year = {2020},
  month = mar,
  volume = {2019},
  pages = {755--764},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7153055/},
  urldate = {2020-04-21},
  abstract = {With the increased adoption of electronic health records, data collected for routine clinical care is used for health outcomes and population sciences research, including the identification of phenotypes. In recent years, research networks, such as eMERGE, OHDSI and PCORnet, have been able to increase statistical power and population diversity by combining patient cohorts. These networks share phenotype algorithms that are executed at each participating site. Here we observe experiences with phenotype algorithm portability across seven research networks and propose a generalizable framework for phenotype algorithm portability. Several strategies exist to increase the portability of phenotype algorithms, reducing the implementation effort needed by each site. These include using a common data model, standardized representation of the phenotype algorithm logic, and technical solutions to facilitate federated execution of queries. Portability is achieved by tradeoffs across three domains: Data, Authoring and Implementation, and multiple approaches were observed in representing portable phenotype algorithms. Our proposed framework will help guide future research in operationalizing phenotype algorithm portability at scale.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BXIYYQYQ/Rasmussen et al_2020_Considerations for Improving the Portability of Electronic Health Record-Based.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC7153055},
  pmid = {null}
}

@article{rasmussenDesignPatternsDevelopment2014,
  title = {Design Patterns for the Development of Electronic Health Record-Driven Phenotype Extraction Algorithms},
  author = {Rasmussen, Luke V. and Thompson, Will K. and Pacheco, Jennifer A. and Kho, Abel N. and Carrell, David S. and Pathak, Jyotishman and Peissig, Peggy L. and Tromp, Gerard and Denny, Joshua C. and Starren, Justin B.},
  year = {2014},
  month = oct,
  volume = {51},
  pages = {280--286},
  issn = {15320464},
  doi = {10.1016/j.jbi.2014.06.007},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046414001452},
  urldate = {2020-07-27},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6FXJP9NT/Rasmussen et al_2014_Design patterns for the development of electronic health record-driven.pdf},
  journal = {Journal of Biomedical Informatics},
  language = {en}
}

@article{rasmussenModularArchitectureElectronic2015,
  title = {A {{Modular Architecture}} for {{Electronic Health Record}}-{{Driven Phenotyping}}},
  author = {Rasmussen, Luke V and Kiefer, Richard C and Mo, Huan and Speltz, Peter and Thompson, William K and Jiang, Guoqian and Pacheco, Jennifer A and Xu, Jie and Zhu, Qian and Denny, Joshua C and Montague, Enid and Pathak, Jyotishman},
  year = {2015},
  month = mar,
  volume = {2015},
  pages = {147--151},
  issn = {2153-4063},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/26306258},
  abstract = {Increasing interest in and experience with electronic health record
(EHR)-driven phenotyping has yielded multiple challenges that are at
present only partially addressed. Many solutions require the adoption of a
single software platform, often with an additional cost of mapping
existing patient and phenotypic data to multiple representations. We
propose a set of guiding design principles and a modular software
architecture to bridge the gap to a standardized phenotype representation,
dissemination and execution. Ongoing development leveraging this proposed
architecture has shown its ability to address existing limitations.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RZRZDYZP/Rasmussen et al_2015_A Modular Architecture for Electronic Health Record-Driven Phenotyping.pdf},
  journal = {AMIA Jt Summits Transl Sci Proc},
  keywords = {Informatics/Phenotyping}
}

@article{rectorBindingOntologiesCoding2009,
  title = {Binding Ontologies and Coding Systems to Electronic Health Records and Messages},
  author = {Rector, Alan L and Qamar, Rahil and Marley, Tom},
  year = {2009},
  volume = {4},
  pages = {51--69},
  issn = {1570-5838},
  url = {https://content.iospress.com/articles/applied-ontology/ao063},
  abstract = {A major use of medical ontologies is to support coding systems for use in
electronic healthcare records and messages. A key task is to define which
codes are to be used where\textendash{} to bind the terminology to the model of the
medical record or message. To achieve this formally, it is necessary to
recognise that the model of codes and information models are at a
meta-level with respect to the underlying ontology. A methodology for
defining a Code Binding Interface in OWL is presented which illustrates
this point. It generalises \ldots},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/5PKZL6SC/Rector et al_2009_Binding ontologies and coding systems to electronic health records and messages.pdf},
  journal = {Appl. Ontol.},
  keywords = {Active papers/AMIA VS},
  number = {1}
}

@article{rectorGruberOntologiesToday2019,
  title = {On beyond {{Gruber}}: ``{{Ontologies}}'' in Today's Biomedical Information Systems and the Limits of {{OWL}}},
  shorttitle = {On beyond {{Gruber}}},
  author = {Rector, Alan and Schulz, Stefan and Rodrigues, Jean Marie and Chute, Christopher G and Solbrig, Harold},
  year = {2019},
  month = jun,
  volume = {2},
  pages = {100002},
  issn = {2590-177X},
  doi = {10.1016/j.yjbinx.2019.100002},
  url = {http://www.sciencedirect.com/science/article/pii/S2590177X19300010},
  urldate = {2020-04-27},
  abstract = {The word ``ontology'' was introduced to information systems when only closed-world reasoning systems were available. It was ``borrowed'' from philosophy, but literal links to its philosophical meaning were explicitly disavowed. Since then, open-world reasoning systems based on description logics have been developed, OWL has become a standard, and philosophical issues have been raised. The result has too often been confusion. The question ``What statements are ontological'' receives a variety of answers. A clearer vocabulary that is better suited to today's information systems is needed. The project to base ICD-11 on a ``Common Ontology'' required addressing this confusion. This paper sets out to systematise the lessons of that experience and subsequent discussions. We explore the semantics of open-world and closed-world systems. For specifying knowledge bases and software, we propose ``invariants'' or, more fully, ``the first order invariant part of the background domain knowledge base'' as an alternative to the words ``ontology'' and ``ontological.'' We discuss the role and limitations of OWL and description logics and how they are complementary to closed world systems such as frames and to less formal ``knowledge organisation systems''. We illustrate why the conventions of classifications such as ICD cannot be formulated directly in OWL, but can be linked to OWL knowledge bases by queries. We contend that while OWL and description logics are major advances for representing invariants and terminologies, they must be combined with other technologies to represent broader background knowledge faithfully. The ICD-11 architecture is one approach. We argue that such hybrid architectures can and should be developed further.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4RF2UU9G/Rector et al_2019_On beyond Gruber.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/I7ZPTVW4/S2590177X19300010.html},
  journal = {Journal of Biomedical Informatics: X},
  keywords = {Description logics,ICD,Knowledge representation,Ontology,OWL,Terminology},
  language = {en}
}

@article{rectorWhatCodeFormal2007,
  title = {What's in a Code? {{Towards}} a Formal Account of the Relation of Ontologies and Coding Systems},
  shorttitle = {What's in a Code?},
  author = {Rector, Alan L.},
  year = {2007},
  volume = {129},
  pages = {730--734},
  issn = {0926-9630},
  abstract = {Terminologies are increasingly based on "ontologies" developed in description logics and related languages such as the new Web Ontology Language, OWL. The use of description logic has been expected to reduce ambiguity and make it easier determine logical equivalence, deal with negation, and specify EHRs. However, this promise has not been fully realised: in part because early description logics were relatively inexpressive, in part, because the relation between coding systems, EHRs, and ontologies expressed in description logics has not been fully understood. This paper presents a unifying approach using the expressive formalisms available in the latest version of OWL, OWL 1.1.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/EJCHZL94/Rector_2007_What's in a code.pdf},
  journal = {Studies in Health Technology and Informatics},
  keywords = {Classification,Forms and Records Control,Logic,Medical Records Systems; Computerized,Programming Languages,Software,Vocabulary; Controlled},
  language = {eng},
  number = {Pt 1},
  pmid = {17911813}
}

@article{reichEvaluationAlternativeStandardized2012,
  title = {Evaluation of Alternative Standardized Terminologies for Medical Conditions within a Network of Observational Healthcare Databases},
  author = {Reich, Christian and Ryan, Patrick B and Stang, Paul E and Rocca, Mitra},
  year = {2012},
  month = aug,
  volume = {45},
  pages = {689--696},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2012.05.002},
  url = {http://dx.doi.org/10.1016/j.jbi.2012.05.002},
  abstract = {Large electronic databases of health care information, such as
administrative claims and electronic health records, are available and are
being used in a number of public health settings, including drug safety
surveillance. However, because of a lack of standardization, clinical
terminologies may differ across databases. With the aid of existing
resources and expert coders, we have developed mapping tables to convert
ICD-9-CM diagnosis codes used in some existing databases to SNOMED-CT and
MedDRA. In addition, previously developed definitions for specific health
outcomes of interest were mapped to the same standardized vocabularies. We
evaluated how vocabulary mapping affected (1) the retention of clinical
data from two test databases, (2) the semantic space of outcome
definitions, (3) the prevalence of each outcome in the test databases, and
(4) the reliability of analytic methods designed to detect drug-outcome
associations in the test databases. Although vocabulary mapping affected
the semantic space of some outcome definitions, as well as the prevalence
of some outcomes in the test databases, it had only minor effects on the
analysis of drug-outcome associations. Furthermore, both SNOMED-CT and
MedDRA were viable for use as standardized vocabularies in systems
designed to perform active medical product surveillance using disparate
sources of observational data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/X3KDP985/Reich et al_2012_Evaluation of alternative standardized terminologies for medical conditions.pdf},
  journal = {J. Biomed. Inform.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background},
  number = {4}
}

@misc{reichStandardClassificationSource,
  title = {Standard, {{Classification}} and {{Source Concepts}}},
  author = {Reich, Christian},
  url = {http://www.ohdsi.org/web/wiki/doku.php?id=documentation:vocabulary:standard_classification_and_source_concepts},
  urldate = {2019-05-19},
  journal = {OHDSI Wiki}
}

@inproceedings{ribesKernelResearchInfrastructure2014,
  title = {The Kernel of a Research Infrastructure},
  booktitle = {Proceedings of the 17th {{ACM}} Conference on {{Computer}} Supported Cooperative Work \& Social Computing},
  author = {Ribes, David},
  year = {2014},
  month = feb,
  pages = {574--587},
  publisher = {{Association for Computing Machinery}},
  address = {{Baltimore, Maryland, USA}},
  doi = {10.1145/2531602.2531700},
  url = {https://doi.org/10.1145/2531602.2531700},
  urldate = {2020-02-27},
  abstract = {Infrastructure makes it easier, faster or possible for investigators to study objects of research. It does so by making available consistent and stable resources and services such as data, collaboration tools, sites of sample collection, or calibrated instruments. This paper offers the concept of the kernel of a research infrastructure as a new unit of analysis for investigating the enabling capacities of infrastructure. The kernel is the core resources and services an infrastructure makes available (called the cache), as well as the work, techniques and technologies that go into sustaining that availability (called addressing). By inspecting and comparing the kernel of two long-term scientific enterprises, this paper demonstrates how focusing on the kernel can help explain key qualities of research infrastructure such as flexibility and persistence in the face of dramatic changes to the objects, methods and practice of science.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/U9CSFCHE/Ribes_2014_The kernel of a research infrastructure.pdf},
  isbn = {978-1-4503-2540-0},
  keywords = {change,ethnography and archival research,grounded theory,infrastructure,kernel,long-term,science,sustainability,technoscientific flexibility},
  series = {{{CSCW}} '14}
}

@inproceedings{ribesNotesConceptData2017,
  title = {Notes on the {{Concept}} of {{Data Interoperability}}: {{Cases}} from an {{Ecology}} of {{AIDS Research Infrastructures}}},
  shorttitle = {Notes on the {{Concept}} of {{Data Interoperability}}},
  booktitle = {Proceedings of the 2017 {{ACM Conference}} on {{Computer Supported Cooperative Work}} and {{Social Computing}}},
  author = {Ribes, David},
  year = {2017},
  month = feb,
  pages = {1514--1526},
  publisher = {{Association for Computing Machinery}},
  address = {{Portland, Oregon, USA}},
  doi = {10.1145/2998181.2998344},
  url = {https://doi.org/10.1145/2998181.2998344},
  urldate = {2020-03-05},
  abstract = {Data interoperation functions with the logic of a black box. Interoperation is achieved through front-loaded work and epistemically charged negotiation that thereafter become infrastructural, that is, supporting downstream actions without fully revealing the underpinnings that enable those actions. Drawing from ethnographic and archival investigations of data interoperation within and across an ecology of HIV/AIDS research infrastructures, this paper offers several sensitizing concepts for the investigation of how data are brought together and thereafter circulate. Data interoperability is historical, infrastructural, relatively irreversible, negotiated, epistemic, seamful and seamless, and is approaching the status of a general value rather than a specific means to an end.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PKGTTBVH/Ribes_2017_Notes on the Concept of Data Interoperability.pdf},
  isbn = {978-1-4503-4335-0},
  keywords = {archival and historical research,data,ethnography,hiv/aids,infrastructure,interoperability},
  series = {{{CSCW}} '17}
}

@article{richessonClinicalPhenotypingSelected2016,
  title = {Clinical Phenotyping in Selected National Networks: Demonstrating the Need for High-Throughput, Portable, and Computational Methods},
  author = {Richesson, Rachel L and Sun, Jimeng and Pathak, Jyotishman and Kho, Abel N and Denny, Joshua C},
  year = {2016},
  month = jul,
  volume = {71},
  pages = {57--61},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2016.05.005},
  url = {http://dx.doi.org/10.1016/j.artmed.2016.05.005},
  abstract = {OBJECTIVE: The combination of phenomic data from electronic health records
(EHR) and clinical data repositories with dense biological data has
enabled genomic and pharmacogenomic discovery, a first step toward
precision medicine. Computational methods for the identification of
clinical phenotypes from EHR data will advance our understanding of
disease risk and drug response, and support the practice of precision
medicine on a national scale. METHODS: Based on our experience within
three national research networks, we summarize the broad approaches to
clinical phenotyping and highlight the important role of these networks in
the progression of high-throughput phenotyping and precision medicine. We
provide supporting literature in the form of a non-systematic review.
RESULTS: The practice of clinical phenotyping is evolving to meet the
growing demand for scalable, portable, and data driven methods and tools.
The resources required for traditional phenotyping algorithms from expert
defined rules are significant. In contrast, machine learning approaches
that rely on data patterns will require fewer clinical domain experts and
resources. CONCLUSIONS: Machine learning approaches that generate
phenotype definitions from patient features and clinical profiles will
result in truly computational phenotypes, derived from data rather than
experts. Research networks and phenotype developers should cooperate to
develop methods, collaboration platforms, and data standards that will
enable computational phenotyping and truly modernize biomedical research
and precision medicine.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4JNUZV2G/Richesson et al_2016_Clinical phenotyping in selected national networks.pdf},
  journal = {Artif. Intell. Med.},
  keywords = {Active papers/AMIA VS,Clinical phenotyping,Electronic health records,Informatics/Phenotyping,Machine learning,Networked research,Precision medicine}
}

@article{richessonComparisonPhenotypeDefinitions2013,
  title = {A Comparison of Phenotype Definitions for Diabetes Mellitus},
  author = {Richesson, Rachel L and Rusincovitch, Shelley A and Wixted, Douglas and Batch, Bryan C and Feinglos, Mark N and Miranda, Marie Lynn and Hammond, W Ed and Califf, Robert M and Spratt, Susan E},
  year = {2013},
  month = dec,
  volume = {20},
  pages = {e319-26},
  issn = {1067-5027},
  doi = {10.1136/amiajnl-2013-001952},
  url = {http://dx.doi.org/10.1136/amiajnl-2013-001952},
  abstract = {OBJECTIVE: This study compares the yield and characteristics of diabetes
cohorts identified using heterogeneous phenotype definitions. MATERIALS
AND METHODS: Inclusion criteria from seven diabetes phenotype definitions
were translated into query algorithms and applied to a population (n=173
503) of adult patients from Duke University Health System. The numbers of
patients meeting criteria for each definition and component (diagnosis,
diabetes-associated medications, and laboratory results) were compared.
RESULTS: Three phenotype definitions based heavily on ICD-9-CM codes
identified 9-11\% of the patient population. A broad definition for the
Durham Diabetes Coalition included additional criteria and identified 13\%.
The electronic medical records and genomics, NYC A1c Registry, and
diabetes-associated medications definitions, which have restricted or no
ICD-9-CM criteria, identified the smallest proportions of patients (7\%).
The demographic characteristics for all seven phenotype definitions were
similar (56-57\% women, mean age range 56-57 years).The NYC A1c Registry
definition had higher average patient encounters (54) than the other
definitions (range 44-48) and the reference population (20) over the
5-year observation period. The concordance between populations returned by
different phenotype definitions ranged from 50 to 86\%. Overall, more
patients met ICD-9-CM and laboratory criteria than medication criteria,
but the number of patients that met abnormal laboratory criteria
exclusively was greater than the numbers meeting diagnostic or medication
data exclusively. DISCUSSION: Differences across phenotype definitions can
potentially affect their application in healthcare organizations and the
subsequent interpretation of data. CONCLUSIONS: Further research focused
on defining the clinical characteristics of standard diabetes cohorts is
important to identify appropriate phenotype definitions for health,
policy, and research.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BAV57AXZ/Richesson et al_2013_A comparison of phenotype definitions for diabetes mellitus.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,Clinical Research,Diabetes,Electronic health records,Informatics/Phenotyping,Patient Registries,Phenotypes,Secondary Data Use},
  number = {e2}
}

@article{richessonDataStandardsClinical2007,
  title = {Data Standards in Clinical Research: Gaps, Overlaps, Challenges and Future Directions},
  author = {Richesson, Rachel L and Krischer, Jeffrey},
  year = {2007},
  month = nov,
  volume = {14},
  pages = {687--696},
  issn = {1067-5027},
  doi = {10.1197/jamia.M2470},
  url = {http://dx.doi.org/10.1197/jamia.M2470},
  abstract = {Current efforts to define and implement health data standards are driven
by issues related to the quality, cost and continuity of care, patient
safety concerns, and desires to speed clinical research findings to the
bedside. The President's goal for national adoption of electronic medical
records in the next decade, coupled with the current emphasis on
translational research, underscore the urgent need for data standards in
clinical research. This paper reviews the motivations and requirements for
standardized clinical research data, and the current state of standards
development and adoption--including gaps and overlaps--in relevant areas.
Unresolved issues and informatics challenges related to the adoption of
clinical research data and terminology standards are mentioned, as are the
collaborations and activities the authors perceive as most likely to
address them.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/VZGQ8H9T/Richesson_Krischer_2007_Data standards in clinical research.pdf},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Informatics/Phenotyping},
  number = {6}
}

@article{richessonElectronicHealthRecords2013,
  title = {Electronic Health Records Based Phenotyping in Next-Generation Clinical Trials: A Perspective from the {{NIH Health Care Systems Collaboratory}}},
  shorttitle = {Electronic Health Records Based Phenotyping in Next-Generation Clinical Trials},
  author = {Richesson, Rachel L. and Hammond, W. Ed and Nahm, Meredith and Wixted, Douglas and Simon, Gregory E. and Robinson, Jennifer G. and Bauck, Alan E. and Cifelli, Denise and Smerek, Michelle M. and Dickerson, John and Laws, Reesa L. and Madigan, Rosemary A. and Rusincovitch, Shelley A. and Kluchar, Cynthia and Califf, Robert M.},
  year = {2013},
  month = dec,
  volume = {20},
  pages = {e226-231},
  issn = {1527-974X},
  doi = {10.1136/amiajnl-2013-001926},
  abstract = {Widespread sharing of data from electronic health records and patient-reported outcomes can strengthen the national capacity for conducting cost-effective clinical trials and allow research to be embedded within routine care delivery. While pragmatic clinical trials (PCTs) have been performed for decades, they now can draw on rich sources of clinical and operational data that are continuously fed back to inform research and practice. The Health Care Systems Collaboratory program, initiated by the NIH Common Fund in 2012, engages healthcare systems as partners in discussing and promoting activities, tools, and strategies for supporting active participation in PCTs. The NIH Collaboratory consists of seven demonstration projects, and seven problem-specific working group 'Cores', aimed at leveraging the data captured in heterogeneous 'real-world' environments for research, thereby improving the efficiency, relevance, and generalizability of trials. Here, we introduce the Collaboratory, focusing on its Phenotype, Data Standards, and Data Quality Core, and present early observations from researchers implementing PCTs within large healthcare systems. We also identify gaps in knowledge and present an informatics research agenda that includes identifying methods for the definition and appropriate application of phenotypes in diverse healthcare settings, and methods for validating both the definition and execution of electronic health records based phenotypes.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/M8266FCK/Richesson et al_2013_Electronic health records based phenotyping in next-generation clinical trials.pdf},
  journal = {Journal of the American Medical Informatics Association: JAMIA},
  keywords = {Clinical Research,Data quality,Electronic Health Records,Humans,National Institutes of Health (U.S.),Phenotype,Phenotyping,Pragmatic Clinical Trials as Topic,Secondary Data Use,United States},
  language = {eng},
  number = {e2},
  pmcid = {PMC3861929},
  pmid = {23956018}
}

@misc{richessonElectronicHealthRecordsBased2020,
  title = {Electronic {{Health Records}}-{{Based Phenotyping}}},
  author = {Richesson, Rachel L. and Wiley, Laura K. and Gold, Sigfried and Rasmussen, Luke V., Luke},
  year = {2020},
  month = jul,
  url = {https://rethinkingclinicaltrials.org/chapters/conduct/electronic-health-records-based-phenotyping/electronic-health-records-based-phenotyping-introduction/},
  urldate = {2020-07-14},
  abstract = {NIH Health Care Systems Research Collaboratory
Bethesda, MD},
  journal = {Rethinking Clinical Trials: A Living Textbook of Pragmatic Clinical Trials}
}

@article{richessonFrameworkSupportSharing2016,
  title = {A {{Framework}} to {{Support}} the {{Sharing}} and {{Reuse}} of {{Computable Phenotype Definitions Across Health Care Delivery}} and {{Clinical Research Applications}}},
  author = {Richesson, Rachel L and Smerek, Michelle M and Blake Cameron, C},
  year = {2016},
  month = jul,
  volume = {4},
  pages = {1232},
  issn = {2327-9214},
  doi = {10.13063/2327-9214.1232},
  url = {http://dx.doi.org/10.13063/2327-9214.1232},
  abstract = {INTRODUCTION: The ability to reproducibly identify clinically equivalent
patient populations is critical to the vision of learning health care
systems that implement and evaluate evidence-based treatments. The use of
common or semantically equivalent phenotype definitions across research
and health care use cases will support this aim. Currently, there is no
single consolidated repository for computable phenotype definitions,
making it difficult to find all definitions that already exist, and also
hindering the sharing of definitions between user groups. METHOD: Drawing
from our experience in an academic medical center that supports a number
of multisite research projects and quality improvement studies, we
articulate a framework that will support the sharing of phenotype
definitions across research and health care use cases, and highlight gaps
and areas that need attention and collaborative solutions. FRAMEWORK: An
infrastructure for re-using computable phenotype definitions and sharing
experience across health care delivery and clinical research applications
includes: access to a collection of existing phenotype definitions,
information to evaluate their appropriateness for particular applications,
a knowledge base of implementation guidance, supporting tools that are
user-friendly and intuitive, and a willingness to use them. NEXT STEPS: We
encourage prospective researchers and health administrators to re-use
existing EHR-based condition definitions where appropriate and share their
results with others to support a national culture of learning health care.
There are a number of federally funded resources to support these
activities, and research sponsors should encourage their use.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GDWNHYQ5/Richesson et al_2016_A Framework to Support the Sharing and Reuse of Computable Phenotype.pdf},
  journal = {EGEMS (Wash DC)},
  keywords = {Active papers/AMIA VS,Computable Phenotypes,Data Standards,Electronic health records,Informatics/Phenotyping,Learning Health Care Systems},
  number = {3}
}

@article{rogersSNOMEDCTBrowsing2008,
  title = {{{SNOMED CT}}: {{Browsing}} the {{Browsers}}},
  author = {Rogers, J and Bodenreider, O},
  year = {2008},
  pages = {7},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4Q387B5E/Rogers_Bodenreider_2008_SNOMED CT.pdf},
  language = {en}
}

@techreport{rosenberghmHistoryStatisticalClassification2011,
  title = {History of the Statistical Classification of Diseases and Causes of Death},
  author = {Rosenberg HM, Hoyert D L},
  year = {2011},
  address = {{Hyattsville, MD}},
  institution = {{National Center for Health Statistics}},
  url = {https://www.cdc.gov/nchs/data/misc/classification_diseases2011.pdf},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/JPB4TDZS/Rosenberg HM_2011_History of the statistical classification of diseases and causes of death.pdf},
  keywords = {Active papers/AMIA VS},
  type = {White {{Paper}}}
}

@article{rosenbloomRepresentingKnowledgeConsistently2017,
  title = {Representing {{Knowledge Consistently Across Health Systems}}},
  author = {Rosenbloom, S T and Carroll, R J and Warner, J L and Matheny, M E and Denny, J C},
  year = {2017},
  month = aug,
  volume = {26},
  pages = {139--147},
  issn = {0943-4747},
  doi = {10.15265/IY-2017-018},
  url = {http://dx.doi.org/10.15265/IY-2017-018},
  abstract = {Objectives: Electronic health records (EHRs) have increasingly emerged as
a powerful source of clinical data that can be leveraged for reuse in
research and in modular health apps that integrate into diverse health
information technologies. A key challenge to these use cases is
representing the knowledge contained within data from different EHR
systems in a uniform fashion. Method: We reviewed several recent studies
covering the knowledge representation in the common data models for the
Observational Medical Outcomes Partnership (OMOP) and its Observational
Health Data Sciences and Informatics program, and the United States
Patient Centered Outcomes Research Network (PCORNet). We also reviewed the
Health Level 7 Fast Healthcare Interoperability Resource standard
supporting app-like programs that can be used across multiple EHR and
research systems. Results: There has been a recent growth in high-impact
efforts to support quality-assured and standardized clinical data sharing
across different institutions and EHR systems. We focused on three major
efforts as part of a larger landscape moving towards shareable,
transportable, and computable clinical data. Conclusion: The growth in
approaches to developing common data models to support interoperable
knowledge representation portends an increasing availability of
high-quality clinical data in support of research. Building on these
efforts will allow a future whereby significant portions of the
populations in the world may be able to share their data for research.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/8EIJ8JKN/Rosenbloom et al_2017_Representing Knowledge Consistently Across Health Systems.pdf},
  journal = {Yearb. Med. Inform.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/essential (all collaborators should peruse),Informatics/med recs / cdms,Random stuff to show Rachel Paperpile},
  number = {1}
}

@article{sachdevaSemanticInteroperabilityStandardized2012,
  title = {Semantic Interoperability in Standardized Electronic Health Record Databases},
  author = {Sachdeva, Shelly and Bhalla, Subhash},
  year = {2012},
  month = may,
  volume = {3},
  pages = {1:1--1:37},
  issn = {1936-1955},
  doi = {10.1145/2166788.2166789},
  url = {https://doi.org/10.1145/2166788.2166789},
  urldate = {2020-03-05},
  abstract = {Different clinics and hospitals have their own information systems to maintain patient data. This hinders the exchange of data among systems (and organizations). Hence there is a need to provide standards for data exchange. In digitized form, the individual patient's medical record can be stored, retrieved, and shared over a network through enhancement in information technology. Thus, electronic health records (EHRs) should be standardized, incorporating semantic interoperability. A subsequent step requires that healthcare professionals and patients get involved in using the EHRs, with the help of technological developments. This study aims to provide different approaches in understanding some current and challenging concepts in health informatics. Successful handling of these challenges will lead to improved quality in healthcare by reducing medical errors, decreasing costs, and enhancing patient care. The study is focused on the following goals: (1) understanding the role of EHRs; (2) understanding the need for standardization to improve quality; (3) establishing interoperability in maintaining EHRs; (4) examining a framework for standardization and interoperability (the openEHR architecture; (5) identifying the role of archetypes for knowledge-based systems; and (6) understanding the difficulties in querying HER data.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BYQNE24F/Sachdeva_Bhalla_2012_Semantic interoperability in standardized electronic health record databases.pdf},
  journal = {Journal of Data and Information Quality},
  keywords = {archetype-based EHR,data quality in healthcare,Electronic health records,openEHR,quality-based EHR,semantic interoperability,standardization in EHR},
  number = {1}
}

@article{safranNationalFrameworkSecondary2007,
  title = {Toward a National Framework for the Secondary Use of Health Data: An {{American Medical Informatics Association White Paper}}},
  shorttitle = {Toward a National Framework for the Secondary Use of Health Data},
  author = {Safran, Charles and Bloomrosen, Meryl and Hammond, W. Edward and Labkoff, Steven and {Markel-Fox}, Suzanne and Tang, Paul C. and Detmer, Don E. and Expert Panel, null},
  year = {2007 Jan-Feb},
  volume = {14},
  pages = {1--9},
  issn = {1067-5027},
  doi = {10.1197/jamia.M2273},
  abstract = {Secondary use of health data applies personal health information (PHI) for uses outside of direct health care delivery. It includes such activities as analysis, research, quality and safety measurement, public health, payment, provider certification or accreditation, marketing, and other business applications, including strictly commercial activities. Secondary use of health data can enhance health care experiences for individuals, expand knowledge about disease and appropriate treatments, strengthen understanding about effectiveness and efficiency of health care systems, support public health and security goals, and aid businesses in meeting customers' needs. Yet, complex ethical, political, technical, and social issues surround the secondary use of health data. While not new, these issues play increasingly critical and complex roles given current public and private sector activities not only expanding health data volume, but also improving access to data. Lack of coherent policies and standard "good practices" for secondary use of health data impedes efforts to strengthen the U.S. health care system. The nation requires a framework for the secondary use of health data with a robust infrastructure of policies, standards, and best practices. Such a framework can guide and facilitate widespread collection, storage, aggregation, linkage, and transmission of health data. The framework will provide appropriate protections for legitimate secondary use.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/UH99698T/Safran et al_2007_Toward a national framework for the secondary use of health data.pdf},
  journal = {Journal of the American Medical Informatics Association: JAMIA},
  keywords = {Access to Information,Biomedical Research,Confidentiality,Health Policy,Health Services Research,Humans,Informed Consent,Medical Records,Societies; Medical,United States},
  language = {eng},
  number = {1},
  pmcid = {PMC2329823},
  pmid = {17077452}
}

@inproceedings{sanchez-ruizGenericImmersiveCollaborative2008,
  title = {Toward Generic, Immersive, and Collaborative Solutions to the Data Interoperability Problem Which Target End-Users},
  booktitle = {Proceedings of the 2nd International Workshop on {{Ontologies}} and Information Systems for the Semantic Web},
  author = {{S{\'a}nchez-Ru{\'i}z}, Arturo J. and Umapathy, Karthikeyan and Hayes, Pat},
  year = {2008},
  month = oct,
  pages = {83--88},
  publisher = {{Association for Computing Machinery}},
  address = {{Napa Valley, California, USA}},
  doi = {10.1145/1458484.1458489},
  url = {https://doi.org/10.1145/1458484.1458489},
  urldate = {2020-03-05},
  abstract = {In this position paper we describe our vision of a "just-in-time" approach to the Data Interoperability Problem (a.k.a. INTEROP.) It empowers data stakeholders (e.g. data producers and data consumers) with integrated tools to interact and collaborate with each other while directly manipulating visual representations of their data in an immersive environment (e.g. implemented via Second Life.) The semantics of these visual representations and the operations associated with the data are supported by ontologies defined using the Common Logic Framework (CL). Data operations gestured by the stakeholders, through their avatars, are translated to a variety of generated resources such as multi-language source code, visualizations, web pages, and web services. The generality of the approach is supported by a plug-in architecture which allows expert users to customize tasks such as data admission, data manipulation in the immersive world, and automatic generation of resources. This approach is designed with a mindset aimed at enabling stake-holders from diverse domains to exchange data and generate new knowledge.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FDNLWP9C/Sánchez-Ruíz et al_2008_Toward generic, immersive, and collaborative solutions to the data.pdf},
  isbn = {978-1-60558-255-9},
  keywords = {CL,data interoperability,end-user approaches,IKL,immersive collaboration,INTEROP,ontologies,plug-in architectures,Second Life},
  series = {{{ONISW}} '08}
}

@article{sansoneFAIRsharingCommunityApproach2019,
  title = {{{FAIRsharing}} as a Community Approach to Standards, Repositories and Policies},
  author = {Sansone, Susanna-Assunta and McQuilton, Peter and {Rocca-Serra}, Philippe and {Gonzalez-Beltran}, Alejandra and Izzo, Massimiliano and Lister, Allyson L. and Thurston, Milo},
  year = {2019},
  month = apr,
  volume = {37},
  pages = {358--367},
  issn = {1546-1696},
  doi = {10.1038/s41587-019-0080-8},
  url = {https://www.nature.com/articles/s41587-019-0080-8},
  urldate = {2020-02-27},
  copyright = {2019 The Author(s)},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/9N8WLSYA/Sansone et al_2019_FAIRsharing as a community approach to standards, repositories and policies.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/MWT3MELF/s41587-019-0080-8.html},
  journal = {Nature Biotechnology},
  language = {en},
  number = {4}
}

@inproceedings{sartipiCrossdomainInformationService2008,
  title = {Cross-Domain Information and Service Interoperability},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Information Integration}} and {{Web}}-Based {{Applications}} \& {{Services}}},
  author = {Sartipi, Kamran and Dehmoobad, Azin},
  year = {2008},
  month = nov,
  pages = {25--32},
  publisher = {{Association for Computing Machinery}},
  address = {{Linz, Austria}},
  doi = {10.1145/1497308.1497318},
  url = {https://doi.org/10.1145/1497308.1497318},
  urldate = {2020-03-05},
  abstract = {The growing trends towards integrating legacy applications with new systems in a network-centric environment has introduced yet another level of complexity beyond those we witnessed in development of large monolithic systems. In this context, most research challenges focus on interoperability within the same domain. However, provision of cross-domain interoperability among collaborating domains is a new challenge that needs more attention from the research community. Such interoperability requires data and service extraction to obtain common subsets of information and services in collaborating domains, e.g., healthcare and insurance. The first step in achieving such a large interoperability is to follow similar development processes for collaborating domains, which provides homogeneity in their architectures. The second step would be to provide intra-domain and inter-domain semantic interoperability through proprietary and shared ontology systems. In this paper, we address the above challenges through description of a framework that is based on core information standards and terminology systems and employs a guideline to achieve service interoperability among systems of the collaborating domains. A real-world case study of cross-domain interoperability among two domains healthcare and insurance is presented.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/SZIWBCPJ/Sartipi_Dehmoobad_2008_Cross-domain information and service interoperability.pdf},
  isbn = {978-1-60558-349-5},
  keywords = {cross-domain interoperability,healthcare,HL7,legacy system,standardization},
  series = {{{iiWAS}} '08}
}

@inproceedings{sayogoUnderstandingCapabilitiesCritical2011,
  title = {Understanding the Capabilities and Critical Success Factors in Collaborative Data Sharing Network: The Case of {{dataONE}}},
  shorttitle = {Understanding the Capabilities and Critical Success Factors in Collaborative Data Sharing Network},
  booktitle = {Proceedings of the 12th {{Annual International Digital Government Research Conference}}: {{Digital Government Innovation}} in {{Challenging Times}}},
  author = {Sayogo, Djoko Sigit and Pardo, Theresa A.},
  year = {2011},
  month = jun,
  pages = {74--83},
  publisher = {{Association for Computing Machinery}},
  address = {{College Park, Maryland, USA}},
  doi = {10.1145/2037556.2037568},
  url = {https://doi.org/10.1145/2037556.2037568},
  urldate = {2020-03-05},
  abstract = {This paper aims to outline the challenges, necessary dimensions of capability, and critical success factors enabling cross-boundary earth observational data sharing. Despite the profound benefits, integrating and bringing data together among researchers and across boundaries and domains presents tremendous challenges. This paper will review and integrate literature from the environmental and information science fields to identify necessary challenges, and reflect on the dimensions of capability, as well as critical success factors for data integration and sharing in collaborative data sharing networks, taking into consideration the information-sharing capability framework from Center for Technology in Government (CTG). This research effort will explore the challenges/barriers, dimensions of capability, and critical success factors in case studies of DataONE, a collaborative earth observational data sharing networks initiative.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FNAYIDW6/Sayogo_Pardo_2011_Understanding the capabilities and critical success factors in collaborative.pdf},
  isbn = {978-1-4503-0762-8},
  keywords = {capability dimensions of information sharing,collaborative network,DataONE,earth observational data sharing},
  series = {Dg.o '11}
}

@article{schneeweissBasicStudyDesign2010,
  title = {A Basic Study Design for Expedited Safety Signal Evaluation Based on Electronic Healthcare Data},
  author = {Schneeweiss, Sebastian},
  year = {2010},
  month = aug,
  volume = {19},
  pages = {858--868},
  issn = {1053-8569},
  doi = {10.1002/pds.1926},
  url = {http://dx.doi.org/10.1002/pds.1926},
  abstract = {Active drug safety monitoring based on longitudinal electronic healthcare
databases (a Sentinel System), as outlined in recent FDA-commissioned
reports, consists of several interlocked processes, including signal
generation, signal strengthening, and signal evaluation. Once a signal of
a potential drug safety issue is generated, signal strengthening and
signal evaluation have to follow in short sequence in order to quickly
provide as much information about the triggering drug-event association as
possible. This paper proposes a basic study design based on the incident
user cohort design for expedited signal evaluation in longitudinal
healthcare databases. It will not resolve all methodological issues nor
will it fit all study questions arising within the framework of a Sentinel
System. It should rather be seen as a guidance that will fit the majority
of situations and serve as a starting point for adaptations to specific
studies. Such an approach will expedite and structure the process of study
development and highlight specific assumptions, which is particularly
valuable in a Sentinel System where signals are by definition preliminary
and evaluation of signals is time critical.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/4ZAYSZ7W/Schneeweiss_2010_A basic study design for expedited safety signal evaluation based on electronic.pdf},
  journal = {Pharmacoepidemiol. Drug Saf.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Informatics/med recs / cdms,Topics/Viz/old papers from backup},
  number = {8}
}

@article{schneeweissChoosingCommonData2020,
  title = {Choosing {{Among Common Data Models}} for {{Real}}-{{World Data Analyses Fit}} for {{Making Decisions About}} the {{Effectiveness}} of {{Medical Products}}},
  author = {Schneeweiss, Sebastian and Brown, Jeff S. and Bate, Andrew and Trifir{\`o}, Gianluca and Bartels, Dorothee B.},
  year = {2020},
  month = apr,
  volume = {107},
  pages = {827--833},
  issn = {0009-9236, 1532-6535},
  doi = {10.1002/cpt.1577},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpt.1577},
  urldate = {2020-08-04},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/I934KU6E/Schneeweiss et al_2020_Choosing Among Common Data Models for Real‐World Data Analyses Fit for Making.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/UTTH3KGU/Schneeweiss et al_Choosing Among Common Data Models for Real World Data Analyses Fit for Making.pdf},
  journal = {Clinical Pharmacology \& Therapeutics},
  language = {en},
  number = {4}
}

@article{schneeweissRealWorldData2016,
  title = {Real {{World Data}} in {{Adaptive Biomedical Innovation}}: {{A Framework}} for {{Generating Evidence Fit}} for {{Decision}}-{{Making}}},
  shorttitle = {Real {{World Data}} in {{Adaptive Biomedical Innovation}}},
  author = {Schneeweiss, S and Eichler, H-G and {Garcia-Altes}, A and Chinn, C and Eggimann, A-V and Garner, S and Goettsch, W and Lim, R and L{\"o}bker, W and Martin, D and M{\"u}ller, T and Park, Bj and Platt, R and Priddy, S and Ruhl, M and Spooner, A and Vannieuwenhuyse, B and Willke, Rj},
  year = {2016},
  month = dec,
  volume = {100},
  pages = {633--646},
  issn = {00099236},
  doi = {10.1002/cpt.512},
  url = {http://doi.wiley.com/10.1002/cpt.512},
  urldate = {2020-04-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/795T37IN/Schneeweiss et al_2016_Real World Data in Adaptive Biomedical Innovation.pdf},
  journal = {Clinical Pharmacology \& Therapeutics},
  language = {en},
  number = {6}
}

@misc{schuemieJourneyPopulationlevelEffect,
  title = {The Journey toward {{Population}}-Level {{Effect Estimation}}},
  author = {Schuemie, Martijn and Ryan, Patrick and Suchard, Marc and Bergvall, Tomas},
  language = {en}
}

@article{schuemiemartijnj.ImprovingReproducibilityUsing2018,
  ids = {schuemieImprovingReproducibilityUsing2018},
  title = {Improving Reproducibility by Using High-Throughput Observational Studies with Empirical Calibration},
  author = {{Schuemie Martijn J.} and {Ryan Patrick B.} and {Hripcsak George} and {Madigan David} and {Suchard Marc A.}},
  year = {2018},
  month = sep,
  volume = {376},
  pages = {20170356},
  doi = {10.1098/rsta.2017.0356},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2017.0356},
  urldate = {2019-05-18},
  abstract = {Concerns over reproducibility in science extend to research using existing healthcare data; many observational studies investigating the same topic produce conflicting results, even when using the same data. To address this problem, we propose a paradigm shift. The current paradigm centres on generating one estimate at a time using a unique study design with unknown reliability and publishing (or not) one estimate at a time. The new paradigm advocates for high-throughput observational studies using consistent and standardized methods, allowing evaluation, calibration and unbiased dissemination to generate a more reliable and complete evidence base. We demonstrate this new paradigm by comparing all depression treatments for a set of outcomes, producing 17\,718 hazard ratios, each using methodology on par with current best practice. We furthermore include control hypotheses to evaluate and calibrate our evidence generation process. Results show good transitivity and consistency between databases, and agree with four out of the five findings from clinical trials. The distribution of effect size estimates reported in the literature reveals an absence of small or null effects, with a sharp cut-off at p\,=\,0.05. No such phenomena were observed in our results, suggesting more complete and more reliable evidence.This article is part of a discussion meeting issue `The growing ubiquity of algorithms in society: implications, impacts and innovations'.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/ALCX6RNE/Schuemie Martijn J. et al_2018_Improving reproducibility by using high-throughput observational studies with.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/FAJBBGGZ/rsta.2017.html},
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  number = {2128}
}

@article{schulzReadCodeQuality1998,
  title = {Read {{Code Quality Assurance}}: {{From Simple Syntax}} to {{Semantic Stability}}},
  shorttitle = {Read {{Code Quality Assurance}}},
  author = {Schulz, E. B. and Barrett, J. W. and Price, C.},
  year = {1998},
  month = jul,
  volume = {5},
  pages = {337--346},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/jamia.1998.0050337},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/jamia.1998.0050337},
  urldate = {2020-04-02},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/65LUP6Y4/Schulz et al_1998_Read Code Quality Assurance.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {4}
}

@article{shangConceptualFrameworkEvaluating2017,
  title = {A Conceptual Framework for Evaluating Data Suitability for Observational Studies},
  author = {Shang, Ning and Weng, Chunhua and Hripcsak, George},
  year = {2017},
  month = sep,
  issn = {1067-5027},
  doi = {10.1093/jamia/ocx095},
  url = {http://dx.doi.org/10.1093/jamia/ocx095},
  abstract = {Objective: To contribute a conceptual framework for evaluating data
suitability to satisfy the research needs of observational studies.
Materials and Methods: Suitability considerations were derived from a
systematic literature review on researchers' common data needs in
observational studies and a scoping review on frequent clinical database
design considerations, and were harmonized to construct a suitability
conceptual framework using a bottom-up approach. The relationships among
the suitability categories are explored from the perspective of 4 facets
of data: intrinsic, contextual, representational, and accessible. A
web-based national survey of domain experts was conducted to validate the
framework. Results: Data suitability for observational studies hinges on
the following key categories: Explicitness of Policy and Data Governance,
Relevance, Availability of Descriptive Metadata and Provenance
Documentation, Usability, and Quality. We describe 16 measures and 33
sub-measures. The survey uncovered the relevance of all categories, with a
5-point Likert importance score of 3.9 {$\pm$} 1.0 for Explicitness of Policy
and Data Governance, 4.1 {$\pm$} 1.0 for Relevance, 3.9 {$\pm$} 0.9 for Availability
of Descriptive Metadata and Provenance Documentation, 4.2 {$\pm$} 1.0 for
Usability, and 4.0 {$\pm$} 0.9 for Quality. Conclusions: The suitability
framework evaluates a clinical data source's fitness for research use. Its
construction reflects both researchers' points of view and data
custodians' design features. The feedback from domain experts rated
Usability, Relevance, and Quality categories as the most important
considerations.},
  journal = {J. Am. Med. Inform. Assoc.},
  keywords = {Active papers/AMIA VS,data suitability,observational studies,survey}
}

@article{sharmaD2RefinePlatformClinical2017,
  title = {{{D2Refine}}: {{A Platform}} for {{Clinical Research Study Data Element Harmonization}} and {{Standardization}}},
  author = {Sharma, Deepak K and Solbrig, Harold R and Prud'hommeaux, Eric and Lee, Kate and Pathak, Jyotishman and Jiang, Guoqian},
  year = {2017},
  month = jul,
  volume = {2017},
  pages = {259--267},
  issn = {2153-4063},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/28815140},
  abstract = {In this paper, we present a platform known as D2Refine for facilitating
clinical research study data element harmonization and standardization.
D2Refine is developed on top of OpenRefine (formerly Google Refine) and
leverages simple interface and extensible architecture of OpenRefine.
D2Refine empowers the tabular representation of clinical research study
data element definitions by allowing it to be easily organized and
standardized using reconciliation services. D2Refine builds on valuable
built-in data transformation features of OpenRefine to bring source data
sets to a finer state quickly. We implemented the reconciliation services
and search capabilities based on the standard Common Terminology Services
2 (CTS2) and the serialization of clinical research study data element
definitions into standard representation using clinical information
modeling technology for semantic interoperability. We demonstrate that
D2Refine is a useful and promising platform that would help address the
emergent needs for clinical research study data element harmonization and
standardization.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/6R6I7D2Y/Sharma et al_2017_D2Refine.pdf},
  journal = {AMIA Jt Summits Transl Sci Proc},
  keywords = {Informatics/Phenotyping}
}

@article{shellFlorenceNightingaleDr2008,
  title = {Florence {{Nightingale}}, {{Dr}}. {{Ernest Codman}}, {{American College}} of {{Surgeons Hospital Standardization Committee}}, and {{The Joint Commission}}: {{Four Pillars}} in the {{Foundation}} of {{Patient Safety}}},
  shorttitle = {Florence {{Nightingale}}, {{Dr}}. {{Ernest Codman}}, {{American College}} of {{Surgeons Hospital Standardization Committee}}, and {{The Joint Commission}}},
  author = {Shell, Charlotte M. and Dunlap, Karen D.},
  year = {2008},
  month = mar,
  volume = {3},
  pages = {19--26},
  issn = {15567931},
  doi = {10.1016/j.cpen.2007.11.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1556793107001027},
  urldate = {2020-03-21},
  journal = {Perioperative Nursing Clinics},
  language = {en},
  number = {1}
}

@article{shiltonValuesEthicsHumanComputer2018,
  title = {Values and {{Ethics}} in {{Human}}-{{Computer Interaction}}},
  author = {Shilton, Katie},
  year = {2018},
  volume = {12},
  pages = {107--171},
  issn = {1551-3955, 1551-3963},
  doi = {10.1561/1100000073},
  url = {http://www.nowpublishers.com/article/Details/HCI-073},
  urldate = {2020-07-27},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/TVGSY27M/Shilton_2018_Values and Ethics in Human-Computer Interaction.pdf},
  journal = {Foundations and Trends\textregistered{} in Human\textendash Computer Interaction},
  language = {en},
  number = {2}
}

@article{shipmanFormalityConsideredHarmful1999,
  title = {Formality {{Considered Harmful}}: {{Experiences}}, {{Emerging Themes}}, and {{Directions}} on the {{Use}} of {{Formal Representations}} in {{Interactive Systems}}},
  author = {Shipman, Frank M and Marshall, Catherine C},
  year = {1999},
  month = dec,
  volume = {8},
  pages = {333--352},
  issn = {0925-9724},
  doi = {10.1023/A:1008716330212},
  url = {https://doi.org/10.1023/A:1008716330212},
  abstract = {This paper reflects on experiences designing, developing, and working with
users of a variety of interactive computer systems. The authors propose,
based on these experiences, that the cause of a number of unexpected
difficulties in human-computer interaction lies in users' unwillingness or
inability to make structure, content, or procedures explicit. Besides
recounting experiences with system use, this paper discusses why users
reject or circumvent formalisms which require such explicit expression,
and suggests how system designers can anticipate and compensate for
problems users have in making implicit aspects of their tasks explicit.
The authors propose computational approaches that address this problem,
including incremental and system-assisted formalization mechanisms and
methods for recognizing and using undeclared structure; they also propose
non-computational solutions that involve designers and users reaching a
shared understanding of the task situation and the methods that motivate
the formalisms. This paper poses that, while it is impossible to remove
all formalisms from computing systems, system designers need to match the
level of formal expression entailed with the goals and situation of the
users -- a design criteria not commonly mentioned in current interface
design.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7ZR6L8BY/Shipman_Marshall_1999_Formality Considered Harmful.pdf},
  journal = {Comput. Support. Coop. Work},
  keywords = {important,ISchool/INST888-Butler},
  number = {4}
}

@article{slovis132TrackingOpioid2017,
  title = {132 {{Tracking}} the {{Opioid Epidemic Through}} the {{OHDSI Collaborative}}},
  author = {Slovis, B.H. and Averitt, A.J. and Vawdrey, D.K. and Perotte, A.},
  year = {2017},
  month = oct,
  volume = {70},
  pages = {S53-S54},
  issn = {01960644},
  doi = {10.1016/j.annemergmed.2017.07.158},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0196064417310582},
  urldate = {2019-05-18},
  abstract = {Methods: The protocol was IRB approved, prospective, and designed as a pilot study. It involved 28 Madigan Army Medical Center Emergency Department personnel. Each participant was timed while setting three normal saline infusions at specific rates. Participants were then asked to fill out a survey.
Results: Most participants thought the DripAssist was easy to set up, understand and were confident in their ability to use it after limited training (4.8/5, 4.7/5, 4.7/5). Compared to IV infusion pumps participants thought it was slightly easier to use (3.7/ 5). In comparison to traditional roller clamps EMTs/paramedics and Army medics in the study found the device neither easier nor harder to use (3.1/5, 3.6/5) whereas nurses and physician assistants found it much easier to use (4.6/5, 4.8/5). Nurses and physician assistants were more likely to see potential for the device in out-of-hospital /austere environments (4.6/5, 4.8/5) than EMTs/paramedics and Army medics (3/5, 3.6/5). Average time to completion of the 83ml/hr, 125ml/hr and 250ml/hr drips were 68, 120, and 114 seconds respectively.
Conclusions: Our pilot study demonstrated that various levels of health care personnel thought that the DripAssist device was easy to use. Increased perceived accuracy, safety and applicability to austere/out-of-hospital /battlefield care was highest among nurses and physician assistants whereas EMTs, paramedics and Army medics had less positive perceived benefit. The DripAssist device may offer a safe, low-weight, functional tool through which to improve care in a variety of resource-limited environments.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/APLP62GR/Slovis et al_2017_132 Tracking the Opioid Epidemic Through the OHDSI Collaborative.pdf},
  journal = {Annals of Emergency Medicine},
  language = {en},
  number = {4}
}

@misc{solbrigISO11179CTS2,
  title = {{{ISO}} 11179 {{CTS2}} and {{Value Set Binding}}},
  author = {Solbrig, Harold},
  url = {http://dbooth.org/2015/solbrig/FHIR_RDF_Solbrig.pdf},
  urldate = {2020-03-28},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/T6QHGV4L/Solbrig_ISO 11179 CTS2 and Value Set Binding.pdf},
  language = {en}
}

@article{springateClinicalCodesOnlineClinical2014,
  title = {{{ClinicalCodes}}: {{An Online Clinical Codes Repository}} to {{Improve}} the {{Validity}} and {{Reproducibility}} of {{Research Using Electronic Medical Records}}},
  shorttitle = {{{ClinicalCodes}}},
  author = {Springate, David A. and Kontopantelis, Evangelos and Ashcroft, Darren M. and Olier, Ivan and Parisi, Rosa and Chamapiwa, Edmore and Reeves, David},
  editor = {Petersen, Irene},
  year = {2014},
  month = jun,
  volume = {9},
  pages = {e99825},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0099825},
  url = {https://dx.plos.org/10.1371/journal.pone.0099825},
  urldate = {2020-01-16},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/T6I85CXU/Springate et al_2014_ClinicalCodes.pdf},
  journal = {PLoS ONE},
  language = {en},
  number = {6}
}

@article{stangAdvancingScienceActive2010,
  title = {Advancing the Science for Active Surveillance: Rationale and Design for the {{Observational Medical Outcomes Partnership}}},
  author = {Stang, Paul E and Ryan, Patrick B and Racoosin, Judith A and Overhage, J Marc and Hartzema, Abraham G and Reich, Christian and Welebob, Emily and Scarnecchia, Thomas and Woodcock, Janet},
  year = {2010},
  month = nov,
  volume = {153},
  pages = {600--606},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-153-9-201011020-00010},
  url = {http://dx.doi.org/10.7326/0003-4819-153-9-201011020-00010},
  abstract = {The U.S. Food and Drug Administration (FDA) Amendments Act of 2007
mandated that the FDA develop a system for using automated health care
data to identify risks of marketed drugs and other medical products. The
Observational Medical Outcomes Partnership is a public-private partnership
among the FDA, academia, data owners, and the pharmaceutical industry that
is responding to the need to advance the science of active medical product
safety surveillance by using existing observational databases. The
Observational Medical Outcomes Partnership's transparent, open innovation
approach is designed to systematically and empirically study critical
governance, data resource, and methodological issues and their
interrelationships in establishing a viable national program of active
drug safety surveillance by using observational data. This article
describes the governance structure, data-access model, methods-testing
approach, and technology development of this effort, as well as the work
that has been initiated.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/MJUHGJB8/Stang et al_2010_Advancing the science for active surveillance.pdf},
  journal = {Ann. Intern. Med.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,Informatics/med recs / cdms},
  number = {9}
}

@article{starInstitutionalEcologyTranslations1989,
  title = {Institutional {{Ecology}}, `{{Translations}}' and {{Boundary Objects}}: {{Amateurs}} and {{Professionals}} in {{Berkeley}}'s {{Museum}} of {{Vertebrate Zoology}}, 1907-39},
  author = {Star, Susan Leigh and Griesemer, James R},
  year = {1989},
  month = aug,
  volume = {19},
  pages = {387--420},
  issn = {0306-3127},
  doi = {10.1177/030631289019003001},
  url = {http://journals.sagepub.com/doi/10.1177/030631289019003001},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/FLFQU72H/Star_Griesemer_1989_Institutional Ecology, `Translations' and Boundary Objects.pdf},
  journal = {Soc. Stud. Sci.},
  keywords = {Active papers/AMIA VS,Active papers/interoperability paper/background,ISchool/INST888-Butler/Leading INST888,ISchool/INST888/Week 13.(November 29) Information Institutions: Libraries; Archives; and Museums},
  number = {3}
}

@incollection{starStructureIllStructuredSolutions1989,
  title = {The {{Structure}} of {{Ill}}-{{Structured Solutions}}: {{Boundary Objects}} and {{Heterogeneous Distributed Problem Solving}}},
  shorttitle = {The {{Structure}} of {{Ill}}-{{Structured Solutions}}},
  booktitle = {Distributed {{Artificial Intelligence}}},
  author = {Star, Susan Leigh},
  year = {1989},
  pages = {37--54},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-1-55860-092-8.50006-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/B978155860092850006X},
  urldate = {2020-04-14},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PIVYUNS2/Star_1989_The Structure of Ill-Structured Solutions.pdf},
  isbn = {978-1-55860-092-8},
  language = {en}
}

@misc{StatisticalAnalysisEQ5D,
  title = {Statistical {{Analysis}} of {{EQ}}-{{5D Profiles}}: {{Does}} the {{Use}} of {{Value Sets Bias Inference}}? - {{David Parkin}}, {{Nigel Rice}}, {{Nancy Devlin}}, 2010},
  url = {https://journals.sagepub.com/doi/abs/10.1177/0272989X09357473},
  urldate = {2020-05-14},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/3TX9SIA2/Statistical Analysis of EQ-5D Profiles Does the U.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/S9E8R7SZ/0272989X09357473.html}
}

@misc{stevebernsteinAHRQEvidencebasedCare2020,
  title = {{{AHRQ}} Evidence-Based {{Care Transformation Support}} ({{ACTS}}) {{Initiative}} - {{MCBK Annual Conference}}},
  author = {{Steve Bernstein}},
  year = {2020},
  month = jul,
  url = {https://digital.ahrq.gov/sites/default/files/docs/page/acts-mcbk-07012020.pdf},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/HKMZBMHM/AHRQ evidence-based Care Transformation Support (A.pdf},
  language = {en}
}

@article{suliemanWikiMedMapExpandingPhenotyping2019,
  title = {{{WikiMedMap}}: {{Expanding}} the {{Phenotyping Mapping Toolbox Using Wikipedia}}},
  shorttitle = {{{WikiMedMap}}},
  author = {Sulieman, Lina and Wu, Patrick and Denny, Joshua C. and Bastarache, Lisa},
  year = {2019},
  month = aug,
  doi = {10.1101/727792},
  url = {http://biorxiv.org/lookup/doi/10.1101/727792},
  urldate = {2019-08-13},
  abstract = {Researchers utilizing phenotypic data from diverse sources require matching of phenotypes to standard clinical vocabularies. Mapping phenotypes to vocabulary can be difficult, as existing tools are often incomplete, can be difficult to access, and can be cumbersome to use, especially for non-experts. We created WikiMedMap as a simple tool that leverages Wikipedia and maps phenotype strings to standard clinical vocabularies. We assessed WikiMedMap by mapping phenotype strings from questionnaires in the UK Biobank and from Mendelian diseases in Online Mendelian Inheritance in Man (OMIM) database to eight vocabularies: International Classification of Diseases, Ninth Revision (ICD-9), ICD-10, ICD-O, Medical Subject Headings (MeSH), OMIM, Disease Database, and MedlinePlus. WikiMedMap outperformed conventional mapping tools in finding potential matches for phenotype strings. We envision WikiMedMap as a technique that complements existing and established tools to map strings to clinical vocabularies that usually do not coexist in one source.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XCRSK9WI/Sulieman et al_2019_WikiMedMap.pdf},
  journal = {bioRxiv},
  language = {en}
}

@article{swerdelPheValuatorDevelopmentEvaluation2019,
  title = {{{PheValuator}}: {{Development}} and Evaluation of a Phenotype Algorithm Evaluator},
  shorttitle = {{{PheValuator}}},
  author = {Swerdel, Joel N. and Hripcsak, George and Ryan, Patrick B.},
  year = {2019},
  month = sep,
  volume = {97},
  pages = {103258},
  issn = {15320464},
  doi = {10.1016/j.jbi.2019.103258},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046419301777},
  urldate = {2020-05-07},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/X4IIKWUM/Swerdel et al_2019_PheValuator.pdf},
  journal = {Journal of Biomedical Informatics},
  language = {en}
}

@article{teixeiraEvaluatingElectronicHealth2017,
  title = {Evaluating Electronic Health Record Data Sources and Algorithmic Approaches to Identify Hypertensive Individuals},
  author = {Teixeira, Pedro L and Wei, Wei-Qi and Cronin, Robert M and Mo, Huan and VanHouten, Jacob P and Carroll, Robert J and LaRose, Eric and Bastarache, Lisa A and Rosenbloom, S. Trent and Edwards, Todd L and Roden, Dan M and Lasko, Thomas A and Dart, Richard A and Nikolai, Anne M and Peissig, Peggy L and Denny, Joshua C},
  year = {2017},
  month = jan,
  volume = {24},
  pages = {162--171},
  issn = {1067-5027, 1527-974X},
  doi = {10.1093/jamia/ocw071},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1093/jamia/ocw071},
  urldate = {2020-01-16},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/I2IPJXJT/Teixeira et al_2017_Evaluating electronic health record data sources and algorithmic approaches to.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {1}
}

@article{theemergeteamEMERGENetworkConsortium2011,
  title = {The {{eMERGE Network}}: {{A}} Consortium of Biorepositories Linked to Electronic Medical Records Data for Conducting Genomic Studies},
  shorttitle = {The {{eMERGE Network}}},
  author = {{the eMERGE Team} and McCarty, Catherine A and Chisholm, Rex L and Chute, Christopher G and Kullo, Iftikhar J and Jarvik, Gail P and Larson, Eric B and Li, Rongling and Masys, Daniel R and Ritchie, Marylyn D and Roden, Dan M and Struewing, Jeffery P and Wolf, Wendy A},
  year = {2011},
  month = dec,
  volume = {4},
  issn = {1755-8794},
  doi = {10.1186/1755-8794-4-13},
  url = {http://bmcmedgenomics.biomedcentral.com/articles/10.1186/1755-8794-4-13},
  urldate = {2020-06-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PSWHMKAS/the eMERGE Team et al_2011_The eMERGE Network.pdf},
  journal = {BMC Medical Genomics},
  language = {en},
  number = {1}
}

@article{thegeneontologyconsortiumGeneOntologyResource2019,
  title = {The {{Gene Ontology Resource}}: 20 Years and Still {{GOing}} Strong},
  shorttitle = {The {{Gene Ontology Resource}}},
  author = {{The Gene Ontology Consortium}},
  year = {2019},
  month = jan,
  volume = {47},
  pages = {D330-D338},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/gky1055},
  url = {https://academic.oup.com/nar/article/47/D1/D330/5160994},
  urldate = {2020-04-28},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/GLY9A94M/The Gene Ontology Consortium_2019_The Gene Ontology Resource.pdf},
  journal = {Nucleic Acids Research},
  language = {en},
  number = {D1}
}

@article{thomerTransformingTaxonomicInterfaces2018,
  title = {Transforming {{Taxonomic Interfaces}}: "{{Arm}}?S {{Length}}" {{Cooperative Work}} and the {{Maintenance}} of a {{Long}}-Lived {{Classification System}}},
  shorttitle = {Transforming {{Taxonomic Interfaces}}},
  author = {Thomer, Andrea K. and Twidale, Michael Bernard and Yoder, Matthew J.},
  year = {2018},
  month = nov,
  volume = {2},
  pages = {173:1--173:23},
  doi = {10.1145/3274442},
  url = {https://doi.org/10.1145/3274442},
  urldate = {2020-03-05},
  abstract = {If scientific research can be described as "arm's length'' cooperative work, then the sciences engaged in the creation and maintenance of cooperatively built classification systems might be said to require extremely long arms; workers must reach across great distances of time, space and awareness to independently contribute to the creation and maintenance of a conceptual infrastructure. This is particularly the case for the field of biological taxonomy, in which researchers across the globe have, for more than three hundred years, cooperatively developed a massive knowledge organization system describing all life on earth. As taxonomists move from paper-based workflows to born-digital, data-first modes of publishing, new tools and approaches are needed to support their work. In this paper, we present research conducted as part of the "Transforming Taxonomic Interfaces" project aimed at improving interfaces for taxonomic software. We describe biological taxonomy in the context of CSCW, and identify key strategies taxonomists deploy to facilitate loosely coupled cooperative work. We also contribute a discussion ofsemantic refactoring, a unique kind of "articulation work'' entailed in developing, maintaining, and migrating classification systems. This work has implications for the design and study of knowledge organization systems and infrastructure, classification research, and for the development of general semantic web tools and software as well as those specifically for biological taxonomy.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/23MQSWKM/Thomer et al_2018_Transforming Taxonomic Interfaces.pdf},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  keywords = {``arm's length' cooperative work,articulation work,biodiversity informatics,classification,loosely coupled cooperative work,semantic refactoring,taxonomy},
  number = {CSCW}
}

@article{thompsonEvaluationNQFQuality2012,
  title = {An Evaluation of the {{NQF Quality Data Model}} for Representing {{Electronic Health Record}} Driven Phenotyping Algorithms},
  author = {Thompson, William K. and Rasmussen, Luke V. and Pacheco, Jennifer A. and Peissig, Peggy L. and Denny, Joshua C. and Kho, Abel N. and Miller, Aaron and Pathak, Jyotishman},
  year = {2012},
  volume = {2012},
  pages = {911--920},
  issn = {1942-597X},
  abstract = {The development of Electronic Health Record (EHR)-based phenotype selection algorithms is a non-trivial and highly iterative process involving domain experts and informaticians. To make it easier to port algorithms across institutions, it is desirable to represent them using an unambiguous formal specification language. For this purpose we evaluated the recently developed National Quality Forum (NQF) information model designed for EHR-based quality measures: the Quality Data Model (QDM). We selected 9 phenotyping algorithms that had been previously developed as part of the eMERGE consortium and translated them into QDM format. Our study concluded that the QDM contains several core elements that make it a promising format for EHR-driven phenotyping algorithms for clinical research. However, we also found areas in which the QDM could be usefully extended, such as representing information extracted from clinical text, and the ability to handle algorithms that do not consist of Boolean combinations of criteria.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/UTBSXB4L/Thompson et al_2012_An evaluation of the NQF Quality Data Model for representing Electronic Health.pdf},
  journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
  keywords = {Algorithms,Biomedical Research,Electronic Health Records,Humans,Natural Language Processing,Phenotype,Programming Languages,Quality Control},
  language = {eng},
  pmcid = {PMC3540514},
  pmid = {23304366}
}

@book{tukeyExploratoryDataAnalysis1977,
  title = {Exploratory Data Analysis},
  author = {Tukey, John Wilder},
  year = {1977},
  publisher = {{Addison-Wesley Pub. Co}},
  address = {{Reading, Mass}},
  isbn = {978-0-201-07616-5},
  keywords = {Statistics},
  lccn = {HA29 .T783},
  series = {Addison-{{Wesley}} Series in Behavioral Science}
}

@inproceedings{valleTypologyArchitecturalStrategies2019,
  title = {A {{Typology}} of {{Architectural Strategies}} for {{Interoperability}}},
  booktitle = {Proceedings of the {{XIII Brazilian Symposium}} on {{Software Components}}, {{Architectures}}, and {{Reuse}}},
  author = {Valle, Pedro Henrique Dias and Garc{\'e}s, Lina and Nakagawa, Elisa Yumi},
  year = {2019},
  month = sep,
  pages = {3--12},
  publisher = {{Association for Computing Machinery}},
  address = {{Salvador, Brazil}},
  doi = {10.1145/3357141.3357144},
  url = {https://doi.org/10.1145/3357141.3357144},
  urldate = {2020-03-05},
  abstract = {An increasing interest in researching the development, integration, composition, and evolution of large-scale, software-intensive systems (LSSIS) have been observed in the last years. These systems are presented in different domains as connected health, industry 4.0, military, smart cities, smart grids, and smart agriculture. These systems are realized through the cooperation among heterogeneous, independent, highly distributed, individual, and heterogeneous systems to achieve their business goals. For the success of these larger systems, their individual parts must interoperate among them allowing the execution of more complex functionalities. However, there are many concerns that software engineers must overcome during the composition of these systems, that can be related to (i) the misunderstanding of data formats, data semantic, procedures, contracts, standards, quality, and interfaces structures provided by individual systems; and (ii) the absence of high-level architectures to analyze, comprehend, and guide how interoperability can be addressed. The goal of this work is to present a typology of existing and proven strategies for achieving interoperability. Strategies were identified through a systematic search in scientific databases and patterns repositories. The selected strategies were categorized according to the level of interoperability they support, namely, technical, syntactic, semantic, and organizational. In each level, the strategies were divided by the type of solution their propose, i.e., technique, and architectural styles, patterns, and tactics. Moreover, statements explaining how each strategy address interoperability are given. Results of this work can be used by architects to identify and understand solutions for achieving interoperability requirements during the composition of larger systems. The resulting typology in this study is the first step to consolidate a patterns-language for interoperability in software architectures.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/EEWHVJ4T/Valle et al_2019_A Typology of Architectural Strategies for Interoperability.pdf},
  isbn = {978-1-4503-7637-2},
  keywords = {Architectural Pattern,Architectural Style,Interoperability,Software Architecture,Tactic,Typology},
  series = {{{SBCARS}} '19}
}

@misc{ValueSetStudy,
  title = {Value {{Set Study}} Paper for {{CHI2020}} - {{Online LaTeX Editor Overleaf}}},
  url = {https://www.overleaf.com/project/5d4800a4a0bab446f68c5030},
  urldate = {2020-02-07},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/F3MQI5KG/5d4800a4a0bab446f68c5030.html}
}

@article{vandenbrouckeStrengtheningReportingObservational2007,
  title = {Strengthening the {{Reporting}} of {{Observational Studies}} in {{Epidemiology}} ({{STROBE}}): Explanation and Elaboration},
  shorttitle = {Strengthening the {{Reporting}} of {{Observational Studies}} in {{Epidemiology}} ({{STROBE}})},
  author = {Vandenbroucke, Jan P. and {von Elm}, Erik and Altman, Douglas G. and G{\o}tzsche, Peter C. and Mulrow, Cynthia D. and Pocock, Stuart J. and Poole, Charles and Schlesselman, James J. and Egger, Matthias and {STROBE Initiative}},
  year = {2007},
  month = oct,
  volume = {4},
  pages = {e297},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0040297},
  abstract = {Much medical research is observational. The reporting of observational studies is often of insufficient quality. Poor reporting hampers the assessment of the strengths and weaknesses of a study and the generalisability of its results. Taking into account empirical evidence and theoretical considerations, a group of methodologists, researchers, and editors developed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) recommendations to improve the quality of reporting of observational studies. The STROBE Statement consists of a checklist of 22 items, which relate to the title, abstract, introduction, methods, results and discussion sections of articles. Eighteen items are common to cohort studies, case-control studies and cross-sectional studies and four are specific to each of the three study designs. The STROBE Statement provides guidance to authors about how to improve the reporting of observational studies and facilitates critical appraisal and interpretation of studies by reviewers, journal editors and readers. This explanatory and elaboration document is intended to enhance the use, understanding, and dissemination of the STROBE Statement. The meaning and rationale for each checklist item are presented. For each item, one or several published examples and, where possible, references to relevant empirical studies and methodological literature are provided. Examples of useful flow diagrams are also included. The STROBE Statement, this document, and the associated Web site (http://www.strobe-statement.org/) should be helpful resources to improve reporting of observational research.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CGABEGXU/Vandenbroucke et al_2007_Strengthening the Reporting of Observational Studies in Epidemiology (STROBE).pdf},
  journal = {PLoS medicine},
  keywords = {Case-Control Studies,Cohort Studies,Cross-Sectional Studies,Epidemiologic Research Design,Guidelines as Topic,Observation,Publishing},
  language = {eng},
  number = {10},
  pmcid = {PMC2020496},
  pmid = {17941715}
}

@article{vanopstalVocabulariesRetrievalTools,
  title = {Vocabularies and {{Retrieval Tools}} in {{Biomedicine}}: {{Disentangling}} the {{Terminological Knot}}},
  shorttitle = {Vocabularies and {{Retrieval Tools}} in {{Biomedicine}}},
  author = {Vanopstal, Klaar and Stichele, Robert and Laureys, Godelieve and Buysschaert, Joost},
  volume = {35},
  pages = {527--543},
  issn = {0148-5598},
  url = {https://www.academia.edu/7740706/Vocabularies_and_Retrieval_Tools_in_Biomedicine_Disentangling_the_Terminological_Knot},
  urldate = {2020-02-27},
  abstract = {Terms like ``thesaurus'', ``taxonomy'', ``classification'', ``glossary'', ``ontology'' and ``controlled vocabulary'' can be used in diverse contexts, causing confusion and vagueness about their denotation. Is a thesaurus a tool to enrich a writer's style or an},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/DL6GNWCM/Vanopstal et al_Vocabularies and Retrieval Tools in Biomedicine.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/US6L9FJI/Vocabularies_and_Retrieval_Tools_in_Biomedicine_Disentangling_the_Terminological_Knot.html},
  journal = {Journal of Medical Systems},
  language = {en},
  number = {4}
}

@article{veltmanSyntacticSemanticInteroperability2001,
  title = {Syntactic and Semantic Interoperability: {{New}} Approaches to Knowledge and the Semantic Web},
  shorttitle = {Syntactic and Semantic Interoperability},
  author = {Veltman, Kim H.},
  year = {2001},
  month = jan,
  volume = {7},
  pages = {159--183},
  publisher = {{Routledge}},
  issn = {1361-4576},
  doi = {10.1080/13614570109516975},
  url = {https://doi.org/10.1080/13614570109516975},
  urldate = {2020-03-05},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/CTURBHHH/Veltman_2001_Syntactic and semantic interoperability.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/WV3UCD2C/13614570109516975.html},
  journal = {New Review of Information Networking},
  number = {1}
}

@article{visweswaranAccrualClinicalTrials2018,
  title = {Accrual to {{Clinical Trials}} ({{ACT}}): {{A Clinical}} and {{Translational Science Award Consortium Network}}},
  shorttitle = {Accrual to {{Clinical Trials}} ({{ACT}})},
  author = {Visweswaran, Shyam and Becich, Michael J and D'Itri, Vincent S and Sendro, Elaina R and MacFadden, Douglas and Anderson, Nicholas R and Allen, Karen A and Ranganathan, Dipti and Murphy, Shawn N and Morrato, Elaine H and Pincus, Harold A and Toto, Robert and Firestein, Gary S and Nadler, Lee M and Reis, Steven E},
  year = {2018},
  month = oct,
  volume = {1},
  pages = {147--152},
  issn = {2574-2531},
  doi = {10.1093/jamiaopen/ooy033},
  url = {https://academic.oup.com/jamiaopen/article/1/2/147/5077449},
  urldate = {2020-06-23},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/RXZMU8Z3/Visweswaran et al_2018_Accrual to Clinical Trials (ACT).pdf},
  journal = {JAMIA Open},
  language = {en},
  number = {2}
}

@article{vossFeasibilityUtilityApplications2015,
  title = {Feasibility and Utility of Applications of the Common Data Model to Multiple, Disparate Observational Health Databases},
  author = {Voss, Erica A. and Makadia, Rupa and Matcho, Amy and Ma, Qianli and Knoll, Chris and Schuemie, Martijn and DeFalco, Frank J. and Londhe, Ajit and Zhu, Vivienne and Ryan, Patrick B.},
  year = {2015},
  month = may,
  volume = {22},
  pages = {553--564},
  publisher = {{Oxford Academic}},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocu023},
  url = {https://academic-oup-com.proxy-um.researchport.umd.edu/jamia/article/22/3/553/775146},
  urldate = {2020-06-01},
  abstract = {Abstract.  Objectives To evaluate the utility of applying the Observational Medical Outcomes Partnership (OMOP) Common Data Model (CDM) across multiple observat},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/WTRSSMY3/Voss et al_2015_Feasibility and utility of applications of the common data model to multiple,.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/NJTMIDD9/775146.html},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {3}
}

@article{walnyDataChangesEverything2019,
  title = {Data {{Changes Everything}}: {{Challenges}} and {{Opportunities}} in {{Data Visualization Design Handoff}}},
  shorttitle = {Data {{Changes Everything}}},
  author = {Walny, Jagoda and Frisson, Christian and West, Mieka and Kosminsky, Doris and Knudsen, S{\o}ren and Carpendale, Sheelagh and Willett, Wesley},
  year = {2019},
  month = jul,
  url = {http://arxiv.org/abs/1908.00192},
  urldate = {2019-11-21},
  abstract = {Complex data visualization design projects often entail collaboration between people with different visualization-related skills. For example, many teams include both designers who create new visualization designs and developers who implement the resulting visualization software. We identify gaps between data characterization tools, visualization design tools, and development platforms that pose challenges for designer-developer teams working to create new data visualizations. While it is common for commercial interaction design tools to support collaboration between designers and developers, creating data visualizations poses several unique challenges that are not supported by current tools. In particular, visualization designers must characterize and build an understanding of the underlying data, then specify layouts, data encodings, and other data-driven parameters that will be robust across many different data values. In larger teams, designers must also clearly communicate these mappings and their dependencies to developers, clients, and other collaborators. We report observations and reflections from five large multidisciplinary visualization design projects and highlight six data-specific visualization challenges for design specification and handoff. These challenges include adapting to changing data, anticipating edge cases in data, understanding technical challenges, articulating data-dependent interactions, communicating data mappings, and preserving the integrity of data mappings across iterations. Based on these observations, we identify opportunities for future tools for prototyping, testing, and communicating data-driven designs, which might contribute to more successful and collaborative data visualization design.},
  archivePrefix = {arXiv},
  eprint = {1908.00192},
  eprinttype = {arxiv},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PMGDXICU/Walny et al_2019_Data Changes Everything.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/Z7BDYDJ6/1908.html},
  journal = {arXiv:1908.00192 [cs]},
  keywords = {Computer Science - Human-Computer Interaction,H.5.2},
  primaryClass = {cs}
}

@article{walshEnablingOpenScienceInitiatives2018,
  title = {Enabling {{Open}}-{{Science Initiatives}} in {{Clinical Psychology}} and {{Psychiatry Without Sacrificing Patients}}' {{Privacy}}: {{Current Practices}} and {{Future Challenges}}},
  shorttitle = {Enabling {{Open}}-{{Science Initiatives}} in {{Clinical Psychology}} and {{Psychiatry Without Sacrificing Patients}}' {{Privacy}}},
  author = {Walsh, Colin G. and Xia, Weiyi and Li, Muqun and Denny, Joshua C. and Harris, Paul A. and Malin, Bradley A.},
  year = {2018},
  month = mar,
  volume = {1},
  pages = {104--114},
  issn = {2515-2459},
  doi = {10.1177/2515245917749652},
  url = {https://doi.org/10.1177/2515245917749652},
  urldate = {2020-02-27},
  abstract = {The psychological and psychiatric communities are generating data on an ever-increasing scale. To ensure that society reaps the greatest utility in research and clinical care from such rich resources, there is significant interest in wide-scale, open data sharing to foster scientific endeavors. However, it is imperative that such open-science initiatives ensure that data-privacy concerns are adequately addressed. In this article, we focus on these issues in clinical research. We review the privacy risks and then discuss how they can be mitigated through appropriate governance mechanisms that are both social (e.g., the application of data-use agreements) and technological (e.g., de-identification of structured data and unstructured narratives). We also discuss the benefits and drawbacks of these mechanisms, particularly as regards data fidelity. Our focus is on de-identification methods that meet regulatory requirements, such as the Privacy Rule of the Health Insurance Portability and Accountability Act of 1996. To illustrate their potential, we show how the principles we discuss have been applied in a large-scale clinical database and distributed research networks. We close this article with a discussion of challenges in supporting data privacy as open-science initiatives grow in their scale and complexity.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XXGJZTLS/Walsh et al_2018_Enabling Open-Science Initiatives in Clinical Psychology and Psychiatry Without.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  keywords = {data sharing,de-identification,natural-language processing,privacy,psychiatric data,psychological data,security},
  language = {en},
  number = {1}
}

@article{wangHowDataScientists2019,
  ids = {wangHowDataScientists2019a},
  title = {How {{Data Scientists Use Computational Notebooks}} for {{Real}}-{{Time Collaboration}}},
  author = {Wang, April Yi and Mittal, Anant and Brooks, Christopher and Oney, Steve},
  year = {2019},
  month = nov,
  volume = {3},
  pages = {39:1--39:30},
  doi = {10.1145/3359141},
  url = {http://doi.org/10.1145/3359141},
  urldate = {2020-03-06},
  abstract = {Effective collaboration in data science can leverage domain expertise from each team member and thus improve the quality and efficiency of the work. Computational notebooks give data scientists a convenient interactive solution for sharing and keeping track of the data exploration process through a combination of code, narrative text, visualizations, and other rich media. In this paper, we report how synchronous editing in computational notebooks changes the way data scientists work together compared to working on individual notebooks. We first conducted a formative survey with 195 data scientists to understand their past experience with collaboration in the context of data science. Next, we carried out an observational study of 24 data scientists working in pairs remotely to solve a typical data science predictive modeling problem, working on either notebooks supported by synchronous groupware or individual notebooks in a collaborative setting. The study showed that working on the synchronous notebooks improves collaboration by creating a shared context, encouraging more exploration, and reducing communication costs. However, the current synchronous editing features may lead to unbalanced participation and activity interference without strategic coordination. The synchronous notebooks may also amplify the tension between quick exploration and clear explanations. Building on these findings, we propose several design implications aimed at better supporting collaborative editing in computational notebooks, and thus improving efficiency in teamwork among data scientists.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7LQMK44J/Wang et al_2019_How Data Scientists Use Computational Notebooks for Real-Time Collaboration.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/WAC3HP67/Wang et al_2019_How Data Scientists Use Computational Notebooks for Real-Time Collaboration.pdf},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  keywords = {collaborative systems,computational notebooks,data science},
  number = {CSCW}
}

@article{weiCombiningBillingCodes2016,
  title = {Combining Billing Codes, Clinical Notes, and Medications from Electronic Health Records Provides Superior Phenotyping Performance},
  author = {Wei, Wei-Qi and Teixeira, Pedro L. and Mo, Huan and Cronin, Robert M. and Warner, Jeremy L. and Denny, Joshua C.},
  year = {2016},
  month = apr,
  volume = {23},
  pages = {e20-27},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocv130},
  abstract = {OBJECTIVE: To evaluate the phenotyping performance of three major electronic health record (EHR) components: International Classification of Disease (ICD) diagnosis codes, primary notes, and specific medications.
MATERIALS AND METHODS: We conducted the evaluation using de-identified Vanderbilt EHR data. We preselected ten diseases: atrial fibrillation, Alzheimer's disease, breast cancer, gout, human immunodeficiency virus infection, multiple sclerosis, Parkinson's disease, rheumatoid arthritis, and types 1 and 2 diabetes mellitus. For each disease, patients were classified into seven categories based on the presence of evidence in diagnosis codes, primary notes, and specific medications. Twenty-five patients per disease category (a total number of 175 patients for each disease, 1750 patients for all ten diseases) were randomly selected for manual chart review. Review results were used to estimate the positive predictive value (PPV), sensitivity, andF-score for each EHR component alone and in combination.
RESULTS: The PPVs of single components were inconsistent and inadequate for accurately phenotyping (0.06-0.71). Using two or more ICD codes improved the average PPV to 0.84. We observed a more stable and higher accuracy when using at least two components (mean\,{$\pm$}\,standard deviation: 0.91\,{$\pm$}\,0.08). Primary notes offered the best sensitivity (0.77). The sensitivity of ICD codes was 0.67. Again, two or more components provided a reasonably high and stable sensitivity (0.59\,{$\pm$}\,0.16). Overall, the best performance (Fscore: 0.70\,{$\pm$}\,0.12) was achieved by using two or more components. Although the overall performance of using ICD codes (0.67\,{$\pm$}\,0.14) was only slightly lower than using two or more components, its PPV (0.71\,{$\pm$}\,0.13) is substantially worse (0.91\,{$\pm$}\,0.08).
CONCLUSION: Multiple EHR components provide a more consistent and higher performance than a single one for the selected phenotypes. We suggest considering multiple EHR components for future phenotyping design in order to obtain an ideal result.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/TXFURLXV/Wei et al_2016_Combining billing codes, clinical notes, and medications from electronic health.pdf},
  journal = {Journal of the American Medical Informatics Association: JAMIA},
  keywords = {Algorithms,clinical notes,Diagnosis,diagnosis codes,electronic health records,Electronic Health Records,Humans,International Classification of Diseases,Medical Records; Problem-Oriented,medications,phenotype,Phenotype,Predictive Value of Tests,problem lists},
  language = {eng},
  number = {e1},
  pmcid = {PMC4954637},
  pmid = {26338219}
}

@article{weiCombiningBillingCodes2016a,
  title = {Combining Billing Codes, Clinical Notes, and Medications from Electronic Health Records Provides Superior Phenotyping Performance},
  author = {Wei, Wei-Qi and Teixeira, Pedro L. and Mo, Huan and Cronin, Robert M. and Warner, Jeremy L. and Denny, Joshua C.},
  year = {2016},
  month = apr,
  volume = {23},
  pages = {e20-e27},
  publisher = {{Oxford Academic}},
  issn = {1067-5027},
  doi = {10.1093/jamia/ocv130},
  url = {https://academic-oup-com.proxy-um.researchport.umd.edu/jamia/article/23/e1/e20/2379841},
  urldate = {2020-06-08},
  abstract = {Abstract.  Objective To evaluate the phenotyping performance of three major electronic health record (EHR) components: International Classification of Disease (},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/28EHZ7NG/Wei et al_2016_Combining billing codes, clinical notes, and medications from electronic health.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/3CYK9Y5X/2379841.html},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {e1}
}

@article{weiEvaluatingPhecodesClinical2017,
  title = {Evaluating Phecodes, Clinical Classification Software, and {{ICD}}-9-{{CM}} Codes for Phenome-Wide Association Studies in the Electronic Health Record},
  author = {Wei, Wei-Qi and Bastarache, Lisa A. and Carroll, Robert J. and Marlo, Joy E. and Osterman, Travis J. and Gamazon, Eric R. and Cox, Nancy J. and Roden, Dan M. and Denny, Joshua C.},
  year = {2017},
  month = jul,
  volume = {12},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0175508},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5501393/},
  urldate = {2020-06-08},
  abstract = {Objective
To compare three groupings of Electronic Health Record (EHR) billing codes for their ability to represent clinically meaningful phenotypes and to replicate known genetic associations. The three tested coding systems were the International Classification of Diseases, Ninth Revision, Clinical Modification (ICD-9-CM) codes, the Agency for Healthcare Research and Quality Clinical Classification Software for ICD-9-CM (CCS), and manually curated ``phecodes'' designed to facilitate phenome-wide association studies (PheWAS) in EHRs.

Methods and materials
We selected 100 disease phenotypes and compared the ability of each coding system to accurately represent them without performing additional groupings. The 100 phenotypes included 25 randomly-chosen clinical phenotypes pursued in prior genome-wide association studies (GWAS) and another 75 common disease phenotypes mentioned across free-text problem lists from 189,289 individuals. We then evaluated the performance of each coding system to replicate known associations for 440 SNP-phenotype pairs.

Results
Out of the 100 tested clinical phenotypes, phecodes exactly matched 83, compared to 53 for ICD-9-CM and 32 for CCS. ICD-9-CM codes were typically too detailed (requiring custom groupings) while CCS codes were often not granular enough. Among 440 tested known SNP-phenotype associations, use of phecodes replicated 153 SNP-phenotype pairs compared to 143 for ICD-9-CM and 139 for CCS. Phecodes also generally produced stronger odds ratios and lower p-values for known associations than ICD-9-CM and CCS. Finally, evaluation of several SNPs via PheWAS identified novel potential signals, some seen in only using the phecode approach. Among them, rs7318369 in PEPD was associated with gastrointestinal hemorrhage.

Conclusion
Our results suggest that the phecode groupings better align with clinical diseases mentioned in clinical practice or for genomic studies. ICD-9-CM, CCS, and phecode groupings all worked for PheWAS-type studies, though the phecode groupings produced superior results.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/R8FCNA7P/Wei et al_2017_Evaluating phecodes, clinical classification software, and ICD-9-CM codes for.pdf},
  journal = {PLoS ONE},
  number = {7},
  pmcid = {PMC5501393},
  pmid = {28686612}
}

@article{weiskopfMethodsDimensionsElectronic2013,
  title = {Methods and Dimensions of Electronic Health Record Data Quality Assessment: Enabling Reuse for Clinical Research},
  shorttitle = {Methods and Dimensions of Electronic Health Record Data Quality Assessment},
  author = {Weiskopf, N. G. and Weng, C.},
  year = {2013},
  month = jan,
  volume = {20},
  pages = {144--151},
  issn = {1067-5027, 1527-974X},
  doi = {10.1136/amiajnl-2011-000681},
  url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2011-000681},
  urldate = {2020-03-21},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/BYZIE4H6/Weiskopf_Weng_2013_Methods and dimensions of electronic health record data quality assessment.pdf},
  journal = {Journal of the American Medical Informatics Association},
  language = {en},
  number = {1}
}

@article{wileyPhenotypingAdverseDrug2015,
  title = {Phenotyping {{Adverse Drug Reactions}}: {{Statin}}-{{Related Myotoxicity}}},
  shorttitle = {Phenotyping {{Adverse Drug Reactions}}},
  author = {Wiley, Laura K. and Moretz, Jeremy D. and Denny, Joshua C. and Peterson, Josh F. and Bush, William S.},
  year = {2015},
  volume = {2015},
  pages = {466--470},
  issn = {2153-4063},
  abstract = {It is unclear the extent to which best practices for phenotyping disease states from electronic medical records (EMRs) translate to phenotyping adverse drug events. Here we use statin-induced myotoxicity as a case study to identify best practices in this area. We compared multiple phenotyping algorithms using administrative codes, laboratory measurements, and full-text keyword matching to identify statin-related myopathy from EMRs. Manual review of 300 deidentified EMRs with exposure to at least one statin, created a gold standard set of 124 cases and 176 controls. We tested algorithms using ICD-9 billing codes, laboratory measurements of creatine kinase (CK) and keyword searches of clinical notes and allergy lists. The combined keyword algorithms produced were the most accurate (PPV=86\%, NPV=91\%). Unlike in most disease phenotyping algorithms, addition of ICD9 codes or laboratory data did not appreciably increase algorithm accuracy. We conclude that phenotype algorithms for adverse drug events should consider text based approaches.},
  journal = {AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science},
  language = {eng},
  pmcid = {PMC4525276},
  pmid = {26306287}
}

@article{wilkinsonFAIRGuidingPrinciples2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and {da Silva Santos}, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and {Gonzalez-Beltran}, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and {'t Hoen}, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and {Rocca-Serra}, Philippe and Roos, Marco and {van Schaik}, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and {van der Lei}, Johan and {van Mulligen}, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  year = {2016},
  month = dec,
  volume = {3},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {http://www.nature.com/articles/sdata201618},
  urldate = {2020-02-27},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/V9BDNNDB/wilkinsonFAIRGuidingPrinciples2016.pdf},
  journal = {Scientific Data},
  language = {en},
  number = {1}
}

@article{williamsClinicalCodeSet2017,
  title = {Clinical Code Set Engineering for Reusing {{EHR}} Data for Research: {{A}} Review},
  shorttitle = {Clinical Code Set Engineering for Reusing {{EHR}} Data for Research},
  author = {Williams, Richard and Kontopantelis, Evangelos and Buchan, Iain and Peek, Niels},
  year = {2017},
  volume = {70},
  pages = {1--13},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7PRAMZG7/williamsClinicalCodeSet2017.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/BSGQ4DMZ/S1532046417300801.html},
  journal = {Journal of biomedical informatics}
}

@article{williamsSMASHSalfordMedication2018,
  title = {{{SMASH}}! {{The Salford}} Medication Safety Dashboard},
  author = {Williams, Richard and Keers, Richard and Gude, Wouter T. and Jeffries, Mark and Davies, Colin and Brown, Benjamin and Kontopantelis, Evangelos and Avery, Anthony J. and Ashcroft, Darren M. and Peek, Niels},
  year = {2018},
  month = jul,
  volume = {25},
  publisher = {{BMJ Specialist Journals}},
  issn = {2632-1009},
  doi = {10.14236/jhi.v25i3.1015},
  url = {https://informatics.bmj.com/content/25/3/183},
  urldate = {2020-07-02},
  abstract = {Background Patient safety is vital to well-functioning health systems. A key component is safe prescribing, particularly in primary care where most medications are prescribed. Previous research has demonstrated that the number of patients exposed to potentially hazardous prescribing can be reduced by interrogating the electronic health record (EHR) database of general practices and providing feedback to general practitioners (GPs) in a pharmacist-led intervention. We aimed to develop and roll out an online dashboard application that delivers this audit and feedback intervention in a continuous fashion.
Method Based on initial system requirements, we designed the dashboard's user interface over three iterations with six GPs, seven pharmacists and a member of the public. Prescribing safety indicators from previous work were implemented in the dashboard. Pharmacists were trained to use the intervention and deliver it to general practices.
Results A web-based electronic dashboard was developed and linked to shared care records in Salford, UK. The completed dashboard was deployed in all but one (n = 43) general practices in the region. By November 2017, 36 pharmacists had been trained in delivering the intervention to practices. There were 135 registered users of the dashboard, with an average of 91 user sessions a week.
Conclusion We have developed and successfully rolled out of a complex, pharmacist-led dashboard intervention in Salford, UK. System usage statistics indicate broad and sustained uptake of the intervention. The use of systems that provide regularly updated audit information may be an important contributor towards medication safety in primary care.},
  chapter = {Research article},
  copyright = {\textcopyright{} 2018 The Author(s). Published by BCS, The Chartered Institute for IT under Creative. Commons license http://creativecommons.org/licenses/by/4.0/},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/AZNXEFUG/Williams et al_2018_SMASH.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/ZET24CJ4/183.html},
  journal = {BMJ Health \& Care Informatics},
  keywords = {dashboard,drug prescriptions,electronic audit and feedback,patient safety},
  language = {en},
  number = {3},
  pmid = {30398462}
}

@article{williamsTermSetsTransparent2019,
  title = {Term Sets: {{A}} Transparent and Reproducible Representation of Clinical Code Sets},
  shorttitle = {Term Sets},
  author = {Williams, Richard and Brown, Benjamin and Kontopantelis, Evan and {van Staa}, Tjeerd and Peek, Niels},
  year = {2019},
  volume = {14},
  pages = {e0212291},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0212291},
  abstract = {OBJECTIVE: Clinical code sets are vital to research using routinely-collected electronic healthcare data. Existing code set engineering methods pose significant limitations when considering reproducible research. To improve the transparency and reusability of research, these code sets must abide by FAIR principles; this is not currently happening. We propose 'term sets', an equivalent alternative to code sets that are findable, accessible, interoperable and reusable.
MATERIALS AND METHODS: We describe a new code set representation, consisting of natural language inclusion and exclusion terms (term sets), and explain its relationship to code sets. We formally prove that any code set has a corresponding term set. We demonstrate utility by searching for recently published code sets, representing them as term sets, and reporting on the number of inclusion and exclusion terms compared with the size of the code set.
RESULTS: Thirty-one code sets from 20 papers covering diverse disease domains were converted into term sets. The term sets were on average 74\% the size of their equivalent original code set. Four term sets were larger due to deficiencies in the original code sets.
DISCUSSION: Term sets can concisely represent any code set. This may reduce barriers for examining and reusing code sets, which may accelerate research using healthcare databases. We have developed open-source software that supports researchers using term sets.
CONCLUSION: Term sets are independent of clinical code terminologies and therefore: enable reproducible research; are resistant to terminology changes; and are less error-prone as they are shorter than the equivalent code set.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/7FLJAP9S/Williams et al_2019_Term sets.pdf},
  journal = {PloS One},
  language = {eng},
  number = {2},
  pmcid = {PMC6375602},
  pmid = {30763407}
}

@inproceedings{winnenburgAligningPharmacologicClasses2013,
  title = {Aligning {{Pharmacologic Classes Between MeSH}} and {{ATC}}},
  booktitle = {{{VDOS}}+ {{DO}}@ {{ICBO}}},
  author = {Winnenburg, Rainer and Rodriguez, Laritza and Callaghan, Fiona M and Sorbello, Alfred and Szarfman, Ana and Bodenreider, Olivier},
  year = {2013},
  url = {https://mor.nlm.nih.gov/pubs/pdf/2013-vdos-rw.pdf},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/PUWAYIMC/Winnenburg et al_2013_Aligning Pharmacologic Classes Between MeSH and ATC.pdf},
  keywords = {Active papers/AMIA VS}
}

@article{winnenburgDesiderataAuthoritativeRepresentation2014,
  title = {Desiderata for an Authoritative {{Representation}} of {{MeSH}} in {{RDF}}},
  author = {Winnenburg, Rainer and Bodenreider, Olivier},
  year = {2014},
  month = nov,
  volume = {2014},
  pages = {1218--1227},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/25954433},
  abstract = {The Semantic Web provides a framework for the integration of resources on
the web, which facilitates information integration and interoperability.
RDF is the main representation format for Linked Open Data (LOD). However,
datasets are not always made available in RDF by their producers and the
Semantic Web community has had to convert some of these datasets to RDF in
order for these datasets to participate in the LOD cloud. As a result, the
LOD cloud sometimes contains outdated, partial and even inaccurate RDF
datasets. We review the LOD landscape for one of these resources, MeSH,
and analyze the characteristics of six existing representations in order
to identify desirable features for an authoritative version, for which we
create a prototype. We illustrate the suitability of this prototype on
three common use cases. NLM intends to release an authoritative
representation of MeSH in RDF (beta version) in the Fall of 2014.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/338FZW4T/Winnenburg_Bodenreider_2014_Desiderata for an authoritative Representation of MeSH in RDF.pdf},
  journal = {AMIA Annu. Symp. Proc.},
  keywords = {Active papers/AMIA VS}
}

@article{winnenburgIssuesCreatingMaintaining2012,
  title = {Issues in Creating and Maintaining Value Sets for Clinical Quality Measures},
  author = {Winnenburg, Rainer and Bodenreider, Olivier},
  year = {2012},
  month = nov,
  volume = {2012},
  pages = {988--996},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/23304374},
  abstract = {OBJECTIVE: To develop methods for assessing the validity, consistency and
currency of value sets for clinical quality measures, in order to support
the developers of quality measures in which such value sets are used.
METHODS: We assessed the well-formedness of the codes (in a given code
system), the existence and currency of the codes in the corresponding code
system, using the UMLS and RxNorm terminology services. We also
investigated the overlap among value sets using the Jaccard similarity
measure. RESULTS: We extracted 163,788 codes (76,062 unique codes) from
1463 unique value sets in the 113 quality measures published by the
National Quality Forum (NQF) in December 2011. Overall, 5\% of the codes
are invalid (4\% of the unique codes). We also found 67 duplicate value
sets and 10 pairs of value sets exhibiting a high degree of similarity
(Jaccard {$>$} .9). CONCLUSION: Invalid codes affect a large proportion of the
value sets (19\%). 79\% of the quality Measures have at least one value set
exhibiting errors. However, 50\% of the quality measures exhibit errors in
less than 10 \% of their value sets. The existence of duplicate and
highly-similar value sets suggests the need for an authoritative
repository of value sets and related tooling in order to support the
development of quality measures.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/XDMGMGE2/Winnenburg_Bodenreider_2012_Issues in creating and maintaining value sets for clinical quality measures.pdf},
  journal = {AMIA Annu. Symp. Proc.}
}

@article{winnenburgMetricsAssessingQuality2013,
  title = {Metrics for Assessing the Quality of Value Sets in Clinical Quality Measures},
  author = {Winnenburg, Rainer and Bodenreider, Olivier},
  year = {2013},
  month = nov,
  volume = {2013},
  pages = {1497--1505},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/24551422},
  abstract = {OBJECTIVE: To assess the quality of value sets in clinical quality
measures, both individually and as a population of value sets. MATERIALS
AND METHODS: The concepts from a given value set are expected to be rooted
by one or few ancestor concepts and the value set is expected to contain
all the descendants of its root concepts and only these descendants. (1)
We assessed the completeness and correctness of individual value sets by
comparison to the extension derived from their roots. (2) We assessed the
non-redundancy of value sets for the entire population of value sets
(within a given code system) using the Jaccard similarity measure.
RESULTS: We demonstrated the utility of our approach on some cases of
inconsistent value sets and produced a list of 58 potentially duplicate
value sets from the current set of clinical quality measures for the 2014
Meaningful Use criteria. CONCLUSION: These metrics are easy to compute and
provide compact indicators of the completeness, correctness, and
non-redundancy of value sets.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/X4J87B7F/winnenburgMetricsAssessingQuality2013.pdf},
  journal = {AMIA Annu. Symp. Proc.}
}

@inproceedings{Wixon1990,
  title = {Contextual Design: {{An}} Emergent View of System Design},
  booktitle = {Proceedings of the {{ACM}} Conference on Human Factors in Computing Systems},
  author = {Wixon, Dennis and Holtzblatt, Karen and Knox, Stephen},
  year = {1990},
  pages = {329--336},
  publisher = {{ACM}},
  address = {{New York, NY, USA}},
  doi = {10.1145/97243.97304}
}

@article{wuEvaluatingCongruenceLaboratory2013,
  title = {Evaluating {{Congruence Between Laboratory LOINC Value Sets}} for {{Quality Measures}}, {{Public Health Reporting}}, and {{Mapping Common Tests}}},
  author = {Wu, Jianmin and Finnell, John T. and Vreeman, Daniel J.},
  year = {2013},
  month = nov,
  volume = {2013},
  pages = {1525--1532},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900163/},
  urldate = {2020-05-14},
  abstract = {Laboratory test results are important for secondary data uses like quality measures and public health reporting, but mapping local laboratory codes to LOINC is a challenge. We evaluated the congruence between laboratory LOINC value sets for quality measures, public health reporting, and mapping common tests. We found a modest proportion of the LOINC codes from the Value Set Authority Center (VSAC) were present in the LOINC Top 2000 Results (16\%) and the Reportable Condition Mapping Table (52\%), and only 25 terms (3\%) were shared with the Notifiable Condition Detector Top 129. More than a third of the VSAC Quality LOINCs were unique to that value set. A relatively small proportion of the VSAC Quality LOINCs were used by our hospital laboratories. Our results illustrate how mapping based only on test frequency might hinder these secondary uses of laboratory test results.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/WAZHKYHU/Wu et al. - 2013 - Evaluating Congruence Between Laboratory LOINC Val.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC3900163},
  pmid = {24551424}
}

@article{wyndenValueValueSets2011,
  title = {The Value of Value Sets},
  author = {Wynden, Rob and Solbrig, Harold and Tu, Samson and Brinkley, James F.},
  year = {2011},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/KPIDVKBR/Wynden et al_2011_The value of value sets.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/PJP32SH7/ValueSetPanelBrinkleyFinal.pdf;../../../../../citation-data/Zotero-after-paperpile/storage/KL3TZ4RS/253.html}
}

@inproceedings{zappa2ndConnectedWorld2019,
  title = {2nd {{Connected World}}/{{Web}} \& {{Semantic Interoperability Workshop}} 2019 ({{IoT}}-{{CWSI}} 2019)},
  booktitle = {Proceedings of the 9th {{International Conference}} on the {{Internet}} of {{Things}}},
  author = {Zappa, Achille and Serrano, Martin},
  year = {2019},
  month = oct,
  pages = {1--8},
  publisher = {{Association for Computing Machinery}},
  address = {{Bilbao, Spain}},
  doi = {10.1145/3365871.3365896},
  url = {https://doi.org/10.1145/3365871.3365896},
  urldate = {2020-03-05},
  abstract = {A Connected World/Web of Things is an emerging area that not only requires development of infrastructure but also deployment of new data services capable of supporting multiple, scalable (cloud-based) and interoperable (cross-systems and cross-domain) applications. In the race of designing the Connected World/Web as part of the Future Internet architecture, academia and Information and Communication Technology (ICT) industry communities have realized that a common problem to be tackled is the interoperability of the data and their availability for providing information services. Worldwide there is an increasingly focusing on how to evolve communications technologies to enable a Connected World, thus Semantic-enabled Web of Things systems will need to interact and be interconnected for offering the always-promoted everything-connected interoperability paradigm. The Connected World/Web \& Semantic Interoperability workshop provides to developers, scientific researchers, industry experts and general audience interested in the evolution of the Internet of connected things world, the possibility to explore interoperability research challenges and provide a room to expose their research scientific ideas and progress and also explore new trends and opportunities of using semantic web technologies for solving problems and creating new solutions on emerging specialized paradigms like the current Internet of connected Things or simply acknowledge as Internet of Things (IoT).},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/TGQ6YMYE/Zappa_Serrano_2019_2nd Connected World-Web & Semantic Interoperability Workshop 2019 (IoT-CWSI.pdf},
  isbn = {978-1-4503-7207-7},
  series = {{{IoT}} 2019}
}

@book{zhengCognitiveInformaticsReengineering2019,
  title = {Cognitive {{Informatics}}: {{Reengineering Clinical Workflow}} for {{Safer}} and {{More Efficient Care}}},
  shorttitle = {Cognitive {{Informatics}}},
  author = {Zheng, Kai and Westbrook, Johanna and Kannampallil, Thomas G. and Patel, Vimla L.},
  year = {2019},
  publisher = {{Springer}},
  abstract = {This timely book addresses gaps in the understanding of how health information technology (IT) impacts on clinical workflows and how the effective implementation of these workflows are central to the safe and effective delivery of care to patients. It features clearly structured chapters covering a range of topics, including aspects of clinical workflows relevant to both practitioners and patients, tools for recording clinical workflow data techniques for potentially redesigning health IT enabled care coordination.Cognitive Informatics: Reengineering Clinical Workflow for More Efficient and Safer Care enables readers to develop a deeper understanding of clinical workflows and how these can potentially be modified to facilitate greater efficiency and safety in care provision, providing a valuable resource for both biomedical and health informatics professionals and trainees.},
  googlebooks = {RjulDwAAQBAJ},
  isbn = {978-3-030-16916-9},
  keywords = {Computers / Social Aspects,Medical / General,Medical / Instruments \& Supplies},
  language = {en}
}

@article{zozusResearchReproducibilityLongitudinal2016,
  title = {Research {{Reproducibility}} in {{Longitudinal Multi}}-{{Center Studies Using Data}} from {{Electronic Health Records}}},
  author = {Zozus, Meredith N and Richesson, Rachel L and Walden, Anita and Tenenbaum, Jessie D and Hammond, W E},
  year = {2016},
  month = jul,
  volume = {2016},
  pages = {279--285},
  issn = {2153-4063},
  url = {https://www.ncbi.nlm.nih.gov/pubmed/27570682},
  abstract = {A fundamental premise of scientific research is that it should be
reproducible. However, the specific requirements for reproducibility of
research using electronic health record (EHR) data have not been
sufficiently articulated. There is no guidance for researchers about how
to assess a given project and identify provisions for reproducibility. We
analyze three different clinical research initiatives that use EHR data in
order to define a set of requirements to reproduce the research using the
original or other datasets. We identify specific project features that
drive these requirements. The resulting framework will support the
much-needed discussion of strategies to ensure the reproducibility of
research that uses data from EHRs.},
  file = {../../../../../citation-data/Zotero-after-paperpile/storage/2YC34QEB/Zozus et al_2016_Research Reproducibility in Longitudinal Multi-Center Studies Using Data from.pdf},
  journal = {AMIA Jt Summits Transl Sci Proc},
  keywords = {Active papers/AMIA VS,Informatics/Phenotyping}
}


